{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Patch\n",
    "import seaborn as sns\n",
    "from typing import Dict, List, Tuple\n",
    "import yfinance as yf\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, classification_report\n",
    "from sklearn.model_selection import KFold\n",
    "import lightgbm as lgb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import warnings\n",
    "from datetime import datetime, timedelta\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "import os\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "from optuna.pruners import MedianPruner\n",
    "import traceback\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NORMALIZATION_METHODS = {\n",
    "    \"min_max\": \"Min-Max normalization to range [0,1]\",\n",
    "    \"z_score\": \"Z-score normalization (mean/std)\",\n",
    "    \"median\": \"Divide by median normalization\",\n",
    "    \"sigmoid\": \"Sigmoid function normalization\",\n",
    "    \"tanh_estimator\": \"Hyperbolic tangent estimator\", \n",
    "}\n",
    "\n",
    "class NormalizationResearch:\n",
    "    def __init__(\n",
    "        self,\n",
    "        cache_path: str = \"data\",\n",
    "        start_date: str = \"2019-01-01\",\n",
    "        end_date: str = \"2024-12-31\",\n",
    "        prediction_horizon: int = 5,\n",
    "        lookback_window: int = 20,\n",
    "        market_index: str = \"OSEBX.OL\",\n",
    "        fast_mode: bool = False,\n",
    "        random_seed: int = 42,\n",
    "        norm_methods: List[str] = None,\n",
    "        baseline_method: str = \"standard\",\n",
    "        n_folds: int = 5,\n",
    "        time_series_split: bool = True,\n",
    "        gap: int = 0,\n",
    "        test_size: float = 0.2\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize the NormalizationResearch class with k-fold cross-validation.\n",
    "        \n",
    "        Args:\n",
    "            cache_path: Path to cache data\n",
    "            start_date: Start date for data analysis\n",
    "            end_date: End date for data analysis\n",
    "            prediction_horizon: Number of days to predict ahead\n",
    "            lookback_window: Number of days to look back for LSTM\n",
    "            market_index: Stock market index to analyze\n",
    "            fast_mode: Whether to use a shortened time period for faster execution\n",
    "            random_seed: Random seed for reproducibility\n",
    "            norm_methods: List of normalization methods to evaluate\n",
    "            baseline_method: Baseline normalization method\n",
    "            n_folds: Number of folds for cross-validation\n",
    "            time_series_split: Whether to use time series split (vs random)\n",
    "            gap: Gap between train and test sets in days (to prevent data leakage)\n",
    "            test_size: Proportion of data to use for testing in each fold\n",
    "        \"\"\"\n",
    "        np.random.seed(random_seed)\n",
    "        torch.manual_seed(random_seed)\n",
    "        \n",
    "        if fast_mode:\n",
    "            print(\"Fast mode enabled - using shortened time period\")\n",
    "            start_date = (datetime.strptime(end_date, \"%Y-%m-%d\") - \n",
    "                         timedelta(days=365)).strftime(\"%Y-%m-%d\")\n",
    "        \n",
    "        self.cache_path = cache_path\n",
    "        self.start_date = start_date\n",
    "        self.end_date = end_date\n",
    "        self.prediction_horizon = prediction_horizon\n",
    "        self.lookback_window = lookback_window\n",
    "        self.market_index = market_index\n",
    "        self.fast_mode = fast_mode\n",
    "        self.random_seed = random_seed\n",
    "        self.n_folds = n_folds\n",
    "        self.time_series_split = time_series_split\n",
    "        self.gap = gap\n",
    "        self.test_size = test_size\n",
    "        \n",
    "        self.data = None\n",
    "        self.features = None\n",
    "        self.feature_names = []\n",
    "        self.target = None\n",
    "        self.dates = None\n",
    "        self.results = {}\n",
    "        self.baseline_perf = {}\n",
    "        self.fold_results = {}\n",
    "        self.actual_returns = None\n",
    "        self.daily_returns = None\n",
    "        self.feature_distributions = {}\n",
    "        \n",
    "        if norm_methods is None:\n",
    "            self.norm_methods = list(NORMALIZATION_METHODS.keys())\n",
    "        else:\n",
    "            self.norm_methods = [method for method in norm_methods if method in NORMALIZATION_METHODS]\n",
    "            if not self.norm_methods:\n",
    "                raise ValueError(f\"No valid normalization methods specified. Available methods: {list(NORMALIZATION_METHODS.keys())}\")\n",
    "        \n",
    "        if baseline_method not in NORMALIZATION_METHODS:\n",
    "            raise ValueError(f\"Baseline method '{baseline_method}' not valid. Available methods: {list(NORMALIZATION_METHODS.keys())}\")\n",
    "        \n",
    "        self.baseline_method = baseline_method\n",
    "        \n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        print(f\"Using device: {self.device}\")\n",
    "    \n",
    "    def fetch_data(self) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Fetches historical market data from Yahoo Finance.\n",
    "        \n",
    "        Returns:\n",
    "            pd.DataFrame: Market data\n",
    "        \"\"\"\n",
    "        print(f\"Fetching {self.market_index} data from {self.start_date} to {self.end_date}...\")\n",
    "        if not os.path.exists(self.cache_path):\n",
    "            os.makedirs(self.cache_path)\n",
    "        else:\n",
    "            cache_file = f\"{self.cache_path}/{self.market_index}_{self.start_date}_{self.end_date}.parquet\"\n",
    "            if os.path.exists(cache_file):\n",
    "                print(\"Data already downloaded. Loading from file...\")\n",
    "                self.data = pd.read_parquet(cache_file)\n",
    "                if \"Date\" in self.data.columns:\n",
    "                    self.data.set_index(\"Date\", inplace=True)\n",
    "                return self.data\n",
    "    \n",
    "        buffer_days = max(100, self.lookback_window * 2)\n",
    "        buffer_start = (datetime.strptime(self.start_date, \"%Y-%m-%d\") - \n",
    "                    timedelta(days=buffer_days)).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "        market_data = None\n",
    "\n",
    "        market_data = yf.download(self.market_index, start=buffer_start, end=self.end_date, progress=False)\n",
    "        \n",
    "        required_columns = [\"Close\", \"High\", \"Low\", \"Open\", \"Volume\"]\n",
    "        for col in required_columns:\n",
    "            if col not in market_data.columns:\n",
    "                print(f\"Warning: {col} not found in data, using Close as fallback\")\n",
    "                market_data[col] = market_data[\"Close\"] if \"Close\" in market_data.columns else None\n",
    "        \n",
    "        data = pd.DataFrame(index=market_data.index)\n",
    "        data[\"close\"] = market_data[\"Close\"]\n",
    "        data[\"high\"] = market_data[\"High\"]\n",
    "        data[\"low\"] = market_data[\"Low\"]\n",
    "        data[\"open\"] = market_data[\"Open\"]\n",
    "        data[\"volume\"] = market_data[\"Volume\"]\n",
    "        \n",
    "        for col in [\"close\", \"high\", \"low\", \"open\"]:\n",
    "            data[col] = data[col].ffill().bfill()\n",
    "\n",
    "        self.data = data.loc[self.start_date:]\n",
    "        print(f\"Data loaded: {len(self.data)} trading days\")\n",
    "\n",
    "        self.daily_returns = self.data[\"close\"].pct_change().dropna()\n",
    "\n",
    "        cache_file = f\"{self.cache_path}/{self.market_index}_{self.start_date}_{self.end_date}.parquet\"\n",
    "        self.data.to_parquet(cache_file)\n",
    "        \n",
    "        return self.data\n",
    "    \n",
    "    def engineer_features(self) -> None:\n",
    "        \"\"\"\n",
    "        Engineers features from raw market data with strict time-awareness to prevent data leakage.\n",
    "        Features are calculated using only past data points for each time step.\n",
    "        \"\"\"\n",
    "        print(\"Engineering features (time-aware approach)...\")\n",
    "        df = self.data.copy()\n",
    "\n",
    "        for period in [1, 2, 3, 5, 10, 21]:\n",
    "            if period < len(df):\n",
    "                df[f\"return_{period}d\"] = df[\"close\"].pct_change(period)\n",
    "        \n",
    "        for period in [10, 20, 50]:\n",
    "            if period < len(df):\n",
    "                df[f\"ma_{period}d\"] = df[\"close\"].rolling(window=period).mean()\n",
    "                # Distance to moving average\n",
    "                df[f\"ma_dist_{period}d\"] = (df[\"close\"] / df[f\"ma_{period}d\"] - 1) * 100\n",
    "        \n",
    "        if \"return_1d\" in df.columns:\n",
    "            for period in [10, 21]:\n",
    "                if period < len(df):\n",
    "                    # Historical volatility calculation\n",
    "                    df[f\"vol_{period}d\"] = df[\"return_1d\"].rolling(window=period).std() * np.sqrt(252)\n",
    "        \n",
    "        if \"ma_20d\" in df.columns and \"ma_50d\" in df.columns:\n",
    "            df[\"ma_cross_20_50\"] = (df[\"ma_20d\"] > df[\"ma_50d\"]).astype(int)\n",
    "        \n",
    "        df[\"high_low_ratio\"] = df[\"high\"] / df[\"low\"]\n",
    "        df[\"close_open_ratio\"] = df[\"close\"] / df[\"open\"]\n",
    "        \n",
    "        if \"volume\" in df.columns and df[\"volume\"].sum() > 0:\n",
    "            df[\"volume_ma_10d\"] = df[\"volume\"].rolling(window=10).mean()\n",
    "            df[\"volume_ratio\"] = df[\"volume\"] / df[\"volume_ma_10d\"]\n",
    "\n",
    "        if self.prediction_horizon < len(df):\n",
    "            df[f\"target_return_{self.prediction_horizon}d\"] = df[\"close\"].pct_change(\n",
    "                self.prediction_horizon\n",
    "            ).shift(-self.prediction_horizon)\n",
    "            \n",
    "            df[\"target\"] = (df[f\"target_return_{self.prediction_horizon}d\"] > 0).astype(int)\n",
    "        else:\n",
    "            print(f\"Warning: Not enough data points for prediction horizon of {self.prediction_horizon}\")\n",
    "            shorter_horizon = max(1, min(3, len(df) // 3))\n",
    "            print(f\"Using shorter prediction horizon: {shorter_horizon} days\")\n",
    "            df[f\"target_return_{shorter_horizon}d\"] = df[\"close\"].pct_change(\n",
    "                shorter_horizon\n",
    "            ).shift(-shorter_horizon)\n",
    "            \n",
    "            df[\"target\"] = (df[f\"target_return_{shorter_horizon}d\"] > 0).astype(int)\n",
    "        \n",
    "        self.feature_names = [col for col in df.columns \n",
    "                            if not col.startswith(\"target\") \n",
    "                            and col != \"close\"\n",
    "                            and col != \"high\"\n",
    "                            and col != \"low\"\n",
    "                            and col != \"open\"\n",
    "                            and col != \"volume\"]\n",
    "                            \n",
    "        if not self.feature_names:\n",
    "            print(\"Warning: No features generated. Creating basic features.\")\n",
    "            df[\"log_return\"] = np.log(df[\"close\"] / df[\"close\"].shift(1))\n",
    "            self.feature_names = [\"log_return\"]\n",
    "        \n",
    "        df = df.dropna()\n",
    "        \n",
    "        self.features = df[self.feature_names]\n",
    "        self.target = df[\"target\"]\n",
    "        self.dates = df.index\n",
    "        self.actual_returns = df[f\"target_return_{self.prediction_horizon}d\"] if f\"target_return_{self.prediction_horizon}d\" in df.columns else df[\"target_return_3d\"]\n",
    "        \n",
    "        print(f\"Features prepared: {len(self.features)} samples with {len(self.feature_names)} features\")\n",
    "        print(f\"Class distribution: {df['target'].value_counts(normalize=True).to_dict()}\")\n",
    "        \n",
    "        if self.fast_mode and len(self.feature_names) > 15:\n",
    "            print(f\"Fast mode: limiting to 15 features (from {len(self.feature_names)})\")\n",
    "            self.feature_names = self.feature_names[:15]\n",
    "            self.features = self.features[self.feature_names]\n",
    "    \n",
    "    def engineer_advanced_features(self) -> None:\n",
    "        \"\"\"\n",
    "        Adds advanced technical indicators and market regime features.\n",
    "        All calculations are time-aware to prevent data leakage.\n",
    "        \"\"\"\n",
    "        print(\"Adding advanced features (time-aware approach)...\")\n",
    "        df = self.data.copy()\n",
    "        \n",
    "        for period in [7, 14, 21]:\n",
    "            delta = df[\"close\"].diff()\n",
    "            gain = delta.mask(delta < 0, 0)\n",
    "            loss = -delta.mask(delta > 0, 0)\n",
    "            avg_gain = gain.rolling(window=period).mean()\n",
    "            avg_loss = loss.rolling(window=period).mean()\n",
    "            rs = avg_gain / avg_loss\n",
    "            df[f\"rsi_{period}\"] = 100 - (100 / (1 + rs))\n",
    "        \n",
    "        ema12 = df[\"close\"].ewm(span=12).mean()\n",
    "        ema26 = df[\"close\"].ewm(span=26).mean()\n",
    "        df[\"macd\"] = ema12 - ema26\n",
    "        df[\"macd_signal\"] = df[\"macd\"].ewm(span=9).mean()\n",
    "        df[\"macd_hist\"] = df[\"macd\"] - df[\"macd_signal\"]\n",
    "        \n",
    "        for period in [20]:\n",
    "            mid = df[\"close\"].rolling(window=period).mean()\n",
    "            std = df[\"close\"].rolling(window=period).std()\n",
    "            df[f\"bb_upper_{period}\"] = mid + 2*std\n",
    "            df[f\"bb_lower_{period}\"] = mid - 2*std\n",
    "            df[f\"bb_width_{period}\"] = (df[f\"bb_upper_{period}\"] - df[f\"bb_lower_{period}\"]) / mid\n",
    "            df[f\"bb_position_{period}\"] = (df[\"close\"] - df[f\"bb_lower_{period}\"]) / (df[f\"bb_upper_{period}\"] - df[f\"bb_lower_{period}\"])\n",
    "        \n",
    "        high_low = df[\"high\"] - df[\"low\"]\n",
    "        high_close = (df[\"high\"] - df[\"close\"].shift()).abs()\n",
    "        low_close = (df[\"low\"] - df[\"close\"].shift()).abs()\n",
    "        ranges = pd.concat([high_low, high_close, low_close], axis=1)\n",
    "        true_range = ranges.max(axis=1)\n",
    "        df[\"atr_14\"] = true_range.rolling(14).mean()\n",
    "        \n",
    "        tp = (df[\"high\"] + df[\"low\"] + df[\"close\"]) / 3\n",
    "        tp_ma = tp.rolling(window=20).mean()\n",
    "        tp_md = tp.rolling(window=20).apply(lambda x: np.abs(x - x.mean()).mean())\n",
    "        df[\"cci_20\"] = (tp - tp_ma) / (0.015 * tp_md)\n",
    "        \n",
    "        low_min = df[\"low\"].rolling(window=14).min()\n",
    "        high_max = df[\"high\"].rolling(window=14).max()\n",
    "        df[\"stoch_k\"] = 100 * ((df[\"close\"] - low_min) / (high_max - low_min))\n",
    "        df[\"stoch_d\"] = df[\"stoch_k\"].rolling(window=3).mean()\n",
    "        \n",
    "        obv = [0]\n",
    "        for i in range(1, len(df)):\n",
    "            if df[\"close\"].iloc[i] > df[\"close\"].iloc[i-1]:\n",
    "                obv.append(obv[-1] + df[\"volume\"].iloc[i])\n",
    "            elif df[\"close\"].iloc[i] < df[\"close\"].iloc[i-1]:\n",
    "                obv.append(obv[-1] - df[\"volume\"].iloc[i])\n",
    "            else:\n",
    "                obv.append(obv[-1])\n",
    "        df[\"obv\"] = obv\n",
    "        \n",
    "        if \"vol_10d\" in df.columns:\n",
    "            df[\"volatility_ratio\"] = df[\"vol_10d\"].pct_change(5)\n",
    "            \n",
    "            if \"ma_dist_10d\" in df.columns:\n",
    "                df[\"trend_strength\"] = abs(df[\"ma_dist_10d\"]) / df[\"vol_10d\"]\n",
    "        \n",
    "        df[\"day_of_week\"] = pd.to_datetime(df.index).dayofweek\n",
    "        df[\"month\"] = pd.to_datetime(df.index).month\n",
    "        df[\"quarter\"] = pd.to_datetime(df.index).quarter\n",
    "        df[\"weekday\"] = pd.to_datetime(df.index).weekday < 5\n",
    "        \n",
    "        if \"vol_10d\" in df.columns and \"rsi_14\" in df.columns:\n",
    "            df[\"vol_rsi_14\"] = df[\"vol_10d\"] * df[\"rsi_14\"]\n",
    "            \n",
    "        if \"macd\" in df.columns and \"rsi_14\" in df.columns:\n",
    "            df[\"macd_rsi_14\"] = df[\"macd\"] * df[\"rsi_14\"]\n",
    "        \n",
    "        df[\"momentum_10d\"] = df[\"close\"] / df[\"close\"].shift(10) - 1\n",
    "        df[\"momentum_30d\"] = df[\"close\"] / df[\"close\"].shift(30) - 1\n",
    "        \n",
    "        df[\"roc_5d\"] = (df[\"close\"] / df[\"close\"].shift(5) - 1) * 100\n",
    "        df[\"roc_21d\"] = (df[\"close\"] / df[\"close\"].shift(21) - 1) * 100\n",
    "\n",
    "        self.data = df\n",
    "\n",
    "    def create_time_series_splits(self) -> List[Tuple[np.ndarray, np.ndarray]]:\n",
    "        \"\"\"\n",
    "        Creates time series splits for cross-validation with proper temporal gaps.\n",
    "        \n",
    "        Returns:\n",
    "            List[Tuple[np.ndarray, np.ndarray]]: List of (train_idx, test_idx) pairs\n",
    "        \"\"\"\n",
    "        n_samples = len(self.features)\n",
    "        indices = np.arange(n_samples)\n",
    "        \n",
    "        if self.time_series_split:\n",
    "            print(f\"Creating {self.n_folds} time series splits with gap={self.gap}\")\n",
    "\n",
    "            splits = []\n",
    "            fold_size = n_samples // (self.n_folds + 1)\n",
    "            \n",
    "            for fold in range(self.n_folds):\n",
    "                test_start = n_samples - (self.n_folds - fold) * fold_size\n",
    "                train_end = test_start - self.gap - 1\n",
    "                \n",
    "                if train_end <= self.lookback_window:\n",
    "                    print(f\"Warning: Not enough data for fold {fold+1}. Skipping.\")\n",
    "                    continue\n",
    "                \n",
    "                train_indices = indices[:train_end]\n",
    "                test_indices = indices[test_start:test_start + fold_size]\n",
    "                \n",
    "                if len(test_indices) == 0:\n",
    "                    print(f\"Warning: Empty test set for fold {fold+1}. Skipping.\")\n",
    "                    continue\n",
    "                \n",
    "                print(f\"Fold {fold+1}: train={len(train_indices)}, test={len(test_indices)}, \"\n",
    "                     f\"gap={test_start-train_end-1} days\")\n",
    "                \n",
    "                splits.append((train_indices, test_indices))\n",
    "        else:\n",
    "            print(f\"Creating {self.n_folds} random k-fold splits (no time awareness)\")\n",
    "            kf = KFold(n_splits=self.n_folds, shuffle=True, random_state=self.random_seed)\n",
    "            splits = list(kf.split(indices))\n",
    "        \n",
    "        return splits\n",
    "\n",
    "    def prepare_train_test_data(self, train_idx: np.ndarray, test_idx: np.ndarray) -> Tuple:\n",
    "        \"\"\"\n",
    "        Prepares training and test data for a given fold.\n",
    "        \n",
    "        Args:\n",
    "            train_idx: Training indices\n",
    "            test_idx: Test indices\n",
    "            \n",
    "        Returns:\n",
    "            Tuple: X_train, X_test, y_train, y_test, dates_test, returns_test\n",
    "        \"\"\"\n",
    "        X_train = self.features.iloc[train_idx].copy()\n",
    "        X_test = self.features.iloc[test_idx].copy()\n",
    "        y_train = self.target.iloc[train_idx].copy()\n",
    "        y_test = self.target.iloc[test_idx].copy()\n",
    "        dates_test = self.dates[test_idx]\n",
    "        returns_test = self.actual_returns.iloc[test_idx].copy()\n",
    "        \n",
    "        return X_train, X_test, y_train, y_test, dates_test, returns_test\n",
    "    \n",
    "    def apply_normalization(self, method: str, X_train: pd.DataFrame, X_test: pd.DataFrame) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Applies normalization method to features, fitting only on training data.\n",
    "        \n",
    "        Args:\n",
    "            method: Normalization method name\n",
    "            X_train: Training features\n",
    "            X_test: Test features\n",
    "            \n",
    "        Returns:\n",
    "            Tuple: Normalized training and test features\n",
    "        \"\"\"\n",
    "        self.feature_distributions[method] = {\n",
    "            'before': {\n",
    "                'train': X_train.copy(),\n",
    "                'test': X_test.copy()\n",
    "            },\n",
    "            'after': {}\n",
    "        }\n",
    "            \n",
    "        if method == \"min_max\":\n",
    "            X_train_norm = X_train.copy().values\n",
    "            X_test_norm = X_test.copy().values\n",
    "            \n",
    "            for col in range(X_train.shape[1]):\n",
    "                col_min = X_train.iloc[:, col].min()\n",
    "                col_max = X_train.iloc[:, col].max()\n",
    "                col_range = col_max - col_min\n",
    "                \n",
    "                if col_range != 0:\n",
    "                    X_train_norm[:, col] = (X_train.iloc[:, col].values - col_min) / col_range\n",
    "                    X_test_norm[:, col] = (X_test.iloc[:, col].values - col_min) / col_range\n",
    "                    X_test_norm[:, col] = np.clip(X_test_norm[:, col], 0, 1)\n",
    "        \n",
    "        elif method == \"z_score\":\n",
    "            X_train_norm = X_train.copy().values\n",
    "            X_test_norm = X_test.copy().values\n",
    "            \n",
    "            for col in range(X_train.shape[1]):\n",
    "                col_mean = X_train.iloc[:, col].mean()\n",
    "                col_std = X_train.iloc[:, col].std()\n",
    "                \n",
    "                if col_std != 0:\n",
    "                    X_train_norm[:, col] = (X_train.iloc[:, col].values - col_mean) / col_std\n",
    "                    X_test_norm[:, col] = (X_test.iloc[:, col].values - col_mean) / col_std\n",
    "        \n",
    "        elif method == \"median\":\n",
    "            X_train_norm = X_train.copy().values\n",
    "            X_test_norm = X_test.copy().values\n",
    "            \n",
    "            for col in range(X_train.shape[1]):\n",
    "                col_median = X_train.iloc[:, col].median()\n",
    "                \n",
    "                if col_median != 0:\n",
    "                    X_train_norm[:, col] = X_train.iloc[:, col].values / col_median\n",
    "                    X_test_norm[:, col] = X_test.iloc[:, col].values / col_median\n",
    "        \n",
    "        elif method == \"sigmoid\":\n",
    "            X_train_norm = X_train.copy().values\n",
    "            X_test_norm = X_test.copy().values\n",
    "            \n",
    "            for col in range(X_train.shape[1]):\n",
    "                X_train_norm[:, col] = 1 / (1 + np.exp(-X_train.iloc[:, col].values))\n",
    "                X_test_norm[:, col] = 1 / (1 + np.exp(-X_test.iloc[:, col].values))\n",
    "        \n",
    "        elif method == \"tanh_estimator\":\n",
    "            X_train_norm = X_train.copy().values\n",
    "            X_test_norm = X_test.copy().values\n",
    "            \n",
    "            for col in range(X_train.shape[1]):\n",
    "                col_mean = X_train.iloc[:, col].mean()\n",
    "                col_std = X_train.iloc[:, col].std()\n",
    "                \n",
    "                if col_std != 0:\n",
    "                    X_train_norm[:, col] = 0.5 * (np.tanh(0.01 * ((X_train.iloc[:, col].values - col_mean) / col_std)) + 1)\n",
    "                    X_test_norm[:, col] = 0.5 * (np.tanh(0.01 * ((X_test.iloc[:, col].values - col_mean) / col_std)) + 1)\n",
    "        \n",
    "            X_train_norm = np.clip(X_train_norm, -10, 10)\n",
    "            X_test_norm = np.clip(X_test_norm, -10, 10)\n",
    "            X_train_norm = np.nan_to_num(X_train_norm)\n",
    "            X_test_norm = np.nan_to_num(X_test_norm)\n",
    "        \n",
    "        else:\n",
    "            raise ValueError(f\"Unknown normalization method: {method}\")\n",
    "        \n",
    "        self.feature_distributions[method]['after'] = {\n",
    "            'train': pd.DataFrame(X_train_norm, columns=X_train.columns),\n",
    "            'test': pd.DataFrame(X_test_norm, columns=X_test.columns)\n",
    "        }\n",
    "        \n",
    "        return X_train_norm, X_test_norm\n",
    "    \n",
    "    def optimize_lightgbm(self, X_train: np.ndarray, y_train: np.ndarray, class_weights: Dict[int, float] = None) -> lgb.LGBMClassifier:\n",
    "        \"\"\"Optimize LightGBM hyperparameters using Bayesian optimization with CV.\n",
    "        \n",
    "        Args:\n",
    "            X_train: Training features\n",
    "            y_train: Training target\n",
    "            class_weights: Optional class weights for imbalanced data\n",
    "            \n",
    "        Returns:\n",
    "            lgb.LGBMClassifier: Optimized model\n",
    "        \"\"\"\n",
    "        print(\"Optimizing LightGBM hyperparameters with CV...\")\n",
    "        \n",
    "        if len(X_train) < 100:\n",
    "            print(f\"Warning: Not enough data for reliable optimization ({len(X_train)} samples). Using default parameters.\")\n",
    "            return self.train_lightgbm_default(X_train, y_train, class_weights)\n",
    "        \n",
    "        n_trials = 15 if self.fast_mode else 50\n",
    "        n_inner_folds = 5\n",
    "        \n",
    "        scale_pos_weight = None\n",
    "        if class_weights is not None:\n",
    "            if 1 in class_weights and 0 in class_weights:\n",
    "                scale_pos_weight = class_weights[1] / class_weights[0]\n",
    "                \n",
    "        def objective(trial):\n",
    "            params = {\n",
    "                \"objective\": \"binary\",\n",
    "                \"metric\": \"binary_logloss\",\n",
    "                \"boosting_type\": trial.suggest_categorical(\"boosting_type\", [\"gbdt\"]),\n",
    "                \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.1, log=True),\n",
    "                \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 500),\n",
    "                \"num_leaves\": trial.suggest_int(\"num_leaves\", 10, 50),\n",
    "                \"max_depth\": trial.suggest_int(\"max_depth\", 3, 10),\n",
    "                \"subsample\": trial.suggest_float(\"subsample\", 0.6, 1.0),\n",
    "                \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.6, 1.0),\n",
    "                \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 0.1, 5.0, log=True),\n",
    "                \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 0.1, 5.0, log=True),\n",
    "                \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 10, 50),\n",
    "                \"random_state\": self.random_seed,\n",
    "                \"verbosity\": -1\n",
    "            }\n",
    "            \n",
    "            if scale_pos_weight is not None:\n",
    "                params[\"scale_pos_weight\"] = scale_pos_weight\n",
    "\n",
    "            kf = KFold(n_splits=n_inner_folds, shuffle=True, random_state=self.random_seed)\n",
    "            cv_scores = []\n",
    "            \n",
    "            for train_idx, val_idx in kf.split(X_train):\n",
    "                X_tr, X_val = X_train[train_idx], X_train[val_idx]\n",
    "                y_tr, y_val = y_train[train_idx], y_train[val_idx]\n",
    "                \n",
    "                if len(val_idx) < 10 or len(np.unique(y_val)) < 2:\n",
    "                    continue\n",
    "                \n",
    "                model = lgb.LGBMClassifier(**params)\n",
    "                model.fit(X_tr, y_tr)\n",
    "                \n",
    "                preds = model.predict_proba(X_val)[:, 1]\n",
    "                score = roc_auc_score(y_val, preds)\n",
    "                cv_scores.append(score)\n",
    "\n",
    "            if cv_scores:\n",
    "                return np.mean(cv_scores)\n",
    "            else:\n",
    "                return 0.0\n",
    "        \n",
    "        pruner = MedianPruner(n_startup_trials=5, n_warmup_steps=5)\n",
    "        study = optuna.create_study(\n",
    "            direction=\"maximize\", \n",
    "            sampler=TPESampler(seed=self.random_seed),\n",
    "            pruner=pruner\n",
    "        )\n",
    "        \n",
    "        try:\n",
    "            timeout = 300 if self.fast_mode else 900\n",
    "            study.optimize(objective, n_trials=n_trials, timeout=timeout, \n",
    "                        catch=(Exception,))\n",
    "            \n",
    "            if len(study.trials) == 0 or study.best_trial is None:\n",
    "                print(\"Optimization failed to complete any trials. Using default parameters.\")\n",
    "                return self.train_lightgbm_default(X_train, y_train, class_weights)\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Optimization error: {str(e)}. Using default parameters.\")\n",
    "            return self.train_lightgbm_default(X_train, y_train, class_weights)\n",
    "        \n",
    "        try:\n",
    "            if not study.best_params:\n",
    "                print(\"No valid parameters found. Using default parameters.\")\n",
    "                return self.train_lightgbm_default(X_train, y_train, class_weights)\n",
    "                \n",
    "            print(\"\\nBest LightGBM Parameters:\")\n",
    "            for key, value in study.best_params.items():\n",
    "                print(f\"  {key}: {value}\")\n",
    "            \n",
    "            best_params = study.best_params\n",
    "            best_params[\"objective\"] = \"binary\"\n",
    "            best_params[\"random_state\"] = self.random_seed\n",
    "            best_params[\"verbosity\"] = -1\n",
    "            \n",
    "            if scale_pos_weight is not None:\n",
    "                best_params[\"scale_pos_weight\"] = scale_pos_weight\n",
    "            \n",
    "            final_model = lgb.LGBMClassifier(**best_params)\n",
    "            final_model.fit(X_train, y_train)\n",
    "            \n",
    "            return final_model\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error building final model with best parameters: {str(e)}. Using default parameters.\")\n",
    "            return self.train_lightgbm_default(X_train, y_train, class_weights)\n",
    "    \n",
    "    def train_lightgbm_default(self, X_train: np.ndarray, y_train: np.ndarray, class_weights: Dict[int, float] = None) -> lgb.LGBMClassifier:\n",
    "        \"\"\"Train a LightGBM model with default parameters.\n",
    "        \n",
    "        Args:\n",
    "            X_train: Training features\n",
    "            y_train: Training target\n",
    "            class_weights: Optional class weights for imbalanced data\n",
    "            \n",
    "        Returns:\n",
    "            lgb.LGBMClassifier: Trained model\n",
    "        \"\"\"\n",
    "        print(\"Training LightGBM model with default parameters...\")\n",
    "        \n",
    "        scale_pos_weight = None\n",
    "        if class_weights is not None:\n",
    "            if 1 in class_weights and 0 in class_weights:\n",
    "                scale_pos_weight = class_weights[1] / class_weights[0]\n",
    "        \n",
    "        params = {\n",
    "            \"objective\": \"binary\",\n",
    "            \"boosting_type\": \"gbdt\",\n",
    "            \"learning_rate\": 0.05,\n",
    "            \"n_estimators\": 1000,\n",
    "            \"max_depth\": 6,\n",
    "            \"num_leaves\": 20,\n",
    "            \"min_child_samples\": 50,\n",
    "            \"min_split_gain\": 0.01,\n",
    "            \"subsample\": 0.8,\n",
    "            \"colsample_bytree\": 0.8,\n",
    "            \"reg_alpha\": 0.5,\n",
    "            \"reg_lambda\": 5.0,\n",
    "            \"random_state\": self.random_seed,\n",
    "            \"verbosity\": -1\n",
    "        }\n",
    "        \n",
    "        if scale_pos_weight is not None:\n",
    "            params[\"scale_pos_weight\"] = scale_pos_weight\n",
    "        \n",
    "        model = lgb.LGBMClassifier(**params)\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def prepare_lstm_data(self, X_train_norm: np.ndarray, X_test_norm: np.ndarray, \n",
    "                     y_train: np.ndarray, y_test: np.ndarray, batch_size: int = 32) -> Tuple:\n",
    "        \"\"\"\n",
    "        Prepares sequential data for LSTM model with time-aware approach.\n",
    "        Adapts lookback window if necessary to ensure data availability.\n",
    "        \n",
    "        Args:\n",
    "            X_train_norm: Normalized training features\n",
    "            X_test_norm: Normalized test features\n",
    "            y_train: Training target\n",
    "            y_test: Test target\n",
    "            batch_size: Batch size for DataLoader\n",
    "            \n",
    "        Returns:\n",
    "            Tuple: train_loader, X_test_lstm, y_test_lstm, lookback\n",
    "        \"\"\"\n",
    "        max_possible_lookback = min(len(X_train_norm), len(X_test_norm)) - 5\n",
    "        \n",
    "        if max_possible_lookback < 3:\n",
    "            raise ValueError(f\"Insufficient data for LSTM sequences. Need at least 8 samples, got {len(X_train_norm)} train, {len(X_test_norm)} test\")\n",
    "        \n",
    "        lookback = min(self.lookback_window, max_possible_lookback)\n",
    "        if lookback < self.lookback_window:\n",
    "            print(f\"Warning: Reduced lookback window from {self.lookback_window} to {lookback} due to limited data\")\n",
    "        \n",
    "        X_train_seq = []\n",
    "        y_train_seq = []\n",
    "        \n",
    "        for i in range(lookback, len(X_train_norm)):\n",
    "            X_train_seq.append(X_train_norm[i-lookback:i])\n",
    "            y_train_seq.append(y_train.iloc[i])\n",
    "        \n",
    "        X_test_seq = []\n",
    "        y_test_seq = []\n",
    "        \n",
    "        for i in range(lookback, len(X_test_norm)):\n",
    "            X_test_seq.append(X_test_norm[i-lookback:i])\n",
    "            y_test_seq.append(y_test.iloc[i])\n",
    "        \n",
    "        if not X_train_seq or not X_test_seq:\n",
    "            raise ValueError(f\"Could not create any valid sequences with lookback={lookback}\")\n",
    "        \n",
    "        X_train_seq = np.array(X_train_seq)\n",
    "        y_train_seq = np.array(y_train_seq)\n",
    "        X_test_seq = np.array(X_test_seq)\n",
    "        y_test_seq = np.array(y_test_seq)\n",
    "        \n",
    "        print(f\"Created LSTM sequences with lookback={lookback}: {len(X_train_seq)} train, {len(X_test_seq)} test\")\n",
    "        \n",
    "        X_train_tensor = torch.FloatTensor(X_train_seq)\n",
    "        y_train_tensor = torch.FloatTensor(y_train_seq).unsqueeze(1)\n",
    "        \n",
    "        train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "        batch_size = min(batch_size, len(X_train_tensor))\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        \n",
    "        return train_loader, torch.FloatTensor(X_test_seq), torch.FloatTensor(y_test_seq), lookback\n",
    "\n",
    "    class BidirectionalLSTM(nn.Module):\n",
    "        \"\"\"\n",
    "        Bidirectional LSTM neural network model with dropout for regularization.\n",
    "        \"\"\"\n",
    "        def __init__(self, input_dim: int, hidden_dim: int = 64, dropout: float = 0.3):\n",
    "            super().__init__()\n",
    "            \n",
    "            self.lstm = nn.LSTM(\n",
    "                input_dim, \n",
    "                hidden_dim, \n",
    "                batch_first=True, \n",
    "                bidirectional=True,\n",
    "                dropout=dropout\n",
    "            )\n",
    "            \n",
    "            self.fc = nn.Sequential(\n",
    "                nn.Linear(hidden_dim * 2, 32),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(dropout),\n",
    "                nn.Linear(32, 1),\n",
    "                nn.Sigmoid()\n",
    "            )\n",
    "            \n",
    "        def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "            lstm_out, _ = self.lstm(x)\n",
    "            lstm_out = lstm_out[:, -1]\n",
    "            return self.fc(lstm_out)\n",
    "    \n",
    "    def train_lstm(self, train_loader: DataLoader, input_dim: int, lstm_params: Dict = None) -> nn.Module:\n",
    "        \"\"\"\n",
    "        Trains an LSTM model with early stopping to prevent overfitting.\n",
    "        \n",
    "        Args:\n",
    "            train_loader: DataLoader with training data\n",
    "            input_dim: Number of input features\n",
    "            lstm_params: Optional hyperparameters from optimization\n",
    "            \n",
    "        Returns:\n",
    "            nn.Module: Trained LSTM model\n",
    "        \"\"\"\n",
    "        print(\"Training LSTM model...\")\n",
    "        \n",
    "        if lstm_params is None:\n",
    "            hidden_dim = 64\n",
    "            dropout = 0.3\n",
    "            learning_rate = 0.001\n",
    "            weight_decay = 1e-5\n",
    "        else:\n",
    "            hidden_dim = lstm_params.get(\"hidden_dim\", 64)\n",
    "            dropout = lstm_params.get(\"dropout\", 0.3)\n",
    "            learning_rate = lstm_params.get(\"learning_rate\", 0.001)\n",
    "            weight_decay = lstm_params.get(\"weight_decay\", 1e-5)\n",
    "        \n",
    "        model = self.BidirectionalLSTM(input_dim, hidden_dim=hidden_dim, dropout=dropout).to(self.device)\n",
    "        criterion = nn.BCELoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "        \n",
    "        num_epochs = 5 if self.fast_mode else 100\n",
    "        patience = 10\n",
    "        best_loss = float('inf')\n",
    "        patience_counter = 0\n",
    "        \n",
    "        for epoch in range(num_epochs):\n",
    "            model.train()\n",
    "            total_loss = 0\n",
    "            \n",
    "            for inputs, labels in train_loader:\n",
    "                inputs = inputs.to(self.device)\n",
    "                labels = labels.to(self.device)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "                optimizer.step()\n",
    "                \n",
    "                total_loss += loss.item()\n",
    "            \n",
    "            avg_loss = total_loss / len(train_loader)\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}\")\n",
    "            \n",
    "            if avg_loss < best_loss:\n",
    "                best_loss = avg_loss\n",
    "                patience_counter = 0\n",
    "                if not self.fast_mode:\n",
    "                    best_model_state = model.state_dict().copy()\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "                if patience_counter >= patience and not self.fast_mode:\n",
    "                    print(f\"Early stopping at epoch {epoch+1}\")\n",
    "                    model.load_state_dict(best_model_state)\n",
    "                    break\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def optimize_lstm(self, X_train_norm: np.ndarray, y_train: np.ndarray, lookback: int) -> Dict:\n",
    "        \"\"\"Optimize LSTM hyperparameters using Bayesian optimization with CV.\n",
    "        \n",
    "        Args:\n",
    "            X_train_norm: Normalized training features\n",
    "            y_train: Training target\n",
    "            lookback: Lookback window size\n",
    "            \n",
    "        Returns:\n",
    "            Dict: Optimized hyperparameters\n",
    "        \"\"\"\n",
    "        print(\"Optimizing LSTM hyperparameters with CV...\")\n",
    "        \n",
    "        if len(X_train_norm) < 100:\n",
    "            print(f\"Warning: Not enough data for reliable LSTM optimization ({len(X_train_norm)} samples). Using default parameters.\")\n",
    "            return {\n",
    "                \"hidden_dim\": 64,\n",
    "                \"dropout\": 0.3, \n",
    "                \"learning_rate\": 0.001,\n",
    "                \"batch_size\": 32,\n",
    "                \"weight_decay\": 1e-5\n",
    "            }\n",
    "        \n",
    "        n_trials = 10 if self.fast_mode else 100\n",
    "        n_inner_folds = 3\n",
    "        \n",
    "        X_train_seq = []\n",
    "        y_train_seq = []\n",
    "        \n",
    "        for i in range(lookback, len(X_train_norm)):\n",
    "            X_train_seq.append(X_train_norm[i-lookback:i])\n",
    "            y_train_seq.append(y_train.iloc[i])\n",
    "        \n",
    "        X_train_seq = np.array(X_train_seq)\n",
    "        y_train_seq = np.array(y_train_seq)\n",
    "        \n",
    "        X_train_tensor = torch.FloatTensor(X_train_seq)\n",
    "        y_train_tensor = torch.FloatTensor(y_train_seq).unsqueeze(1)\n",
    "        \n",
    "        num_samples = len(X_train_tensor)\n",
    "        feature_dim = X_train_norm.shape[1]\n",
    "        \n",
    "        def objective(trial):\n",
    "            hidden_dim = trial.suggest_int(\"hidden_dim\", 32, 128)\n",
    "            dropout = trial.suggest_float(\"dropout\", 0.1, 0.5)\n",
    "            \n",
    "            learning_rate = trial.suggest_float(\"learning_rate\", 1e-4, 1e-2, log=True)\n",
    "            batch_size = trial.suggest_categorical(\"batch_size\", [16, 32, 64])\n",
    "            weight_decay = trial.suggest_float(\"weight_decay\", 1e-6, 1e-4, log=True)\n",
    "            \n",
    "            kf = KFold(n_splits=n_inner_folds, shuffle=True, random_state=self.random_seed)\n",
    "            cv_scores = []\n",
    "            \n",
    "            try:\n",
    "                for train_idx, val_idx in kf.split(range(num_samples)):\n",
    "                    X_tr, X_val = X_train_tensor[train_idx], X_train_tensor[val_idx]\n",
    "                    y_tr, y_val = y_train_tensor[train_idx], y_train_tensor[val_idx]\n",
    "                    \n",
    "                    if len(val_idx) < 10 or len(torch.unique(y_val)) < 2:\n",
    "                        continue\n",
    "                    \n",
    "                    train_dataset = TensorDataset(X_tr, y_tr)\n",
    "                    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "                    \n",
    "                    model = self.BidirectionalLSTM(\n",
    "                        input_dim=feature_dim,\n",
    "                        hidden_dim=hidden_dim,\n",
    "                        dropout=dropout\n",
    "                    ).to(self.device)\n",
    "                    \n",
    "                    criterion = nn.BCELoss()\n",
    "                    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "                    \n",
    "                    epochs = 3 if self.fast_mode else 100\n",
    "                    for epoch in range(epochs):\n",
    "                        model.train()\n",
    "                        for inputs, labels in train_loader:\n",
    "                            inputs = inputs.to(self.device)\n",
    "                            labels = labels.to(self.device)\n",
    "                            \n",
    "                            optimizer.zero_grad()\n",
    "                            outputs = model(inputs)\n",
    "                            loss = criterion(outputs, labels)\n",
    "                            \n",
    "                            loss.backward()\n",
    "                            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "                            optimizer.step()\n",
    "                    \n",
    "                    model.eval()\n",
    "                    with torch.no_grad():\n",
    "                        X_val = X_val.to(self.device)\n",
    "                        y_val = y_val.to(self.device)\n",
    "                        \n",
    "                        outputs = model(X_val)\n",
    "                        probs = outputs.cpu().numpy().flatten()\n",
    "                        y_true = y_val.cpu().numpy().flatten()\n",
    "                        \n",
    "                        try:\n",
    "                            score = roc_auc_score(y_true, probs)\n",
    "                            cv_scores.append(score)\n",
    "                        except:\n",
    "                            continue\n",
    "                \n",
    "                if cv_scores:\n",
    "                    return np.mean(cv_scores)\n",
    "                else:\n",
    "                    return 0.0\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"LSTM trial failed: {str(e)}\")\n",
    "                return 0.0\n",
    "        \n",
    "        pruner = MedianPruner(n_startup_trials=5, n_warmup_steps=5)\n",
    "        study = optuna.create_study(\n",
    "            direction=\"maximize\", \n",
    "            sampler=TPESampler(seed=self.random_seed),\n",
    "            pruner=pruner\n",
    "        )\n",
    "\n",
    "        lstm_default_params = {\n",
    "            \"hidden_dim\": 64,\n",
    "            \"dropout\": 0.3, \n",
    "            \"learning_rate\": 0.001,\n",
    "            \"batch_size\": 32,\n",
    "            \"weight_decay\": 1e-5\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            timeout = 300 if self.fast_mode else 900\n",
    "            study.optimize(objective, n_trials=n_trials, timeout=timeout, \n",
    "                        catch=(Exception,))\n",
    "            \n",
    "            if len(study.trials) == 0 or study.best_trial is None:\n",
    "                print(\"LSTM optimization failed to complete any trials. Using default parameters.\")\n",
    "                return lstm_default_params\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"LSTM optimization error: {str(e)}. Using default parameters.\")\n",
    "            return lstm_default_params\n",
    "        \n",
    "        try:\n",
    "            if not study.best_params:\n",
    "                print(\"No valid parameters found for LSTM. Using default parameters.\")\n",
    "                return lstm_default_params\n",
    "                    \n",
    "            print(\"\\nBest LSTM Parameters:\")\n",
    "            for key, value in study.best_params.items():\n",
    "                print(f\"  {key}: {value}\")\n",
    "            \n",
    "            return study.best_params\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error building LSTM model with best parameters: {str(e)}. Using default parameters.\")\n",
    "            return lstm_default_params\n",
    "    \n",
    "    def evaluate_models(self, lgb_model: lgb.LGBMClassifier, lstm_model: nn.Module, \n",
    "                      X_test: np.ndarray, y_test: np.ndarray, \n",
    "                      X_test_lstm: torch.Tensor, y_test_lstm: torch.Tensor,\n",
    "                      actual_returns: pd.Series, dates_test: pd.DatetimeIndex) -> Dict:\n",
    "        \"\"\"\n",
    "        Evaluates trained models on test data with comprehensive metrics.\n",
    "        Handles potential length mismatches between LSTM and regular test data.\n",
    "        \n",
    "        Args:\n",
    "            lgb_model: Trained LightGBM model\n",
    "            lstm_model: Trained LSTM model\n",
    "            X_test: Test features for LightGBM\n",
    "            y_test: Test target for LightGBM\n",
    "            X_test_lstm: Test features for LSTM\n",
    "            y_test_lstm: Test target for LSTM\n",
    "            actual_returns: Actual returns for the test period\n",
    "            dates_test: Dates for the test data\n",
    "            \n",
    "        Returns:\n",
    "            Dict: Evaluation metrics\n",
    "        \"\"\"\n",
    "        print(\"Evaluating models...\")\n",
    "        \n",
    "        lgb_preds = lgb_model.predict(X_test)\n",
    "        lgb_preds_proba = lgb_model.predict_proba(X_test)[:, 1]\n",
    "        \n",
    "        predictions_df = pd.DataFrame({\n",
    "            'date': dates_test,\n",
    "            'actual_return': actual_returns,\n",
    "            'actual_direction': y_test,\n",
    "            'lgb_pred': lgb_preds,\n",
    "            'lgb_pred_proba': lgb_preds_proba\n",
    "        })\n",
    "        predictions_df.set_index('date', inplace=True)\n",
    "        \n",
    "        metrics = {}\n",
    "        \n",
    "        metrics[\"lightgbm\"] = {\n",
    "            \"accuracy\": accuracy_score(y_test, lgb_preds),\n",
    "            \"f1\": f1_score(y_test, lgb_preds),\n",
    "            \"precision\": precision_score(y_test, lgb_preds),\n",
    "            \"recall\": recall_score(y_test, lgb_preds),\n",
    "            \"roc_auc\": roc_auc_score(y_test, lgb_preds_proba) if len(np.unique(y_test)) > 1 else 0.5\n",
    "        }\n",
    "        \n",
    "        cm = confusion_matrix(y_test, lgb_preds)\n",
    "        metrics[\"lightgbm\"][\"confusion_matrix\"] = cm\n",
    "        \n",
    "        metrics[\"lightgbm\"][\"classification_report\"] = classification_report(y_test, lgb_preds, output_dict=True)\n",
    "        \n",
    "        if lstm_model is not None and len(X_test_lstm) > 0 and len(y_test_lstm) > 0:\n",
    "            try:\n",
    "                if len(X_test_lstm) != len(y_test_lstm):\n",
    "                    print(f\"Warning: LSTM test data length mismatch - X: {len(X_test_lstm)}, y: {len(y_test_lstm)}\")\n",
    "                    print(\"Using minimum length for evaluation\")\n",
    "                    min_len = min(len(X_test_lstm), len(y_test_lstm))\n",
    "                    X_test_lstm = X_test_lstm[:min_len]\n",
    "                    y_test_lstm = y_test_lstm[:min_len]\n",
    "                \n",
    "                lstm_model.eval()\n",
    "                with torch.no_grad():\n",
    "                    lstm_outputs = lstm_model(X_test_lstm.to(self.device))\n",
    "                    lstm_preds_proba = lstm_outputs.cpu().numpy().flatten()\n",
    "                    \n",
    "                    if len(lstm_preds_proba) != len(y_test_lstm):\n",
    "                        print(f\"Warning: LSTM output length mismatch - pred: {len(lstm_preds_proba)}, y: {len(y_test_lstm)}\")\n",
    "                        min_len = min(len(lstm_preds_proba), len(y_test_lstm))\n",
    "                        lstm_preds_proba = lstm_preds_proba[:min_len]\n",
    "                        y_test_lstm = y_test_lstm[:min_len]\n",
    "                    \n",
    "                    lstm_preds = (lstm_preds_proba > 0.5).astype(int)\n",
    "                \n",
    "                y_test_lstm_np = y_test_lstm.numpy()\n",
    "                \n",
    "                metrics[\"lstm\"] = {\n",
    "                    \"accuracy\": accuracy_score(y_test_lstm_np, lstm_preds),\n",
    "                    \"f1\": f1_score(y_test_lstm_np, lstm_preds),\n",
    "                    \"precision\": precision_score(y_test_lstm_np, lstm_preds),\n",
    "                    \"recall\": recall_score(y_test_lstm_np, lstm_preds),\n",
    "                    \"roc_auc\": roc_auc_score(y_test_lstm_np, lstm_preds_proba) if len(np.unique(y_test_lstm_np)) > 1 else 0.5\n",
    "                }\n",
    "                \n",
    "                cm_lstm = confusion_matrix(y_test_lstm_np, lstm_preds)\n",
    "                metrics[\"lstm\"][\"confusion_matrix\"] = cm_lstm\n",
    "                \n",
    "                diff = len(predictions_df) - len(lstm_preds)\n",
    "                \n",
    "                padded_lstm_preds = np.full(len(predictions_df), np.nan)\n",
    "                padded_lstm_probs = np.full(len(predictions_df), np.nan)\n",
    "                \n",
    "                padded_lstm_preds[diff:] = lstm_preds\n",
    "                padded_lstm_probs[diff:] = lstm_preds_proba\n",
    "                \n",
    "                predictions_df['lstm_pred'] = padded_lstm_preds\n",
    "                predictions_df['lstm_pred_proba'] = padded_lstm_probs\n",
    "                \n",
    "                print(f\"Successfully aligned predictions with {diff} NaN padding values\")\n",
    "                \n",
    "                print(f\"LSTM - Accuracy: {metrics['lstm']['accuracy']:.4f}, \"\n",
    "                    f\"F1: {metrics['lstm']['f1']:.4f}, \"\n",
    "                    f\"ROC AUC: {metrics['lstm']['roc_auc']:.4f}\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"Error evaluating LSTM model: {str(e)}\")\n",
    "                traceback.print_exc()\n",
    "        \n",
    "        print(f\"LightGBM - Accuracy: {metrics['lightgbm']['accuracy']:.4f}, \"\n",
    "             f\"F1: {metrics['lightgbm']['f1']:.4f}, \"\n",
    "             f\"ROC AUC: {metrics['lightgbm']['roc_auc']:.4f}\")\n",
    "        \n",
    "        metrics[\"predictions\"] = predictions_df\n",
    "        \n",
    "        return metrics\n",
    "    \n",
    "    def run_kfold_cv(self) -> Dict:\n",
    "        \"\"\"\n",
    "        Performs k-fold cross-validation on the dataset for all normalization methods.\n",
    "        Uses time series splits to prevent data leakage.\n",
    "        Optimizes both LightGBM and LSTM models for the baseline method.\n",
    "        \n",
    "        Returns:\n",
    "            Dict: Results for each normalization method and fold\n",
    "        \"\"\"\n",
    "        print(f\"\\nRunning {self.n_folds}-fold cross-validation\")\n",
    "        \n",
    "        splits = self.create_time_series_splits()\n",
    "        \n",
    "        methods_to_evaluate = self.norm_methods.copy()\n",
    "        if self.baseline_method not in methods_to_evaluate:\n",
    "            methods_to_evaluate.append(self.baseline_method)\n",
    "\n",
    "        self.fold_results = {\n",
    "            method: {\n",
    "                f\"fold_{i+1}\": {} for i in range(len(splits))\n",
    "            } for method in methods_to_evaluate\n",
    "        }\n",
    "        \n",
    "        print(\"\\nOptimizing LightGBM and LSTM parameters for baseline method...\")\n",
    "        optimized_lgb_params = {}\n",
    "        optimized_lstm_params = {}\n",
    "        \n",
    "        for fold_idx, (train_idx, test_idx) in enumerate(splits):\n",
    "            X_train, X_test, y_train, y_test, dates_test, returns_test = self.prepare_train_test_data(\n",
    "                train_idx, test_idx\n",
    "            )\n",
    "            \n",
    "            if len(X_train) < 30 or len(X_test) < 10:\n",
    "                continue\n",
    "                \n",
    "            class_counts = pd.Series(y_train).value_counts()\n",
    "            if 0 in class_counts and 1 in class_counts:\n",
    "                class_weights = {0: 1.0, 1: class_counts[0] / class_counts[1]}\n",
    "            else:\n",
    "                class_weights = None\n",
    "            \n",
    "            X_train_norm, X_test_norm = self.apply_normalization(self.baseline_method, X_train, X_test)\n",
    "            \n",
    "            if not self.fast_mode:\n",
    "                try:\n",
    "                    print(f\"\\nOptimizing LightGBM for fold {fold_idx+1} using {self.baseline_method} normalization\")\n",
    "                    lgb_model = self.optimize_lightgbm(X_train_norm, y_train.values, class_weights)\n",
    "                    lgb_params = {\n",
    "                        key: value for key, value in lgb_model.get_params().items() \n",
    "                        if key in [\"learning_rate\", \"n_estimators\", \"num_leaves\", \"max_depth\", \n",
    "                                \"subsample\", \"colsample_bytree\", \"reg_alpha\", \"reg_lambda\", \n",
    "                                \"min_child_samples\"]\n",
    "                    }\n",
    "                    optimized_lgb_params[f\"fold_{fold_idx+1}\"] = lgb_params\n",
    "                except Exception as e:\n",
    "                    print(f\"LightGBM optimization failed for fold {fold_idx+1}: {str(e)}\")\n",
    "                    optimized_lgb_params[f\"fold_{fold_idx+1}\"] = None\n",
    "                \n",
    "                try:\n",
    "                    print(f\"\\nOptimizing LSTM for fold {fold_idx+1} using {self.baseline_method} normalization\")\n",
    "                    _, _, _, lookback = self.prepare_lstm_data(X_train_norm, X_test_norm, y_train, y_test)\n",
    "                    \n",
    "                    lstm_params = self.optimize_lstm(X_train_norm, y_train, lookback)\n",
    "                    optimized_lstm_params[f\"fold_{fold_idx+1}\"] = lstm_params\n",
    "                except Exception as e:\n",
    "                    print(f\"LSTM optimization failed for fold {fold_idx+1}: {str(e)}\")\n",
    "                    optimized_lstm_params[f\"fold_{fold_idx+1}\"] = None\n",
    "            else:\n",
    "                optimized_lgb_params[f\"fold_{fold_idx+1}\"] = None\n",
    "                optimized_lstm_params[f\"fold_{fold_idx+1}\"] = None\n",
    "        \n",
    "        print(\"\\nStarting k-fold evaluation for all normalization methods\")\n",
    "        \n",
    "        for fold_idx, (train_idx, test_idx) in enumerate(splits):\n",
    "            print(f\"\\nProcessing fold {fold_idx+1}/{len(splits)}\")\n",
    "            \n",
    "            X_train, X_test, y_train, y_test, dates_test, returns_test = self.prepare_train_test_data(\n",
    "                train_idx, test_idx\n",
    "            )\n",
    "            \n",
    "            if len(X_train) < 30 or len(X_test) < 10:\n",
    "                print(f\"Warning: Fold {fold_idx+1} has insufficient data (train: {len(X_train)}, test: {len(X_test)})\")\n",
    "                print(\"Skipping this fold\")\n",
    "                continue\n",
    "            \n",
    "            class_counts = pd.Series(y_train).value_counts()\n",
    "            print(f\"Class distribution in fold {fold_idx+1}: {class_counts.to_dict()}\")\n",
    "            \n",
    "            if 0 in class_counts and 1 in class_counts:\n",
    "                class_weights = {0: 1.0, 1: class_counts[0] / class_counts[1]}\n",
    "            else:\n",
    "                class_weights = None\n",
    "            \n",
    "            lgb_params = optimized_lgb_params.get(f\"fold_{fold_idx+1}\")\n",
    "            lstm_params = optimized_lstm_params.get(f\"fold_{fold_idx+1}\")\n",
    "            \n",
    "            for method in tqdm(methods_to_evaluate, desc=f\"Fold {fold_idx+1} - Evaluating methods\"):\n",
    "                print(f\"\\nTesting normalization method: {method} (Fold {fold_idx+1})\")\n",
    "                \n",
    "                try:\n",
    "                    X_train_norm, X_test_norm = self.apply_normalization(method, X_train, X_test)\n",
    "                    \n",
    "                    if lgb_params is not None:\n",
    "                        params = lgb_params.copy()\n",
    "                        params[\"random_state\"] = self.random_seed\n",
    "                        params[\"verbosity\"] = -1\n",
    "                        params[\"objective\"] = \"binary\"\n",
    "                        \n",
    "                        if class_weights is not None and 1 in class_weights and 0 in class_weights:\n",
    "                            params[\"scale_pos_weight\"] = class_weights[1] / class_weights[0]\n",
    "                        \n",
    "                        lgb_model = lgb.LGBMClassifier(**params)\n",
    "                        lgb_model.fit(X_train_norm, y_train.values)\n",
    "                    else:\n",
    "                        lgb_model = self.train_lightgbm_default(X_train_norm, y_train.values, class_weights)\n",
    "                    \n",
    "                    lstm_model = None\n",
    "                    model_metrics = {}\n",
    "                    \n",
    "                    try:\n",
    "                        batch_size = lstm_params.get(\"batch_size\", 32) if lstm_params else 32\n",
    "                        \n",
    "                        train_loader, X_test_lstm, y_test_lstm, _ = self.prepare_lstm_data(\n",
    "                            X_train_norm, X_test_norm, y_train, y_test, batch_size\n",
    "                        )\n",
    "                        \n",
    "                        lstm_model = self.train_lstm(train_loader, X_train.shape[1], lstm_params)\n",
    "                        \n",
    "                        model_metrics = self.evaluate_models(\n",
    "                            lgb_model, lstm_model, \n",
    "                            X_test_norm, y_test, \n",
    "                            X_test_lstm, y_test_lstm,\n",
    "                            returns_test, dates_test\n",
    "                        )\n",
    "                    except Exception as e:\n",
    "                        print(f\"LSTM training/evaluation failed: {str(e)}\")\n",
    "                        print(\"Evaluating only LightGBM model\")\n",
    "                        \n",
    "                        lgb_preds = lgb_model.predict(X_test_norm)\n",
    "                        lgb_preds_proba = lgb_model.predict_proba(X_test_norm)[:, 1]\n",
    "                        \n",
    "                        model_metrics = {\n",
    "                            \"lightgbm\": {\n",
    "                                \"accuracy\": accuracy_score(y_test, lgb_preds),\n",
    "                                \"f1\": f1_score(y_test, lgb_preds),\n",
    "                                \"precision\": precision_score(y_test, lgb_preds),\n",
    "                                \"recall\": recall_score(y_test, lgb_preds),\n",
    "                                \"roc_auc\": roc_auc_score(y_test, lgb_preds_proba) if len(np.unique(y_test)) > 1 else 0.5,\n",
    "                                \"confusion_matrix\": confusion_matrix(y_test, lgb_preds),\n",
    "                                \"classification_report\": classification_report(y_test, lgb_preds, output_dict=True)\n",
    "                            }\n",
    "                        }\n",
    "                        \n",
    "                        predictions_df = pd.DataFrame({\n",
    "                            'date': dates_test,\n",
    "                            'actual_return': returns_test,\n",
    "                            'actual_direction': y_test,\n",
    "                            'lgb_pred': lgb_preds,\n",
    "                            'lgb_pred_proba': lgb_preds_proba\n",
    "                        })\n",
    "                        predictions_df.set_index('date', inplace=True)\n",
    "                        \n",
    "                        model_metrics[\"predictions\"] = predictions_df\n",
    "                    \n",
    "                    self.fold_results[method][f\"fold_{fold_idx+1}\"] = model_metrics\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Error evaluating {method} (Fold {fold_idx+1}): {str(e)}\")\n",
    "                    self.fold_results[method][f\"fold_{fold_idx+1}\"] = {\"error\": str(e)}\n",
    "                \n",
    "                if \"lgb_model\" in locals():\n",
    "                    del lgb_model\n",
    "                if \"lstm_model\" in locals():\n",
    "                    del lstm_model\n",
    "                if \"train_loader\" in locals():\n",
    "                    del train_loader\n",
    "                if \"X_test_lstm\" in locals():\n",
    "                    del X_test_lstm\n",
    "                if \"y_test_lstm\" in locals():\n",
    "                    del y_test_lstm\n",
    "                gc.collect()\n",
    "                if torch.cuda.is_available():\n",
    "                    torch.cuda.empty_cache()\n",
    "        \n",
    "        self.process_fold_results()\n",
    "        \n",
    "        return self.results\n",
    "    \n",
    "    def process_fold_results(self) -> None:\n",
    "        \"\"\"\n",
    "        Process fold results to calculate average metrics and standard deviations.\n",
    "        Includes additional financial and predictive performance metrics.\n",
    "        \"\"\"\n",
    "        print(\"\\nProcessing cross-validation results...\")\n",
    "        \n",
    "        self.results = {}\n",
    "        \n",
    "        for method in self.fold_results:\n",
    "            method_results = {}\n",
    "            \n",
    "            for model_name in [\"lightgbm\", \"lstm\"]:\n",
    "                model_metrics = {}\n",
    "                \n",
    "                for metric in [\"accuracy\", \"f1\", \"precision\", \"recall\", \"roc_auc\"]:\n",
    "                    metric_values = []\n",
    "                    \n",
    "                    for fold in range(len(self.fold_results[method])):\n",
    "                        fold_name = f\"fold_{fold+1}\"\n",
    "                        if (fold_name in self.fold_results[method] and\n",
    "                            model_name in self.fold_results[method][fold_name] and\n",
    "                            metric in self.fold_results[method][fold_name][model_name]):\n",
    "                            metric_values.append(self.fold_results[method][fold_name][model_name][metric])\n",
    "                    \n",
    "                    if metric_values:\n",
    "                        model_metrics[metric] = np.mean(metric_values)\n",
    "                        model_metrics[f\"{metric}_std\"] = np.std(metric_values)\n",
    "                        model_metrics[f\"{metric}_values\"] = metric_values\n",
    "                \n",
    "                if model_metrics:\n",
    "                    method_results[model_name] = model_metrics\n",
    "            \n",
    "            self.results[method] = method_results\n",
    "            \n",
    "            if method == self.baseline_method:\n",
    "                self.baseline_perf = method_results\n",
    "    \n",
    "    def run_normalization_comparison(self) -> Dict:\n",
    "        \"\"\"\n",
    "        Runs the complete normalization comparison experiment with k-fold CV.\n",
    "        \n",
    "        Returns:\n",
    "            Dict: Comparison results\n",
    "        \"\"\"\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(f\"NORMALIZATION TECHNIQUES COMPARISON WITH {self.n_folds}-FOLD CV\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        self.fetch_data()\n",
    "        self.engineer_features()\n",
    "        self.engineer_advanced_features()\n",
    "        \n",
    "        return self.run_kfold_cv()\n",
    "    \n",
    "    def plot_results(self) -> None:\n",
    "        \"\"\"\n",
    "        Plots detailed results including classifier performance metrics.\n",
    "        \"\"\"\n",
    "        valid_results = {method: results for method, results in self.results.items() \n",
    "                       if isinstance(results, dict) and \"error\" not in results}\n",
    "        \n",
    "        if not valid_results:\n",
    "            print(\"No valid results to plot. All methods encountered errors.\")\n",
    "            return\n",
    "        \n",
    "        try:\n",
    "            data = []\n",
    "            baseline_data = []\n",
    "            for norm_method, model_results in valid_results.items():\n",
    "                for model_name, metrics in model_results.items():\n",
    "                    for metric_name, value in metrics.items():\n",
    "                        if not metric_name.endswith(\"_std\") and not metric_name.endswith(\"_values\"):\n",
    "                            try:\n",
    "                                if isinstance(value, (int, float)) and not isinstance(value, bool):\n",
    "                                    data_point = {\n",
    "                                        \"Normalization\": norm_method,\n",
    "                                        \"Model\": model_name,\n",
    "                                        \"Metric\": metric_name,\n",
    "                                        \"Value\": value\n",
    "                                    }\n",
    "                                    \n",
    "                                    data.append(data_point)\n",
    "                                    \n",
    "                                    if norm_method == self.baseline_method:\n",
    "                                        baseline_data.append(data_point)\n",
    "                            except Exception as e:\n",
    "                                print(f\"Warning: Could not process metric {metric_name} with value {value}: {str(e)}\")\n",
    "            \n",
    "            if not data:\n",
    "                print(\"No data available for plotting. Check if results contain valid metrics.\")\n",
    "                return\n",
    "                \n",
    "            df_results = pd.DataFrame(data)\n",
    "            df_baseline = pd.DataFrame(baseline_data) if baseline_data else None\n",
    "            \n",
    "            required_cols = [\"Normalization\", \"Model\", \"Metric\", \"Value\"]\n",
    "            if not all(col in df_results.columns for col in required_cols):\n",
    "                print(f\"Warning: DataFrame missing required columns. Columns found: {df_results.columns.tolist()}\")\n",
    "                return\n",
    "            \n",
    "            self.plot_classification_metrics(df_results, df_baseline)\n",
    "            self.plot_feature_distributions()\n",
    "            self.plot_roc_curves()\n",
    "            self.plot_confusion_matrices()\n",
    "            self.plot_fold_comparison()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error in plotting results: {str(e)}\")\n",
    "            traceback.print_exc()\n",
    "    \n",
    "    def plot_classification_metrics(self, df_results: pd.DataFrame, df_baseline: pd.DataFrame = None) -> None:\n",
    "        \"\"\"\n",
    "        Plots classification metrics for all normalization methods.\n",
    "        \n",
    "        Args:\n",
    "            df_results: DataFrame with all results\n",
    "            df_baseline: DataFrame with baseline results\n",
    "        \"\"\"\n",
    "        if df_results is None or df_results.empty:\n",
    "            print(\"No data available for classification metrics plot\")\n",
    "            return\n",
    "            \n",
    "        if not all(col in df_results.columns for col in [\"Normalization\", \"Model\", \"Metric\", \"Value\"]):\n",
    "            print(f\"Missing required columns for classification metrics. Available columns: {df_results.columns.tolist()}\")\n",
    "            return\n",
    "        \n",
    "        classification_metrics = [\"accuracy\", \"f1\", \"precision\", \"recall\", \"roc_auc\"]\n",
    "        available_metrics = df_results[\"Metric\"].unique()\n",
    "        \n",
    "        metrics_to_plot = [metric for metric in classification_metrics if metric in available_metrics]\n",
    "        \n",
    "        if not metrics_to_plot:\n",
    "            print(f\"No classification metrics found in data. Available metrics: {available_metrics}\")\n",
    "            return\n",
    "        \n",
    "        n_metrics = len(metrics_to_plot)\n",
    "        n_rows = (n_metrics + 1) // 2\n",
    "        \n",
    "        fig = plt.figure(figsize=(20, 6 * n_rows))\n",
    "        \n",
    "        for i, metric in enumerate(metrics_to_plot):\n",
    "            try:\n",
    "                plt.subplot(n_rows, 2, i+1)\n",
    "                df_metric = df_results[df_results[\"Metric\"] == metric]\n",
    "                \n",
    "                if df_metric.empty:\n",
    "                    continue\n",
    "                \n",
    "                plot = sns.barplot(x=\"Normalization\", y=\"Value\", hue=\"Model\", data=df_metric)\n",
    "                \n",
    "                if df_baseline is not None:\n",
    "                    baseline_metric = df_baseline[df_baseline[\"Metric\"] == metric]\n",
    "                    if not baseline_metric.empty:\n",
    "                        for model in [\"lightgbm\", \"lstm\"]:\n",
    "                            model_baseline = baseline_metric[baseline_metric[\"Model\"] == model]\n",
    "                            if not model_baseline.empty:\n",
    "                                baseline_val = model_baseline[\"Value\"].values\n",
    "                                if len(baseline_val) > 0:\n",
    "                                    plt.axhline(\n",
    "                                        y=baseline_val[0], \n",
    "                                        linestyle=\"--\", \n",
    "                                        color=\"red\" if model == \"lightgbm\" else \"blue\",\n",
    "                                        alpha=0.7,\n",
    "                                        label=f\"{self.baseline_method} {model} baseline\"\n",
    "                                    )\n",
    "                \n",
    "                plt.title(f\"{metric.capitalize()} by Normalization Method\")\n",
    "                plt.xlabel(\"Normalization Method\")\n",
    "                plt.ylabel(metric.capitalize())\n",
    "                plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "                plt.legend(title=\"Model\")\n",
    "                plt.xticks(rotation=45)\n",
    "                \n",
    "                try:\n",
    "                    for container in plot.containers:\n",
    "                        plot.bar_label(container, fmt=\"%.3f\", fontsize=8)\n",
    "                except Exception as e:\n",
    "                    print(f\"Could not add bar labels: {str(e)}\")\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(f\"Error plotting {metric}: {str(e)}\")\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        try:\n",
    "            if not os.path.exists(\"visualizations\"):\n",
    "                os.makedirs(\"visualizations\")\n",
    "            plt.savefig(\"visualizations/classification_metrics.png\", dpi=300, bbox_inches=\"tight\")\n",
    "        except Exception as e:\n",
    "            print(f\"Could not save figure: {str(e)}\")\n",
    "        plt.close()\n",
    "\n",
    "    def plot_feature_distributions(self) -> None:\n",
    "        \"\"\"\n",
    "        Plots feature distributions before and after normalization for selected features.\n",
    "        Handles missing data gracefully.\n",
    "        \"\"\"\n",
    "        if not self.feature_distributions:\n",
    "            print(\"No feature distribution data available.\")\n",
    "            return\n",
    "        \n",
    "        methods_to_plot = [self.baseline_method] + [m for m in self.norm_methods if m != self.baseline_method]\n",
    "        methods_to_plot = [m for m in methods_to_plot if m in self.feature_distributions]\n",
    "        \n",
    "        if not methods_to_plot:\n",
    "            print(\"No valid normalization methods in feature distributions.\")\n",
    "            return\n",
    "            \n",
    "        try:\n",
    "            if self.features is not None and not self.features.empty:\n",
    "                feature_cols = list(self.features.columns)[:min(3, len(self.features.columns))]\n",
    "                \n",
    "                if not feature_cols:\n",
    "                    print(\"No features available for plotting distributions\")\n",
    "                    return\n",
    "                    \n",
    "                for feature in feature_cols:\n",
    "                    feature_exists = True\n",
    "                    for method in methods_to_plot:\n",
    "                        if (method not in self.feature_distributions or\n",
    "                            'before' not in self.feature_distributions[method] or\n",
    "                            'after' not in self.feature_distributions[method] or\n",
    "                            feature not in self.feature_distributions[method]['before']['train'].columns or\n",
    "                            feature not in self.feature_distributions[method]['after']['train'].columns):\n",
    "                            feature_exists = False\n",
    "                            break\n",
    "                    \n",
    "                    if not feature_exists:\n",
    "                        print(f\"Skipping feature {feature} as it's not available in all distributions\")\n",
    "                        continue\n",
    "                        \n",
    "                    plt.figure(figsize=(15, 10))\n",
    "                    \n",
    "                    for i, method in enumerate(methods_to_plot):\n",
    "                        plt.subplot(len(methods_to_plot), 2, i*2 + 1)\n",
    "                        before_train = self.feature_distributions[method]['before']['train'][feature]\n",
    "                        sns.histplot(before_train, kde=True)\n",
    "                        plt.title(f\"{method} - Before Normalization\")\n",
    "                        plt.xlabel(feature)\n",
    "                        \n",
    "                        plt.subplot(len(methods_to_plot), 2, i*2 + 2)\n",
    "                        after_train = self.feature_distributions[method]['after']['train'][feature]\n",
    "                        sns.histplot(after_train, kde=True)\n",
    "                        plt.title(f\"{method} - After Normalization\")\n",
    "                        plt.xlabel(feature)\n",
    "                    \n",
    "                    plt.suptitle(f\"Distribution of '{feature}' Before and After Normalization\")\n",
    "                    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "                    plt.savefig(f\"visualizations/feature_distribution_{feature}.png\", dpi=300, bbox_inches=\"tight\")\n",
    "                    plt.close()\n",
    "                \n",
    "                if len(feature_cols) > 0:\n",
    "                    feature = feature_cols[0]\n",
    "                    \n",
    "                    feature_exists = True\n",
    "                    for method in methods_to_plot:\n",
    "                        if (method not in self.feature_distributions or\n",
    "                            'after' not in self.feature_distributions[method] or\n",
    "                            feature not in self.feature_distributions[method]['after']['train'].columns):\n",
    "                            feature_exists = False\n",
    "                            break\n",
    "                    \n",
    "                    if feature_exists:\n",
    "                        n_methods = len(methods_to_plot)\n",
    "                        ncols = min(n_methods, 2)\n",
    "                        nrows = (n_methods + 1) // 2\n",
    "                        \n",
    "                        plt.figure(figsize=(7 * ncols, 5 * nrows))\n",
    "                        \n",
    "                        for i, method in enumerate(methods_to_plot):\n",
    "                            plt.subplot(nrows, ncols, i+1)\n",
    "                            after_train = self.feature_distributions[method]['after']['train'][feature]\n",
    "                            sns.histplot(after_train, kde=True)\n",
    "                            plt.title(f\"{method}\")\n",
    "                            plt.xlabel(feature)\n",
    "                        \n",
    "                        plt.suptitle(f\"Distribution of '{feature}' Across Normalization Methods\")\n",
    "                        plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "                        plt.savefig(f\"visualizations/normalization_comparison_{feature}.png\", dpi=300, bbox_inches=\"tight\")\n",
    "                        plt.close()\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error plotting feature distributions: {str(e)}\")\n",
    "            traceback.print_exc()\n",
    "    \n",
    "    def plot_roc_curves(self) -> None:\n",
    "        \"\"\"\n",
    "        Plots ROC curves for different normalization methods.\n",
    "        Handles cases where LSTM predictions might not be available or contain NaN values.\n",
    "        \"\"\"\n",
    "        fold_name = \"fold_1\"\n",
    "        \n",
    "        methods_to_plot = [self.baseline_method] + [m for m in self.norm_methods if m != self.baseline_method]\n",
    "        \n",
    "        for model_name in [\"lightgbm\", \"lstm\"]:\n",
    "            try:\n",
    "                plt.figure(figsize=(10, 8))\n",
    "                curves_plotted = 0\n",
    "                \n",
    "                for method in methods_to_plot:\n",
    "                    if (method in self.fold_results and \n",
    "                        fold_name in self.fold_results[method] and\n",
    "                        model_name in self.fold_results[method][fold_name] and\n",
    "                        \"predictions\" in self.fold_results[method][fold_name]):\n",
    "                        \n",
    "                        predictions = self.fold_results[method][fold_name][\"predictions\"]\n",
    "                        \n",
    "                        if model_name == \"lightgbm\":\n",
    "                            if all(col in predictions.columns for col in [\"actual_direction\", \"lgb_pred_proba\"]):\n",
    "                                y_true = predictions[\"actual_direction\"]\n",
    "                                y_score = predictions[\"lgb_pred_proba\"]\n",
    "                                \n",
    "                                fpr, tpr, _ = roc_curve(y_true, y_score)\n",
    "                                roc_auc = roc_auc_score(y_true, y_score)\n",
    "                                \n",
    "                                plt.plot(fpr, tpr, lw=2, label=f'{method} (AUC = {roc_auc:.3f})')\n",
    "                                curves_plotted += 1\n",
    "                        else:\n",
    "                            if all(col in predictions.columns for col in [\"actual_direction\", \"lstm_pred_proba\"]):\n",
    "                                mask = ~predictions[\"lstm_pred_proba\"].isna()\n",
    "                                if mask.sum() > 10:\n",
    "                                    y_true = predictions.loc[mask, \"actual_direction\"]\n",
    "                                    y_score = predictions.loc[mask, \"lstm_pred_proba\"]\n",
    "                                    \n",
    "                                    fpr, tpr, _ = roc_curve(y_true, y_score)\n",
    "                                    roc_auc = roc_auc_score(y_true, y_score)\n",
    "                                    \n",
    "                                    plt.plot(fpr, tpr, lw=2, label=f'{method} (AUC = {roc_auc:.3f})')\n",
    "                                    curves_plotted += 1\n",
    "                \n",
    "                if curves_plotted > 0:\n",
    "                    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "                    plt.xlim([0.0, 1.0])\n",
    "                    plt.ylim([0.0, 1.05])\n",
    "                    plt.xlabel('False Positive Rate')\n",
    "                    plt.ylabel('True Positive Rate')\n",
    "                    plt.title(f'ROC Curves for {model_name.upper()}')\n",
    "                    plt.legend(loc=\"lower right\")\n",
    "                    plt.grid(True, alpha=0.3)\n",
    "                    plt.savefig(f\"visualizations/roc_curves_{model_name}.png\", dpi=300, bbox_inches=\"tight\")\n",
    "                else:\n",
    "                    print(f\"No data available to plot ROC curves for {model_name}\")\n",
    "                \n",
    "                plt.close()\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error plotting ROC curves for {model_name}: {str(e)}\")\n",
    "                traceback.print_exc()\n",
    "                plt.close()\n",
    "    \n",
    "    def plot_confusion_matrices(self) -> None:\n",
    "        \"\"\"\n",
    "        Plots confusion matrices for different normalization methods.\n",
    "        Handles missing data and NaN values gracefully.\n",
    "        \"\"\"\n",
    "        fold_name = \"fold_1\"\n",
    "        \n",
    "        methods_to_plot = [self.baseline_method] + [m for m in self.norm_methods if m != self.baseline_method]\n",
    "        \n",
    "        for model_name in [\"lightgbm\", \"lstm\"]:\n",
    "            try:\n",
    "                valid_methods = []\n",
    "                matrices = []\n",
    "                \n",
    "                for method in methods_to_plot:\n",
    "                    if (method in self.fold_results and \n",
    "                        fold_name in self.fold_results[method] and\n",
    "                        model_name in self.fold_results[method][fold_name] and\n",
    "                        \"confusion_matrix\" in self.fold_results[method][fold_name][model_name]):\n",
    "                        \n",
    "                        cm = self.fold_results[method][fold_name][model_name][\"confusion_matrix\"]\n",
    "                        if np.sum(cm) > 0:\n",
    "                            valid_methods.append(method)\n",
    "                            matrices.append(cm)\n",
    "                \n",
    "                if valid_methods:\n",
    "                    n_methods = len(valid_methods)\n",
    "                    ncols = min(n_methods, 2)\n",
    "                    nrows = (n_methods + 1) // 2\n",
    "                    \n",
    "                    plt.figure(figsize=(7 * ncols, 5 * nrows))\n",
    "                    \n",
    "                    for i, (method, cm) in enumerate(zip(valid_methods, matrices)):\n",
    "                        plt.subplot(nrows, ncols, i+1)\n",
    "                        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "                        plt.title(f'{method}')\n",
    "                        plt.ylabel('True Label')\n",
    "                        plt.xlabel('Predicted Label')\n",
    "                    \n",
    "                    plt.suptitle(f'Confusion Matrices for {model_name.upper()}')\n",
    "                    plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "                    plt.savefig(f\"visualizations/confusion_matrices_{model_name}.png\", dpi=300, bbox_inches=\"tight\")\n",
    "                else:\n",
    "                    print(f\"No confusion matrices available for {model_name}\")\n",
    "                \n",
    "                plt.close()\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error plotting confusion matrices for {model_name}: {str(e)}\")\n",
    "                plt.close()\n",
    "    \n",
    "    def plot_fold_comparison(self) -> None:\n",
    "        \"\"\"\n",
    "        Plot detailed fold-by-fold comparison between baseline and best methods.\n",
    "        \"\"\"\n",
    "        best_methods = {}\n",
    "        for metric in [\"accuracy\", \"f1\", \"roc_auc\"]:\n",
    "            for model_name in [\"lightgbm\", \"lstm\"]:\n",
    "                best_value = 0\n",
    "                best_method = None\n",
    "                \n",
    "                for method, results in self.results.items():\n",
    "                    if (model_name in results and \n",
    "                        metric in results[model_name] and \n",
    "                        results[model_name][metric] > best_value):\n",
    "                        best_value = results[model_name][metric]\n",
    "                        best_method = method\n",
    "                \n",
    "                if best_method:\n",
    "                    key = f\"{model_name}_{metric}\"\n",
    "                    best_methods[key] = best_method\n",
    "        \n",
    "        for metric in [\"accuracy\", \"f1\", \"roc_auc\"]:\n",
    "            for model_name in [\"lightgbm\", \"lstm\"]:\n",
    "                key = f\"{model_name}_{metric}\"\n",
    "                if key not in best_methods:\n",
    "                    continue\n",
    "                    \n",
    "                best_method = best_methods[key]\n",
    "                if best_method == self.baseline_method:\n",
    "                    continue\n",
    "                \n",
    "                plt.figure(figsize=(12, 6))\n",
    "                \n",
    "                baseline_values = []\n",
    "                best_values = []\n",
    "                fold_labels = []\n",
    "                \n",
    "                num_folds = len(self.fold_results[self.baseline_method])\n",
    "                \n",
    "                for fold in range(num_folds):\n",
    "                    fold_name = f\"fold_{fold+1}\"\n",
    "                    fold_labels.append(f\"Fold {fold+1}\")\n",
    "                    \n",
    "                    if (fold_name in self.fold_results[self.baseline_method] and\n",
    "                        model_name in self.fold_results[self.baseline_method][fold_name] and\n",
    "                        metric in self.fold_results[self.baseline_method][fold_name][model_name]):\n",
    "                        baseline_values.append(\n",
    "                            self.fold_results[self.baseline_method][fold_name][model_name][metric]\n",
    "                        )\n",
    "                    else:\n",
    "                        baseline_values.append(0)\n",
    "                    \n",
    "                    if (fold_name in self.fold_results[best_method] and\n",
    "                        model_name in self.fold_results[best_method][fold_name] and\n",
    "                        metric in self.fold_results[best_method][fold_name][model_name]):\n",
    "                        best_values.append(\n",
    "                            self.fold_results[best_method][fold_name][model_name][metric]\n",
    "                        )\n",
    "                    else:\n",
    "                        best_values.append(0)\n",
    "                \n",
    "                bar_width = 0.35\n",
    "                index = np.arange(len(fold_labels))\n",
    "                \n",
    "                plt.bar(index, baseline_values, bar_width, \n",
    "                       label=f\"Baseline ({self.baseline_method})\", color=\"blue\", alpha=0.7)\n",
    "                plt.bar(index + bar_width, best_values, bar_width,\n",
    "                       label=f\"Best ({best_method})\", color=\"green\", alpha=0.7)\n",
    "                \n",
    "                plt.xlabel(\"Fold\")\n",
    "                plt.ylabel(metric.capitalize())\n",
    "                plt.title(f\"{model_name.upper()} - {metric.capitalize()} Across Folds\")\n",
    "                plt.xticks(index + bar_width / 2, fold_labels)\n",
    "                plt.legend()\n",
    "                plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.3)\n",
    "                \n",
    "                avg_baseline = np.mean(baseline_values)\n",
    "                avg_best = np.mean(best_values)\n",
    "                improvement = ((avg_best - avg_baseline) / avg_baseline) * 100\n",
    "                \n",
    "                plt.figtext(\n",
    "                    0.5, 0.01, \n",
    "                    f\"Overall improvement: {improvement:.2f}% ({avg_best:.4f} vs {avg_baseline:.4f})\",\n",
    "                    ha=\"center\", fontsize=12\n",
    "                )\n",
    "                \n",
    "                plt.tight_layout(rect=[0, 0.05, 1, 1])\n",
    "                plt.savefig(f\"visualizations/fold_comparison_{model_name}_{metric}.png\", dpi=300, bbox_inches=\"tight\")\n",
    "                plt.close()\n",
    "    \n",
    "    def print_summary(self) -> None:\n",
    "        \"\"\"\n",
    "        Print detailed summary of cross-validation results.\n",
    "        \"\"\"\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(f\"NORMALIZATION METHOD PERFORMANCE SUMMARY ({self.n_folds}-FOLD CV)\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        best_methods = {}\n",
    "        for model_name in [\"lightgbm\", \"lstm\"]:\n",
    "            best_methods[model_name] = {}\n",
    "            for metric in [\"accuracy\", \"f1\", \"roc_auc\"]:\n",
    "                best_val = 0\n",
    "                best_method = None\n",
    "                \n",
    "                for method, results in self.results.items():\n",
    "                    if (model_name in results and \n",
    "                        metric in results[model_name] and \n",
    "                        results[model_name][metric] > best_val):\n",
    "                        best_val = results[model_name][metric]\n",
    "                        best_method = method\n",
    "                \n",
    "                if best_method:\n",
    "                    best_methods[model_name][metric] = (best_method, best_val)\n",
    "        \n",
    "        for model_name in [\"lightgbm\", \"lstm\"]:\n",
    "            print(f\"\\n{model_name.upper()} MODEL RESULTS:\")\n",
    "            print(\"-\" * 40)\n",
    "            \n",
    "            for metric in [\"accuracy\", \"f1\", \"roc_auc\"]:\n",
    "                if metric in best_methods[model_name]:\n",
    "                    best_method, best_val = best_methods[model_name][metric]\n",
    "                    print(f\"Best {metric}: {best_method} ({best_val:.4f})\")\n",
    "                    \n",
    "                    if (self.baseline_method in self.results and \n",
    "                        model_name in self.results[self.baseline_method] and\n",
    "                        metric in self.results[self.baseline_method][model_name]):\n",
    "                        \n",
    "                        baseline_val = self.results[self.baseline_method][model_name][metric]\n",
    "                        diff = best_val - baseline_val\n",
    "                        pct_change = (diff / baseline_val) * 100 if baseline_val != 0 else float(\"inf\")\n",
    "                        \n",
    "                        print(f\"  vs. baseline ({self.baseline_method}): {baseline_val:.4f} ({pct_change:+.2f}%)\")\n",
    "                        \n",
    "                        if f\"{metric}_std\" in self.results[best_method][model_name]:\n",
    "                            best_std = self.results[best_method][model_name][f\"{metric}_std\"]\n",
    "                            baseline_std = self.results[self.baseline_method][model_name][f\"{metric}_std\"]\n",
    "                            \n",
    "                            print(f\"  Std Dev: {best_std:.4f} vs. baseline: {baseline_std:.4f}\")\n",
    "            \n",
    "            print(\"\\nAll methods:\")\n",
    "            rows = []\n",
    "            for method in self.norm_methods:\n",
    "                if method not in self.results:\n",
    "                    continue\n",
    "                    \n",
    "                if model_name not in self.results[method]:\n",
    "                    continue\n",
    "                \n",
    "                row = [method]\n",
    "                \n",
    "                for metric in [\"accuracy\", \"f1\", \"roc_auc\"]:\n",
    "                    if metric in self.results[method][model_name]:\n",
    "                        val = self.results[method][model_name][metric]\n",
    "                        std = self.results[method][model_name].get(f\"{metric}_std\", 0)\n",
    "                        row.append(f\"{val:.4f}  {std:.4f}\")\n",
    "                    else:\n",
    "                        row.append(\"N/A\")\n",
    "                \n",
    "                rows.append(row)\n",
    "            \n",
    "            if rows:\n",
    "                headers = [\"Method\", \"Accuracy\", \"F1-Score\", \"ROC AUC\"]\n",
    "                row_format = \"{:<15} {:<20} {:<20} {:<20}\"\n",
    "                print(row_format.format(*headers))\n",
    "                print(\"-\" * 75)\n",
    "                for row in rows:\n",
    "                    print(row_format.format(*row))\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*40)\n",
    "        print(\"OVERALL BEST NORMALIZATION METHODS\")\n",
    "        print(\"=\"*40)\n",
    "        \n",
    "        for model_name in [\"lightgbm\", \"lstm\"]:\n",
    "            print(f\"\\n{model_name.upper()}:\")\n",
    "            \n",
    "            method_ranks = {}\n",
    "            for method in self.norm_methods:\n",
    "                if method not in self.results or model_name not in self.results[method]:\n",
    "                    continue\n",
    "                \n",
    "                ranks = []\n",
    "                for metric in [\"accuracy\", \"f1\", \"roc_auc\"]:\n",
    "                    if metric not in self.results[method][model_name]:\n",
    "                        continue\n",
    "                        \n",
    "                    values = [(m, self.results[m][model_name][metric]) \n",
    "                             for m in self.results \n",
    "                             if model_name in self.results[m] and metric in self.results[m][model_name]]\n",
    "                    \n",
    "                    values.sort(key=lambda x: x[1], reverse=True)\n",
    "                    \n",
    "                    for i, (m, _) in enumerate(values):\n",
    "                        if m == method:\n",
    "                            ranks.append(i + 1)\n",
    "                            break\n",
    "                \n",
    "                if ranks:\n",
    "                    method_ranks[method] = sum(ranks) / len(ranks)\n",
    "            \n",
    "            sorted_methods = sorted(method_ranks.items(), key=lambda x: x[1])\n",
    "            \n",
    "            print(\"Top methods by average rank:\")\n",
    "            for i, (method, avg_rank) in enumerate(sorted_methods[:3], 1):\n",
    "                acc = self.results[method][model_name].get(\"accuracy\", 0)\n",
    "                f1 = self.results[method][model_name].get(\"f1\", 0)\n",
    "                roc = self.results[method][model_name].get(\"roc_auc\", 0)\n",
    "                \n",
    "                print(f\"{i}. {method} (avg rank: {avg_rank:.2f}, acc: {acc:.4f}, f1: {f1:.4f}, roc_auc: {roc:.4f})\")\n",
    "\n",
    "    def perform_statistical_tests(self) -> Dict:\n",
    "        \"\"\"\n",
    "        Performs statistical significance tests comparing normalization methods against the baseline.\n",
    "        Uses Wilcoxon signed-rank tests on fold results.\n",
    "        \n",
    "        Returns:\n",
    "            Dict: Statistical test results with p-values\n",
    "        \"\"\"\n",
    "        if not self.fold_results:\n",
    "            print(\"No fold results available for statistical testing.\")\n",
    "            return {}\n",
    "        \n",
    "        print(\"\\nPerforming statistical significance tests (Wilcoxon)...\")\n",
    "        \n",
    "        stat_results = {}\n",
    "        \n",
    "        metrics_to_test = [\"accuracy\", \"f1\", \"roc_auc\"]\n",
    "        models_to_test = [\"lightgbm\"]\n",
    "        \n",
    "        for method in self.fold_results:\n",
    "            for fold in self.fold_results[method]:\n",
    "                if \"lstm\" in self.fold_results[method][fold]:\n",
    "                    models_to_test.append(\"lstm\")\n",
    "                    break\n",
    "            break\n",
    "        \n",
    "        for model_name in models_to_test:\n",
    "            stat_results[model_name] = {}\n",
    "            \n",
    "            for metric in metrics_to_test:\n",
    "                stat_results[model_name][metric] = {}\n",
    "                \n",
    "                baseline_values = []\n",
    "                for fold in range(self.n_folds):\n",
    "                    fold_name = f\"fold_{fold+1}\"\n",
    "                    if (fold_name in self.fold_results[self.baseline_method] and\n",
    "                        model_name in self.fold_results[self.baseline_method][fold_name] and\n",
    "                        metric in self.fold_results[self.baseline_method][fold_name][model_name]):\n",
    "                        baseline_values.append(self.fold_results[self.baseline_method][fold_name][model_name][metric])\n",
    "                \n",
    "                if not baseline_values:\n",
    "                    continue\n",
    "                    \n",
    "                for method in self.norm_methods:\n",
    "                    if method == self.baseline_method:\n",
    "                        continue\n",
    "                    \n",
    "                    method_values = []\n",
    "                    for fold in range(self.n_folds):\n",
    "                        fold_name = f\"fold_{fold+1}\"\n",
    "                        if (fold_name in self.fold_results[method] and\n",
    "                            model_name in self.fold_results[method][fold_name] and\n",
    "                            metric in self.fold_results[method][fold_name][model_name]):\n",
    "                            method_values.append(self.fold_results[method][fold_name][model_name][metric])\n",
    "                    \n",
    "                    if not method_values:\n",
    "                        continue\n",
    "                    \n",
    "                    min_length = min(len(baseline_values), len(method_values))\n",
    "                    if min_length < 2:\n",
    "                        print(f\"Warning: Not enough samples for {model_name}/{metric}/{method} - need at least 2.\")\n",
    "                        continue\n",
    "                    \n",
    "                    baseline_values_trimmed = baseline_values[:min_length]\n",
    "                    method_values_trimmed = method_values[:min_length]\n",
    "                    \n",
    "                    mean_diff = np.mean(method_values_trimmed) - np.mean(baseline_values_trimmed)\n",
    "                    \n",
    "                    try:\n",
    "                        w_stat, p_value_w = stats.wilcoxon(method_values_trimmed, baseline_values_trimmed)\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error in Wilcoxon test for {model_name}/{metric}/{method}: {str(e)}\")\n",
    "                        w_stat, p_value_w = np.nan, np.nan\n",
    "\n",
    "                    is_significant = p_value_w < 0.05 if not np.isnan(p_value_w) else False\n",
    "                    \n",
    "                    stat_results[model_name][metric][method] = {\n",
    "                        \"mean_diff\": mean_diff,\n",
    "                        \"percent_improvement\": (mean_diff / np.mean(baseline_values_trimmed)) * 100,\n",
    "                        \"w_stat\": w_stat,\n",
    "                        \"p_value\": p_value_w,\n",
    "                        \"significant\": is_significant,\n",
    "                        \"baseline_mean\": np.mean(baseline_values_trimmed),\n",
    "                        \"method_mean\": np.mean(method_values_trimmed)\n",
    "                    }\n",
    "        \n",
    "        self.statistical_test_results = stat_results\n",
    "        return stat_results\n",
    "\n",
    "    def print_statistical_summary(self) -> None:\n",
    "        \"\"\"\n",
    "        Prints a summary of statistical significance test results.\n",
    "        \"\"\"\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"STATISTICAL SIGNIFICANCE ANALYSIS (WILCOXON TEST)\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        for model_name in self.statistical_test_results:\n",
    "            print(f\"\\n{model_name.upper()} MODEL RESULTS:\")\n",
    "            print(\"-\" * 50)\n",
    "            \n",
    "            for metric in self.statistical_test_results[model_name]:\n",
    "                print(f\"\\n{metric.upper()} (baseline: {self.baseline_method}):\")\n",
    "                \n",
    "                sorted_methods = sorted(\n",
    "                    self.statistical_test_results[model_name][metric].items(),\n",
    "                    key=lambda x: x[1][\"mean_diff\"],\n",
    "                    reverse=True\n",
    "                )\n",
    "                \n",
    "                headers = [\"Method\", \"Mean Diff\", \"% Improv\", \"p-value\", \"Significant\"]\n",
    "                print(f\"{headers[0]:<15} {headers[1]:<12} {headers[2]:<10} {headers[3]:<12} {headers[4]:<10}\")\n",
    "                print(\"-\" * 60)\n",
    "                \n",
    "                for method, results in sorted_methods:\n",
    "                    mean_diff = f\"{results['mean_diff']:.4f}\"\n",
    "                    pct_improv = f\"{results['percent_improvement']:.2f}%\"\n",
    "                    p_value = f\"{results['p_value']:.4f}\" if not np.isnan(results['p_value']) else \"N/A\"\n",
    "                    sig = \"Yes*\" if results['significant'] else \"No\"\n",
    "                    \n",
    "                    if results['significant']:\n",
    "                        p_value += \"*\"\n",
    "                    \n",
    "                    print(f\"{method:<15} {mean_diff:<12} {pct_improv:<10} {p_value:<12} {sig:<10}\")\n",
    "                \n",
    "                print(\"\\n* p < 0.05 indicates statistical significance\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"SUMMARY OF STATISTICAL FINDINGS\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        significant_findings = []\n",
    "        \n",
    "        for model_name in self.statistical_test_results:\n",
    "            for metric in self.statistical_test_results[model_name]:\n",
    "                sig_methods = [\n",
    "                    (method, results) \n",
    "                    for method, results in self.statistical_test_results[model_name][metric].items()\n",
    "                    if results['significant'] and results['mean_diff'] > 0\n",
    "                ]\n",
    "                \n",
    "                sig_methods.sort(key=lambda x: x[1]['mean_diff'], reverse=True)\n",
    "                \n",
    "                if sig_methods:\n",
    "                    top_method, top_results = sig_methods[0]\n",
    "                    finding = f\"{top_method} showed statistically significant improvement over {self.baseline_method} \"\n",
    "                    finding += f\"for {metric} in {model_name} (p < 0.05, {top_results['percent_improvement']:.2f}% improvement)\"\n",
    "                    significant_findings.append(finding)\n",
    "        \n",
    "        if significant_findings:\n",
    "            print(\"\\nKey significant findings:\")\n",
    "            for i, finding in enumerate(significant_findings, 1):\n",
    "                print(f\"{i}. {finding}\")\n",
    "        else:\n",
    "            print(\"\\nNo statistically significant improvements were found over the baseline method.\")\n",
    "        \n",
    "        print(\"\\nNote: Statistical significance was tested using the Wilcoxon signed-rank test.\")\n",
    "\n",
    "    def plot_statistical_significance(self, save_path=\"visualizations/\") -> None:\n",
    "        \"\"\"\n",
    "        Creates visualizations highlighting statistical significance of results.\n",
    "        \n",
    "        Args:\n",
    "            save_path: Directory to save visualizations\n",
    "        \"\"\"\n",
    "        if not os.path.exists(save_path):\n",
    "            os.makedirs(save_path)\n",
    "        \n",
    "        print(f\"\\nGenerating statistical significance visualizations in {save_path}\")\n",
    "        \n",
    "        for model_name in self.statistical_test_results:\n",
    "            for metric in self.statistical_test_results[model_name]:\n",
    "                try:\n",
    "                    methods = []\n",
    "                    mean_diffs = []\n",
    "                    is_significant = []\n",
    "                    \n",
    "                    for method, results in self.statistical_test_results[model_name][metric].items():\n",
    "                        methods.append(method)\n",
    "                        mean_diffs.append(results['mean_diff'])\n",
    "                        is_significant.append(results['significant'])\n",
    "                    \n",
    "                    if not methods:\n",
    "                        continue\n",
    "                    \n",
    "                    sorted_indices = np.argsort(mean_diffs)[::-1]  # Descending\n",
    "                    methods = [methods[i] for i in sorted_indices]\n",
    "                    mean_diffs = [mean_diffs[i] for i in sorted_indices]\n",
    "                    is_significant = [is_significant[i] for i in sorted_indices]\n",
    "                    \n",
    "                    plt.figure(figsize=(12, 6))\n",
    "                    \n",
    "                    colors = ['green' if sig else 'gray' for sig in is_significant]\n",
    "                    \n",
    "                    bars = plt.bar(range(len(methods)), mean_diffs, color=colors, alpha=0.7)\n",
    "                    \n",
    "                    plt.axhline(y=0, color='red', linestyle='--', alpha=0.7)\n",
    "                    \n",
    "                    for i, bar in enumerate(bars):\n",
    "                        height = bar.get_height()\n",
    "                        if is_significant[i]:\n",
    "                            plt.text(\n",
    "                                bar.get_x() + bar.get_width()/2,\n",
    "                                height + 0.001 if height > 0 else height - 0.003,\n",
    "                                '*',\n",
    "                                ha='center',\n",
    "                                va='bottom' if height > 0 else 'top',\n",
    "                                fontsize=16,\n",
    "                                fontweight='bold'\n",
    "                            )\n",
    "                    \n",
    "                    plt.title(f'Mean Difference vs {self.baseline_method} - {metric} ({model_name})', fontsize=14)\n",
    "                    plt.xlabel('Normalization Method')\n",
    "                    plt.ylabel(f'Mean Difference in {metric}')\n",
    "                    plt.xticks(range(len(methods)), methods, rotation=45)\n",
    "                    plt.grid(axis='y', linestyle='--', alpha=0.3)\n",
    "\n",
    "                    legend_elements = [\n",
    "                        Patch(facecolor='green', alpha=0.7, label='Statistically Significant (p < 0.05)'),\n",
    "                        Patch(facecolor='gray', alpha=0.7, label='Not Significant')\n",
    "                    ]\n",
    "                    plt.legend(handles=legend_elements, loc='best')\n",
    "                    \n",
    "                    plt.tight_layout()\n",
    "                    plt.savefig(f\"{save_path}significance_{model_name}_{metric}.png\", dpi=300, bbox_inches=\"tight\")\n",
    "                    plt.close()\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Error plotting statistical significance for {model_name}/{metric}: {str(e)}\")\n",
    "                    plt.close()\n",
    "\n",
    "    def plot_pvalue_heatmap(self, save_path=\"visualizations/\") -> None:\n",
    "        \"\"\"\n",
    "        Creates a heatmap visualization of p-values across methods and metrics.\n",
    "        \n",
    "        Args:\n",
    "            save_path: Directory to save visualizations\n",
    "        \"\"\"\n",
    "        if not os.path.exists(save_path):\n",
    "            os.makedirs(save_path)\n",
    "        \n",
    "        for model_name in self.statistical_test_results:\n",
    "            try:\n",
    "                metrics = list(self.statistical_test_results[model_name].keys())\n",
    "                \n",
    "                if not metrics:\n",
    "                    continue\n",
    "                    \n",
    "                all_methods = set()\n",
    "                for metric in metrics:\n",
    "                    all_methods.update(self.statistical_test_results[model_name][metric].keys())\n",
    "                all_methods = sorted(list(all_methods))\n",
    "                \n",
    "                if not all_methods:\n",
    "                    continue\n",
    "                \n",
    "                heatmap_data = np.zeros((len(metrics), len(all_methods)))\n",
    "                annot_data = np.empty((len(metrics), len(all_methods)), dtype=object)\n",
    "                \n",
    "                for i, metric in enumerate(metrics):\n",
    "                    for j, method in enumerate(all_methods):\n",
    "                        if method in self.statistical_test_results[model_name][metric]:\n",
    "                            p_value = self.statistical_test_results[model_name][metric][method]['p_value']\n",
    "                            \n",
    "                            p_value = p_value if not np.isnan(p_value) else 1.0\n",
    "                            \n",
    "                            heatmap_data[i, j] = p_value\n",
    "                            \n",
    "                            annot_data[i, j] = f\"{p_value:.3f}\"\n",
    "                            if p_value < 0.05:\n",
    "                                annot_data[i, j] += \"*\"\n",
    "                            if p_value < 0.01:\n",
    "                                annot_data[i, j] += \"*\"\n",
    "                        else:\n",
    "                            heatmap_data[i, j] = 1.0  # Max p-value for missing data\n",
    "                            annot_data[i, j] = \"N/A\"\n",
    "                \n",
    "                plt.figure(figsize=(12, max(6, len(metrics) * 0.8)))\n",
    "                \n",
    "                cmap = plt.cm.YlGnBu_r\n",
    "                \n",
    "                ax = sns.heatmap(\n",
    "                    heatmap_data,\n",
    "                    annot=annot_data,\n",
    "                    fmt=\"\",\n",
    "                    cmap=cmap,\n",
    "                    vmin=0,\n",
    "                    vmax=0.1,\n",
    "                    linewidths=0.5,\n",
    "                    cbar_kws={'label': 'p-value'}\n",
    "                )\n",
    "                \n",
    "                cbar = ax.collections[0].colorbar\n",
    "                cbar.set_ticks([0, 0.01, 0.05, 0.1])\n",
    "                cbar.set_ticklabels(['0', '0.01', '0.05', '0.1'])\n",
    "                \n",
    "                plt.title(f'P-values Heatmap for {model_name}', fontsize=14)\n",
    "                plt.yticks(np.arange(len(metrics)) + 0.5, metrics, rotation=0)\n",
    "                plt.xticks(np.arange(len(all_methods)) + 0.5, all_methods, rotation=45, ha='right')\n",
    "                \n",
    "                plt.tight_layout()\n",
    "                plt.savefig(f\"{save_path}pvalue_heatmap_{model_name}.png\", dpi=300, bbox_inches=\"tight\")\n",
    "                plt.close()\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error creating p-value heatmap for {model_name}: {str(e)}\")\n",
    "                plt.close()\n",
    "    \n",
    "    def save_results_to_csv(self, filename=\"normalization_results.csv\"):\n",
    "        \"\"\"\n",
    "        Save the results to a CSV file for further analysis.\n",
    "        \n",
    "        Args:\n",
    "            filename: Name of the CSV file\n",
    "        \"\"\"\n",
    "        rows = []\n",
    "        \n",
    "        for method in self.results:\n",
    "            for model in self.results[method]:\n",
    "                row = {\"Normalization\": method, \"Model\": model}\n",
    "                \n",
    "                for metric, value in self.results[method][model].items():\n",
    "                    if not metric.endswith(\"_std\") and not metric.endswith(\"_values\"):\n",
    "                        row[metric] = value\n",
    "                        if f\"{metric}_std\" in self.results[method][model]:\n",
    "                            row[f\"{metric}_std\"] = self.results[method][model][f\"{metric}_std\"]\n",
    "                \n",
    "                rows.append(row)\n",
    "        \n",
    "        df = pd.DataFrame(rows)\n",
    "        df.to_csv(filename, index=False)\n",
    "        print(f\"Results saved to {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Impact of Normalization Techniques with Statistical Significance Testing\n",
      "============================================================\n",
      "Using device: cuda\n",
      "\n",
      "==================================================\n",
      "NORMALIZATION TECHNIQUES COMPARISON WITH 10-FOLD CV\n",
      "==================================================\n",
      "Fetching OSEBX.OL data from 2014-01-01 to 2024-12-31...\n",
      "Data already downloaded. Loading from file...\n",
      "Engineering features (time-aware approach)...\n",
      "Features prepared: 1709 samples with 19 features\n",
      "Class distribution: {1: 0.5792861322410766, 0: 0.42071386775892333}\n",
      "Adding advanced features (time-aware approach)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-20 03:03:18,694] A new study created in memory with name: no-name-8a783415-d8d9-4ff0-af89-efd4600ecb05\n",
      "[I 2025-03-20 03:03:18,779] Trial 0 finished with value: 0.7378460000200813 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.013661178428178952, 'n_estimators': 456, 'num_leaves': 48, 'max_depth': 6, 'subsample': 0.7552942184455931, 'colsample_bytree': 0.7030385741204636, 'reg_alpha': 1.3087232248047334, 'reg_lambda': 0.6869757398160233, 'min_child_samples': 49}. Best is trial 0 with value: 0.7378460000200813.\n",
      "[I 2025-03-20 03:03:18,827] Trial 1 finished with value: 0.7430340219972068 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.06323892443630524, 'n_estimators': 282, 'num_leaves': 42, 'max_depth': 3, 'subsample': 0.9077831487751247, 'colsample_bytree': 0.6012684467021177, 'reg_alpha': 0.31439409038438626, 'reg_lambda': 1.0912521853098582, 'min_child_samples': 47}. Best is trial 1 with value: 0.7430340219972068.\n",
      "[I 2025-03-20 03:03:18,877] Trial 2 finished with value: 0.7581315066232281 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.019957907467756848, 'n_estimators': 199, 'num_leaves': 37, 'max_depth': 10, 'subsample': 0.7873081624297713, 'colsample_bytree': 0.6493149518105418, 'reg_alpha': 3.6000609130029044, 'reg_lambda': 4.050134848257446, 'min_child_samples': 21}. Best is trial 2 with value: 0.7581315066232281.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running 10-fold cross-validation\n",
      "Creating 10 time series splits with gap=5\n",
      "Fold 1: train=153, test=155, gap=5 days\n",
      "Fold 2: train=308, test=155, gap=5 days\n",
      "Fold 3: train=463, test=155, gap=5 days\n",
      "Fold 4: train=618, test=155, gap=5 days\n",
      "Fold 5: train=773, test=155, gap=5 days\n",
      "Fold 6: train=928, test=155, gap=5 days\n",
      "Fold 7: train=1083, test=155, gap=5 days\n",
      "Fold 8: train=1238, test=155, gap=5 days\n",
      "Fold 9: train=1393, test=155, gap=5 days\n",
      "Fold 10: train=1548, test=155, gap=5 days\n",
      "\n",
      "Optimizing LightGBM and LSTM parameters for baseline method...\n",
      "\n",
      "Optimizing LightGBM for fold 1 using min_max normalization\n",
      "Optimizing LightGBM hyperparameters with CV...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-20 03:03:18,925] Trial 3 finished with value: 0.794725944849784 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.03308671790989007, 'n_estimators': 162, 'num_leaves': 10, 'max_depth': 5, 'subsample': 0.9963593754983149, 'colsample_bytree': 0.805256515122397, 'reg_alpha': 3.0841806167907238, 'reg_lambda': 0.1301677362213169, 'min_child_samples': 21}. Best is trial 3 with value: 0.794725944849784.\n",
      "[I 2025-03-20 03:03:18,999] Trial 4 finished with value: 0.7910122485088833 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.029437387715603364, 'n_estimators': 405, 'num_leaves': 47, 'max_depth': 6, 'subsample': 0.9716350708762611, 'colsample_bytree': 0.7998448041733087, 'reg_alpha': 2.304933318498776, 'reg_lambda': 3.3362817514757888, 'min_child_samples': 29}. Best is trial 3 with value: 0.794725944849784.\n",
      "[I 2025-03-20 03:03:19,046] Trial 5 finished with value: 0.7843851075339163 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.07045793365915588, 'n_estimators': 210, 'num_leaves': 23, 'max_depth': 3, 'subsample': 0.8092590874861125, 'colsample_bytree': 0.859403208540551, 'reg_alpha': 3.3760828530802196, 'reg_lambda': 0.15012918259918107, 'min_child_samples': 22}. Best is trial 3 with value: 0.794725944849784.\n",
      "[I 2025-03-20 03:03:19,146] Trial 6 finished with value: 0.7922073162849176 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.011970252710206382, 'n_estimators': 476, 'num_leaves': 49, 'max_depth': 4, 'subsample': 0.9816084577717837, 'colsample_bytree': 0.7776193095921519, 'reg_alpha': 0.2802529145561249, 'reg_lambda': 1.3744727196612017, 'min_child_samples': 25}. Best is trial 3 with value: 0.794725944849784.\n",
      "[I 2025-03-20 03:03:19,211] Trial 7 finished with value: 0.8081467448959708 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.0967088301559984, 'n_estimators': 367, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.6725825297010686, 'colsample_bytree': 0.7765487989776441, 'reg_alpha': 1.3901311581414446, 'reg_lambda': 1.2894120399825089, 'min_child_samples': 25}. Best is trial 7 with value: 0.8081467448959708.\n",
      "[I 2025-03-20 03:03:19,275] Trial 8 finished with value: 0.7482635311249526 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.04669085237595252, 'n_estimators': 388, 'num_leaves': 42, 'max_depth': 5, 'subsample': 0.6388242673991037, 'colsample_bytree': 0.9337670455562896, 'reg_alpha': 0.11037032003620384, 'reg_lambda': 0.25448376172072, 'min_child_samples': 45}. Best is trial 7 with value: 0.8081467448959708.\n",
      "[I 2025-03-20 03:03:19,337] Trial 9 finished with value: 0.8122517234638652 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.011232085595448875, 'n_estimators': 177, 'num_leaves': 29, 'max_depth': 4, 'subsample': 0.7436406503252848, 'colsample_bytree': 0.6580654068535353, 'reg_alpha': 0.1699984374960256, 'reg_lambda': 0.1466016632681982, 'min_child_samples': 16}. Best is trial 9 with value: 0.8122517234638652.\n",
      "[I 2025-03-20 03:03:19,403] Trial 10 finished with value: 0.8310803885171231 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.010203239368765429, 'n_estimators': 107, 'num_leaves': 25, 'max_depth': 8, 'subsample': 0.7069078546074001, 'colsample_bytree': 0.6908092364947312, 'reg_alpha': 0.10041221396969888, 'reg_lambda': 0.3643418906227222, 'min_child_samples': 13}. Best is trial 10 with value: 0.8310803885171231.\n",
      "[I 2025-03-20 03:03:19,473] Trial 11 finished with value: 0.8309437672750366 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.010584247001202422, 'n_estimators': 105, 'num_leaves': 24, 'max_depth': 8, 'subsample': 0.7139880178778377, 'colsample_bytree': 0.6972493226467112, 'reg_alpha': 0.10851898378714334, 'reg_lambda': 0.3893436068121292, 'min_child_samples': 11}. Best is trial 10 with value: 0.8310803885171231.\n",
      "[I 2025-03-20 03:03:19,544] Trial 12 finished with value: 0.8515415388443387 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.018163303910654047, 'n_estimators': 100, 'num_leaves': 20, 'max_depth': 8, 'subsample': 0.6970181089776377, 'colsample_bytree': 0.7277729906866098, 'reg_alpha': 0.4890443135321556, 'reg_lambda': 0.3732270949355206, 'min_child_samples': 11}. Best is trial 12 with value: 0.8515415388443387.\n",
      "[I 2025-03-20 03:03:19,618] Trial 13 finished with value: 0.8444035109683246 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.01799896736950928, 'n_estimators': 121, 'num_leaves': 15, 'max_depth': 8, 'subsample': 0.6099175615913681, 'colsample_bytree': 0.7327796917902567, 'reg_alpha': 0.624621297496924, 'reg_lambda': 0.39942926719139454, 'min_child_samples': 10}. Best is trial 12 with value: 0.8515415388443387.\n",
      "[I 2025-03-20 03:03:19,689] Trial 14 finished with value: 0.7844036419675806 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.01875701063732107, 'n_estimators': 242, 'num_leaves': 14, 'max_depth': 8, 'subsample': 0.6026801984668724, 'colsample_bytree': 0.7476580045414775, 'reg_alpha': 0.5675326694633099, 'reg_lambda': 0.6549068695379046, 'min_child_samples': 35}. Best is trial 12 with value: 0.8515415388443387.\n",
      "[I 2025-03-20 03:03:19,763] Trial 15 finished with value: 0.809636157802802 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.018174221903841048, 'n_estimators': 151, 'num_leaves': 17, 'max_depth': 9, 'subsample': 0.6181855746593979, 'colsample_bytree': 0.9760821659339693, 'reg_alpha': 0.6274503046638632, 'reg_lambda': 0.27290575213336515, 'min_child_samples': 16}. Best is trial 12 with value: 0.8515415388443387.\n",
      "[I 2025-03-20 03:03:19,888] Trial 16 finished with value: 0.8560592733196717 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.026164906063309068, 'n_estimators': 314, 'num_leaves': 18, 'max_depth': 7, 'subsample': 0.6651795192374913, 'colsample_bytree': 0.8878755698081912, 'reg_alpha': 1.083173784109097, 'reg_lambda': 0.5039561408129002, 'min_child_samples': 10}. Best is trial 16 with value: 0.8560592733196717.\n",
      "[I 2025-03-20 03:03:19,967] Trial 17 finished with value: 0.7870421379894392 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.02760123638415903, 'n_estimators': 328, 'num_leaves': 20, 'max_depth': 7, 'subsample': 0.8449841175070596, 'colsample_bytree': 0.880382983683888, 'reg_alpha': 1.126088505655428, 'reg_lambda': 0.830339347517797, 'min_child_samples': 37}. Best is trial 16 with value: 0.8560592733196717.\n",
      "[I 2025-03-20 03:03:20,069] Trial 18 finished with value: 0.8421886830134913 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.03946372513140026, 'n_estimators': 271, 'num_leaves': 34, 'max_depth': 7, 'subsample': 0.6772470431951765, 'colsample_bytree': 0.85917610767415, 'reg_alpha': 0.3463453486394099, 'reg_lambda': 2.0700082233542947, 'min_child_samples': 16}. Best is trial 16 with value: 0.8560592733196717.\n",
      "[I 2025-03-20 03:03:20,136] Trial 19 finished with value: 0.7645179345041372 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.023573663264591257, 'n_estimators': 318, 'num_leaves': 10, 'max_depth': 9, 'subsample': 0.667362922000207, 'colsample_bytree': 0.9113301919306592, 'reg_alpha': 0.9320380371960342, 'reg_lambda': 0.2099867860913448, 'min_child_samples': 40}. Best is trial 16 with value: 0.8560592733196717.\n",
      "[I 2025-03-20 03:03:20,210] Trial 20 finished with value: 0.8013418967625455 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.015339980850650834, 'n_estimators': 237, 'num_leaves': 29, 'max_depth': 7, 'subsample': 0.8448191737030581, 'colsample_bytree': 0.992827399172982, 'reg_alpha': 1.7131737805393947, 'reg_lambda': 0.4686483013442848, 'min_child_samples': 31}. Best is trial 16 with value: 0.8560592733196717.\n",
      "[I 2025-03-20 03:03:20,294] Trial 21 finished with value: 0.857550924980256 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.02354322019202556, 'n_estimators': 140, 'num_leaves': 15, 'max_depth': 9, 'subsample': 0.6392392740398731, 'colsample_bytree': 0.7472105296614974, 'reg_alpha': 0.47030520300856754, 'reg_lambda': 0.500293696538067, 'min_child_samples': 10}. Best is trial 21 with value: 0.857550924980256.\n",
      "[I 2025-03-20 03:03:20,371] Trial 22 finished with value: 0.8314581833117302 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.023910810212014657, 'n_estimators': 145, 'num_leaves': 19, 'max_depth': 9, 'subsample': 0.6508687513980185, 'colsample_bytree': 0.8184397284830398, 'reg_alpha': 0.8294586440540981, 'reg_lambda': 0.544573162851502, 'min_child_samples': 14}. Best is trial 21 with value: 0.857550924980256.\n",
      "[I 2025-03-20 03:03:20,539] Trial 23 finished with value: 0.8819194897398559 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.03444159246436669, 'n_estimators': 352, 'num_leaves': 13, 'max_depth': 9, 'subsample': 0.724476370879777, 'colsample_bytree': 0.7439592921420766, 'reg_alpha': 0.4207815438686873, 'reg_lambda': 0.8207706648796971, 'min_child_samples': 10}. Best is trial 23 with value: 0.8819194897398559.\n",
      "[I 2025-03-20 03:03:20,668] Trial 24 finished with value: 0.8436106469919903 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.037874040143961084, 'n_estimators': 346, 'num_leaves': 14, 'max_depth': 10, 'subsample': 0.7344067234607558, 'colsample_bytree': 0.8333961163683786, 'reg_alpha': 0.44663981356432536, 'reg_lambda': 1.0133035355376856, 'min_child_samples': 18}. Best is trial 23 with value: 0.8819194897398559.\n",
      "[I 2025-03-20 03:03:20,824] Trial 25 finished with value: 0.8694762398726594 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.04810088997815246, 'n_estimators': 419, 'num_leaves': 12, 'max_depth': 9, 'subsample': 0.7697432328779531, 'colsample_bytree': 0.7713549723689853, 'reg_alpha': 0.2124799261404179, 'reg_lambda': 2.0935775675288655, 'min_child_samples': 13}. Best is trial 23 with value: 0.8819194897398559.\n",
      "[I 2025-03-20 03:03:20,951] Trial 26 finished with value: 0.8500716636528993 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.05454565254072128, 'n_estimators': 416, 'num_leaves': 11, 'max_depth': 9, 'subsample': 0.7760286701775468, 'colsample_bytree': 0.7583695159613084, 'reg_alpha': 0.2024298627320363, 'reg_lambda': 2.0630458023901515, 'min_child_samples': 19}. Best is trial 23 with value: 0.8819194897398559.\n",
      "[I 2025-03-20 03:03:21,112] Trial 27 finished with value: 0.8762306085801846 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.045050481503938665, 'n_estimators': 435, 'num_leaves': 13, 'max_depth': 10, 'subsample': 0.8225860826658231, 'colsample_bytree': 0.6607846922043091, 'reg_alpha': 0.21260290231685255, 'reg_lambda': 1.796423624311662, 'min_child_samples': 14}. Best is trial 23 with value: 0.8819194897398559.\n",
      "[I 2025-03-20 03:03:21,279] Trial 28 finished with value: 0.8683003183831021 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.0464238227176156, 'n_estimators': 497, 'num_leaves': 11, 'max_depth': 10, 'subsample': 0.8317896608315682, 'colsample_bytree': 0.6060633406459508, 'reg_alpha': 0.18103550837089294, 'reg_lambda': 2.2260907675565504, 'min_child_samples': 14}. Best is trial 23 with value: 0.8819194897398559.\n",
      "[I 2025-03-20 03:03:21,394] Trial 29 finished with value: 0.8463304653124952 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.08707673066717547, 'n_estimators': 431, 'num_leaves': 14, 'max_depth': 10, 'subsample': 0.8721814093671049, 'colsample_bytree': 0.6638443498170109, 'reg_alpha': 0.26214348960623823, 'reg_lambda': 2.4410017047147567, 'min_child_samples': 24}. Best is trial 23 with value: 0.8819194897398559.\n",
      "[I 2025-03-20 03:03:21,499] Trial 30 finished with value: 0.8167918682251027 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.035415298285062354, 'n_estimators': 458, 'num_leaves': 22, 'max_depth': 9, 'subsample': 0.7697720387073888, 'colsample_bytree': 0.710645781605167, 'reg_alpha': 0.14289075870846413, 'reg_lambda': 1.5877166901531197, 'min_child_samples': 28}. Best is trial 23 with value: 0.8819194897398559.\n",
      "[I 2025-03-20 03:03:21,662] Trial 31 finished with value: 0.8758917103670771 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.04759123429765386, 'n_estimators': 491, 'num_leaves': 12, 'max_depth': 10, 'subsample': 0.8159005614373748, 'colsample_bytree': 0.6034320832099629, 'reg_alpha': 0.21941500726068927, 'reg_lambda': 3.2621553273160755, 'min_child_samples': 13}. Best is trial 23 with value: 0.8819194897398559.\n",
      "[I 2025-03-20 03:03:21,789] Trial 32 finished with value: 0.8438683366483206 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.04520556568032182, 'n_estimators': 431, 'num_leaves': 13, 'max_depth': 10, 'subsample': 0.8981375155566447, 'colsample_bytree': 0.625456395811495, 'reg_alpha': 0.2377287998021623, 'reg_lambda': 4.971620359316415, 'min_child_samples': 18}. Best is trial 23 with value: 0.8819194897398559.\n",
      "[I 2025-03-20 03:03:21,966] Trial 33 finished with value: 0.877724280923904 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.06632997647757997, 'n_estimators': 499, 'num_leaves': 17, 'max_depth': 10, 'subsample': 0.8170820902015196, 'colsample_bytree': 0.6329141666142772, 'reg_alpha': 0.36288345442122394, 'reg_lambda': 3.0723675209216013, 'min_child_samples': 13}. Best is trial 23 with value: 0.8819194897398559.\n",
      "[I 2025-03-20 03:03:22,142] Trial 34 finished with value: 0.8806520970392284 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.06274323226881068, 'n_estimators': 492, 'num_leaves': 17, 'max_depth': 10, 'subsample': 0.8167439528673417, 'colsample_bytree': 0.6324958383148344, 'reg_alpha': 0.3573796670350799, 'reg_lambda': 2.999822097073425, 'min_child_samples': 13}. Best is trial 23 with value: 0.8819194897398559.\n",
      "[I 2025-03-20 03:03:22,286] Trial 35 finished with value: 0.8498881242820534 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.06931601657954174, 'n_estimators': 455, 'num_leaves': 26, 'max_depth': 10, 'subsample': 0.8655932549503513, 'colsample_bytree': 0.6352121521724019, 'reg_alpha': 0.3636189291121942, 'reg_lambda': 3.2639918445042615, 'min_child_samples': 19}. Best is trial 23 with value: 0.8819194897398559.\n",
      "[I 2025-03-20 03:03:22,441] Trial 36 finished with value: 0.8730413830571994 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.06648813531980188, 'n_estimators': 460, 'num_leaves': 17, 'max_depth': 10, 'subsample': 0.9352537077446509, 'colsample_bytree': 0.681225985220998, 'reg_alpha': 0.37606797219017285, 'reg_lambda': 2.8076232699797936, 'min_child_samples': 16}. Best is trial 23 with value: 0.8819194897398559.\n",
      "[I 2025-03-20 03:03:22,552] Trial 37 finished with value: 0.8382145554450038 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.05879000044772112, 'n_estimators': 379, 'num_leaves': 21, 'max_depth': 9, 'subsample': 0.7900557414112253, 'colsample_bytree': 0.6393489707583409, 'reg_alpha': 0.14655697487111677, 'reg_lambda': 4.337658805945365, 'min_child_samples': 21}. Best is trial 23 with value: 0.8819194897398559.\n",
      "[I 2025-03-20 03:03:22,706] Trial 38 finished with value: 0.8865656011328376 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.0819032584475924, 'n_estimators': 500, 'num_leaves': 17, 'max_depth': 10, 'subsample': 0.8037845297098607, 'colsample_bytree': 0.6626220662335015, 'reg_alpha': 0.3014158656716065, 'reg_lambda': 1.633537839062495, 'min_child_samples': 12}. Best is trial 38 with value: 0.8865656011328376.\n",
      "[I 2025-03-20 03:03:22,830] Trial 39 finished with value: 0.8453411416734206 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.08344905254004688, 'n_estimators': 476, 'num_leaves': 27, 'max_depth': 6, 'subsample': 0.7953684251544864, 'colsample_bytree': 0.6766468190153823, 'reg_alpha': 0.3028751941079663, 'reg_lambda': 1.0153628555884582, 'min_child_samples': 23}. Best is trial 38 with value: 0.8865656011328376.\n",
      "[I 2025-03-20 03:03:22,966] Trial 40 finished with value: 0.869995195386567 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.07966697273110204, 'n_estimators': 478, 'num_leaves': 33, 'max_depth': 9, 'subsample': 0.7522260025542231, 'colsample_bytree': 0.6253755412400629, 'reg_alpha': 0.4114324905799834, 'reg_lambda': 1.3084385369734954, 'min_child_samples': 12}. Best is trial 38 with value: 0.8865656011328376.\n",
      "[I 2025-03-20 03:03:23,121] Trial 41 finished with value: 0.8657857884476542 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.05833743939878031, 'n_estimators': 449, 'num_leaves': 17, 'max_depth': 10, 'subsample': 0.8168252701182619, 'colsample_bytree': 0.6571418152017943, 'reg_alpha': 0.28113322431787124, 'reg_lambda': 1.69043149807438, 'min_child_samples': 15}. Best is trial 38 with value: 0.8865656011328376.\n",
      "[I 2025-03-20 03:03:23,255] Trial 42 finished with value: 0.8816194834016884 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.09836367034268784, 'n_estimators': 497, 'num_leaves': 16, 'max_depth': 10, 'subsample': 0.8726022560498711, 'colsample_bytree': 0.7131265863776833, 'reg_alpha': 0.32286093229719315, 'reg_lambda': 1.7294285313962876, 'min_child_samples': 12}. Best is trial 38 with value: 0.8865656011328376.\n",
      "[I 2025-03-20 03:03:23,418] Trial 43 finished with value: 0.8759384849457538 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.0941196119937379, 'n_estimators': 495, 'num_leaves': 23, 'max_depth': 10, 'subsample': 0.9063231328921306, 'colsample_bytree': 0.7115808269945066, 'reg_alpha': 0.32221063650496173, 'reg_lambda': 2.717489964889958, 'min_child_samples': 12}. Best is trial 38 with value: 0.8865656011328376.\n",
      "[I 2025-03-20 03:03:23,492] Trial 44 finished with value: 0.7600580373769901 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.07547149216750576, 'n_estimators': 394, 'num_leaves': 16, 'max_depth': 9, 'subsample': 0.879865429553862, 'colsample_bytree': 0.6785726667435138, 'reg_alpha': 4.673879544484267, 'reg_lambda': 3.959186500785523, 'min_child_samples': 17}. Best is trial 38 with value: 0.8865656011328376.\n",
      "[I 2025-03-20 03:03:23,594] Trial 45 finished with value: 0.879409828740829 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.09939966797035898, 'n_estimators': 478, 'num_leaves': 19, 'max_depth': 10, 'subsample': 0.8479500645935099, 'colsample_bytree': 0.7141588822222109, 'reg_alpha': 0.5392293731261125, 'reg_lambda': 0.8150907449372574, 'min_child_samples': 10}. Best is trial 38 with value: 0.8865656011328376.\n",
      "[I 2025-03-20 03:03:23,688] Trial 46 finished with value: 0.8782692252782439 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.09953910254815977, 'n_estimators': 472, 'num_leaves': 42, 'max_depth': 8, 'subsample': 0.9352042099420312, 'colsample_bytree': 0.7141866827010958, 'reg_alpha': 0.7526764697380042, 'reg_lambda': 0.7653566860796237, 'min_child_samples': 10}. Best is trial 38 with value: 0.8865656011328376.\n",
      "[I 2025-03-20 03:03:23,765] Trial 47 finished with value: 0.7438869746263069 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.09173465005263216, 'n_estimators': 355, 'num_leaves': 20, 'max_depth': 5, 'subsample': 0.8561496698204991, 'colsample_bytree': 0.7306416759144715, 'reg_alpha': 0.4847590116196665, 'reg_lambda': 1.1578458953158761, 'min_child_samples': 46}. Best is trial 38 with value: 0.8865656011328376.\n",
      "[I 2025-03-20 03:03:23,846] Trial 48 finished with value: 0.7514018685357359 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.07535698407234766, 'n_estimators': 444, 'num_leaves': 19, 'max_depth': 10, 'subsample': 0.8917715635988317, 'colsample_bytree': 0.7932124922710738, 'reg_alpha': 0.5728316932224936, 'reg_lambda': 0.9146734889774805, 'min_child_samples': 49}. Best is trial 38 with value: 0.8865656011328376.\n",
      "[I 2025-03-20 03:03:23,946] Trial 49 finished with value: 0.8408901203341909 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.08539311531899803, 'n_estimators': 280, 'num_leaves': 22, 'max_depth': 9, 'subsample': 0.844957223260667, 'colsample_bytree': 0.6969123895120719, 'reg_alpha': 0.6794394059062948, 'reg_lambda': 1.4672482030664549, 'min_child_samples': 20}. Best is trial 38 with value: 0.8865656011328376.\n",
      "[I 2025-03-20 03:03:23,986] A new study created in memory with name: no-name-ced9b34d-43a2-40da-81cb-13a0ca950bde\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best LightGBM Parameters:\n",
      "  boosting_type: gbdt\n",
      "  learning_rate: 0.0819032584475924\n",
      "  n_estimators: 500\n",
      "  num_leaves: 17\n",
      "  max_depth: 10\n",
      "  subsample: 0.8037845297098607\n",
      "  colsample_bytree: 0.6626220662335015\n",
      "  reg_alpha: 0.3014158656716065\n",
      "  reg_lambda: 1.633537839062495\n",
      "  min_child_samples: 12\n",
      "\n",
      "Optimizing LSTM for fold 1 using min_max normalization\n",
      "Created LSTM sequences with lookback=10: 143 train, 145 test\n",
      "Optimizing LSTM hyperparameters with CV...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-20 03:03:27,748] Trial 0 finished with value: 0.893012894705603 and parameters: {'hidden_dim': 45, 'dropout': 0.4551406810921512, 'learning_rate': 0.007331811314274292, 'batch_size': 16, 'weight_decay': 2.064121088592392e-05}. Best is trial 0 with value: 0.893012894705603.\n",
      "[I 2025-03-20 03:03:29,725] Trial 1 finished with value: 0.8873530645666062 and parameters: {'hidden_dim': 79, 'dropout': 0.48569536770002286, 'learning_rate': 0.003999161563860724, 'batch_size': 32, 'weight_decay': 3.45872269711161e-05}. Best is trial 0 with value: 0.893012894705603.\n",
      "[I 2025-03-20 03:03:33,402] Trial 2 finished with value: 0.8751796139816973 and parameters: {'hidden_dim': 32, 'dropout': 0.21712375681979076, 'learning_rate': 0.0016665895921660098, 'batch_size': 16, 'weight_decay': 2.1517123363927774e-05}. Best is trial 0 with value: 0.893012894705603.\n",
      "[I 2025-03-20 03:03:35,317] Trial 3 finished with value: 0.7428306502525253 and parameters: {'hidden_dim': 127, 'dropout': 0.2873081624297713, 'learning_rate': 0.00017643094449433023, 'batch_size': 32, 'weight_decay': 1.0947309020486406e-05}. Best is trial 0 with value: 0.893012894705603.\n",
      "[I 2025-03-20 03:03:39,282] Trial 4 finished with value: 0.8414523844211343 and parameters: {'hidden_dim': 47, 'dropout': 0.10585094112968818, 'learning_rate': 0.0004451295365396247, 'batch_size': 16, 'weight_decay': 1.3639281514957935e-06}. Best is trial 0 with value: 0.893012894705603.\n",
      "[I 2025-03-20 03:03:40,724] Trial 5 finished with value: 0.9087774783087283 and parameters: {'hidden_dim': 59, 'dropout': 0.2875597071705984, 'learning_rate': 0.0033384615669657483, 'batch_size': 64, 'weight_decay': 9.98214837316597e-06}. Best is trial 5 with value: 0.9087774783087283.\n",
      "[I 2025-03-20 03:03:47,613] Trial 6 finished with value: 0.8788922882672883 and parameters: {'hidden_dim': 109, 'dropout': 0.4586320455614753, 'learning_rate': 0.0009209968619749436, 'batch_size': 16, 'weight_decay': 1.6223673683559225e-06}. Best is trial 5 with value: 0.9087774783087283.\n",
      "[I 2025-03-20 03:03:49,482] Trial 7 finished with value: 0.8717847208732626 and parameters: {'hidden_dim': 82, 'dropout': 0.3594032085405511, 'learning_rate': 0.006298297451196278, 'batch_size': 32, 'weight_decay': 7.511737052942637e-05}. Best is trial 5 with value: 0.9087774783087283.\n",
      "[I 2025-03-20 03:03:50,779] Trial 8 finished with value: 0.8440601932789433 and parameters: {'hidden_dim': 125, 'dropout': 0.17649687394806254, 'learning_rate': 0.00809174687672524, 'batch_size': 64, 'weight_decay': 5.656354626844694e-06}. Best is trial 5 with value: 0.9087774783087283.\n",
      "[I 2025-03-20 03:03:54,499] Trial 9 finished with value: 0.82740374498187 and parameters: {'hidden_dim': 127, 'dropout': 0.3668293205677101, 'learning_rate': 0.009614679235250567, 'batch_size': 16, 'weight_decay': 2.2160868002868673e-05}. Best is trial 5 with value: 0.9087774783087283.\n",
      "[I 2025-03-20 03:03:55,785] Trial 10 finished with value: 0.8952415109967194 and parameters: {'hidden_dim': 68, 'dropout': 0.2783115442415032, 'learning_rate': 0.0020861108338934425, 'batch_size': 64, 'weight_decay': 4.712885048357283e-06}. Best is trial 5 with value: 0.9087774783087283.\n",
      "[I 2025-03-20 03:03:57,185] Trial 11 finished with value: 0.8841257459747044 and parameters: {'hidden_dim': 69, 'dropout': 0.2839268982313757, 'learning_rate': 0.0019222890575082043, 'batch_size': 64, 'weight_decay': 4.899133576690419e-06}. Best is trial 5 with value: 0.9087774783087283.\n",
      "[I 2025-03-20 03:03:58,527] Trial 12 finished with value: 0.8861641252266251 and parameters: {'hidden_dim': 64, 'dropout': 0.22885194066795841, 'learning_rate': 0.0026587501928706167, 'batch_size': 64, 'weight_decay': 3.460656555538206e-06}. Best is trial 5 with value: 0.9087774783087283.\n",
      "[I 2025-03-20 03:03:59,938] Trial 13 finished with value: 0.8516579726215143 and parameters: {'hidden_dim': 97, 'dropout': 0.355353283883613, 'learning_rate': 0.0008030291804136277, 'batch_size': 64, 'weight_decay': 1.0840506859901975e-05}. Best is trial 5 with value: 0.9087774783087283.\n",
      "[I 2025-03-20 03:04:01,336] Trial 14 finished with value: 0.8826828649745316 and parameters: {'hidden_dim': 55, 'dropout': 0.31653470353178464, 'learning_rate': 0.0033529860098850885, 'batch_size': 64, 'weight_decay': 3.0743961693868685e-06}. Best is trial 5 with value: 0.9087774783087283.\n",
      "[I 2025-03-20 03:04:02,834] Trial 15 finished with value: 0.7798931489035655 and parameters: {'hidden_dim': 84, 'dropout': 0.23443397896592474, 'learning_rate': 0.0003543779292407648, 'batch_size': 64, 'weight_decay': 8.73103087669017e-06}. Best is trial 5 with value: 0.9087774783087283.\n",
      "[I 2025-03-20 03:04:04,224] Trial 16 finished with value: 0.8663385322239489 and parameters: {'hidden_dim': 67, 'dropout': 0.4073530676872772, 'learning_rate': 0.0016532604402274915, 'batch_size': 64, 'weight_decay': 2.422514320377802e-06}. Best is trial 5 with value: 0.9087774783087283.\n",
      "[I 2025-03-20 03:04:05,631] Trial 17 finished with value: 0.8886194004683589 and parameters: {'hidden_dim': 32, 'dropout': 0.13580248957982521, 'learning_rate': 0.00472778532989426, 'batch_size': 64, 'weight_decay': 5.670885701167959e-06}. Best is trial 5 with value: 0.9087774783087283.\n",
      "[I 2025-03-20 03:04:06,967] Trial 18 finished with value: 0.7816689531533281 and parameters: {'hidden_dim': 95, 'dropout': 0.26605777678480524, 'learning_rate': 0.0005307863900589909, 'batch_size': 64, 'weight_decay': 4.997557883497495e-05}. Best is trial 5 with value: 0.9087774783087283.\n",
      "[I 2025-03-20 03:04:08,348] Trial 19 finished with value: 0.6797915722394889 and parameters: {'hidden_dim': 55, 'dropout': 0.327392532265835, 'learning_rate': 0.00011600174401008022, 'batch_size': 64, 'weight_decay': 1.333031756030595e-05}. Best is trial 5 with value: 0.9087774783087283.\n",
      "[I 2025-03-20 03:04:10,235] Trial 20 finished with value: 0.882898934591643 and parameters: {'hidden_dim': 72, 'dropout': 0.18156862119423717, 'learning_rate': 0.0025297901087907022, 'batch_size': 32, 'weight_decay': 1.1290921652220012e-06}. Best is trial 5 with value: 0.9087774783087283.\n",
      "[I 2025-03-20 03:04:13,955] Trial 21 finished with value: 0.8523172092182509 and parameters: {'hidden_dim': 49, 'dropout': 0.3904290136968126, 'learning_rate': 0.005265328934102206, 'batch_size': 16, 'weight_decay': 1.8978753623238552e-05}. Best is trial 5 with value: 0.9087774783087283.\n",
      "[I 2025-03-20 03:04:20,819] Trial 22 finished with value: 0.9103519503259087 and parameters: {'hidden_dim': 43, 'dropout': 0.42649110230530074, 'learning_rate': 0.00132963949040977, 'batch_size': 16, 'weight_decay': 3.6891387241329175e-05}. Best is trial 22 with value: 0.9103519503259087.\n",
      "[I 2025-03-20 03:04:24,607] Trial 23 finished with value: 0.8648902216610549 and parameters: {'hidden_dim': 59, 'dropout': 0.25681776019818714, 'learning_rate': 0.0013374201487084808, 'batch_size': 16, 'weight_decay': 9.527475608374498e-05}. Best is trial 22 with value: 0.9103519503259087.\n",
      "[I 2025-03-20 03:04:25,992] Trial 24 finished with value: 0.8130240033885867 and parameters: {'hidden_dim': 45, 'dropout': 0.4153266668706781, 'learning_rate': 0.0011427880726981286, 'batch_size': 64, 'weight_decay': 7.988124851344944e-06}. Best is trial 22 with value: 0.9103519503259087.\n",
      "[I 2025-03-20 03:04:29,736] Trial 25 finished with value: 0.8935276914443581 and parameters: {'hidden_dim': 42, 'dropout': 0.31829349965704995, 'learning_rate': 0.002552635490016211, 'batch_size': 16, 'weight_decay': 3.645766319861453e-05}. Best is trial 22 with value: 0.9103519503259087.\n",
      "[I 2025-03-20 03:04:31,102] Trial 26 finished with value: 0.8201334593261677 and parameters: {'hidden_dim': 38, 'dropout': 0.18834136045019265, 'learning_rate': 0.0007046586419126022, 'batch_size': 64, 'weight_decay': 1.5156888260101681e-05}. Best is trial 22 with value: 0.9103519503259087.\n",
      "[I 2025-03-20 03:04:32,463] Trial 27 finished with value: 0.9135419701825951 and parameters: {'hidden_dim': 60, 'dropout': 0.3374763172906297, 'learning_rate': 0.0033997294158391186, 'batch_size': 64, 'weight_decay': 4.081574045055095e-06}. Best is trial 27 with value: 0.9135419701825951.\n",
      "[I 2025-03-20 03:04:34,359] Trial 28 finished with value: 0.8513907774324441 and parameters: {'hidden_dim': 60, 'dropout': 0.4338145565622533, 'learning_rate': 0.003336333296246742, 'batch_size': 32, 'weight_decay': 1.9113847598607556e-06}. Best is trial 27 with value: 0.9135419701825951.\n",
      "[I 2025-03-20 03:04:37,946] Trial 29 finished with value: 0.8250306551087802 and parameters: {'hidden_dim': 74, 'dropout': 0.4913476080831227, 'learning_rate': 0.006105566142656729, 'batch_size': 16, 'weight_decay': 3.425503815110053e-05}. Best is trial 27 with value: 0.9135419701825951.\n",
      "[I 2025-03-20 03:04:41,773] Trial 30 finished with value: 0.882620779105154 and parameters: {'hidden_dim': 53, 'dropout': 0.44626966017007064, 'learning_rate': 0.0012908757959236327, 'batch_size': 16, 'weight_decay': 7.79052918224446e-06}. Best is trial 27 with value: 0.9135419701825951.\n",
      "[I 2025-03-20 03:04:43,259] Trial 31 finished with value: 0.8488529121341623 and parameters: {'hidden_dim': 64, 'dropout': 0.3392775482589103, 'learning_rate': 0.0020558929841084897, 'batch_size': 64, 'weight_decay': 3.661398970924771e-06}. Best is trial 27 with value: 0.9135419701825951.\n",
      "[I 2025-03-20 03:04:44,605] Trial 32 finished with value: 0.8779572231395149 and parameters: {'hidden_dim': 77, 'dropout': 0.3832965152030622, 'learning_rate': 0.003304191450015509, 'batch_size': 64, 'weight_decay': 4.006072892268249e-06}. Best is trial 27 with value: 0.9135419701825951.\n",
      "[I 2025-03-20 03:04:45,872] Trial 33 finished with value: 0.8870735938444273 and parameters: {'hidden_dim': 39, 'dropout': 0.2991594311452422, 'learning_rate': 0.0014909196289027654, 'batch_size': 64, 'weight_decay': 6.693895075357755e-06}. Best is trial 27 with value: 0.9135419701825951.\n",
      "[I 2025-03-20 03:04:47,203] Trial 34 finished with value: 0.9102537797850297 and parameters: {'hidden_dim': 88, 'dropout': 0.2619023211904471, 'learning_rate': 0.0023230585981956096, 'batch_size': 64, 'weight_decay': 2.2491105744829932e-06}. Best is trial 27 with value: 0.9135419701825951.\n",
      "[I 2025-03-20 03:04:49,120] Trial 35 finished with value: 0.8736105715272382 and parameters: {'hidden_dim': 89, 'dropout': 0.25159243666676706, 'learning_rate': 0.0037061034280032237, 'batch_size': 32, 'weight_decay': 2.651253444642282e-06}. Best is trial 27 with value: 0.9135419701825951.\n",
      "[I 2025-03-20 03:04:55,905] Trial 36 finished with value: 0.8482168439199689 and parameters: {'hidden_dim': 98, 'dropout': 0.20876301043117906, 'learning_rate': 0.0042411615710725575, 'batch_size': 16, 'weight_decay': 2.0329341442470865e-06}. Best is trial 27 with value: 0.9135419701825951.\n",
      "[I 2025-03-20 03:04:57,234] Trial 37 finished with value: 0.8387131868902703 and parameters: {'hidden_dim': 106, 'dropout': 0.47447281896616345, 'learning_rate': 0.0010222687667330171, 'batch_size': 64, 'weight_decay': 1.0561186025576705e-06}. Best is trial 27 with value: 0.9135419701825951.\n",
      "[I 2025-03-20 03:04:59,069] Trial 38 finished with value: 0.8801489791073124 and parameters: {'hidden_dim': 49, 'dropout': 0.3022693214364958, 'learning_rate': 0.0026634673676071024, 'batch_size': 32, 'weight_decay': 1.5163299137417412e-06}. Best is trial 27 with value: 0.9135419701825951.\n",
      "[I 2025-03-20 03:05:02,635] Trial 39 finished with value: 0.8015815203315203 and parameters: {'hidden_dim': 86, 'dropout': 0.334871011699652, 'learning_rate': 0.0002650263504785184, 'batch_size': 16, 'weight_decay': 1.4284255767055812e-05}. Best is trial 27 with value: 0.9135419701825951.\n",
      "[I 2025-03-20 03:05:03,943] Trial 40 finished with value: 0.8568864729020979 and parameters: {'hidden_dim': 119, 'dropout': 0.14886626780745005, 'learning_rate': 0.007186323415869851, 'batch_size': 64, 'weight_decay': 2.6484189090236794e-05}. Best is trial 27 with value: 0.9135419701825951.\n",
      "[I 2025-03-20 03:05:05,232] Trial 41 finished with value: 0.8961203245057412 and parameters: {'hidden_dim': 79, 'dropout': 0.2819687776929019, 'learning_rate': 0.002063994426559537, 'batch_size': 64, 'weight_decay': 2.567230496044336e-06}. Best is trial 27 with value: 0.9135419701825951.\n",
      "[I 2025-03-20 03:05:06,511] Trial 42 finished with value: 0.8802839087995338 and parameters: {'hidden_dim': 77, 'dropout': 0.24363765569427026, 'learning_rate': 0.0018159115840847325, 'batch_size': 64, 'weight_decay': 2.314241522135545e-06}. Best is trial 27 with value: 0.9135419701825951.\n",
      "[I 2025-03-20 03:05:07,797] Trial 43 finished with value: 0.8650633269122853 and parameters: {'hidden_dim': 106, 'dropout': 0.28036114436733867, 'learning_rate': 0.0022631718413967795, 'batch_size': 64, 'weight_decay': 2.8464548681726037e-06}. Best is trial 27 with value: 0.9135419701825951.\n",
      "[I 2025-03-20 03:05:09,077] Trial 44 finished with value: 0.817279802566261 and parameters: {'hidden_dim': 91, 'dropout': 0.208794907436078, 'learning_rate': 0.0006387994220321746, 'batch_size': 64, 'weight_decay': 5.395025133715409e-05}. Best is trial 27 with value: 0.9135419701825951.\n",
      "[I 2025-03-20 03:05:10,346] Trial 45 finished with value: 0.8765243244409912 and parameters: {'hidden_dim': 60, 'dropout': 0.2982806533755087, 'learning_rate': 0.005330219014262644, 'batch_size': 64, 'weight_decay': 4.600654240742409e-06}. Best is trial 27 with value: 0.9135419701825951.\n",
      "[I 2025-03-20 03:05:11,636] Trial 46 finished with value: 0.8763474421026505 and parameters: {'hidden_dim': 83, 'dropout': 0.3539323941330506, 'learning_rate': 0.0028864313457387333, 'batch_size': 64, 'weight_decay': 1.7805680032566898e-06}. Best is trial 27 with value: 0.9135419701825951.\n",
      "[I 2025-03-20 03:05:15,186] Trial 47 finished with value: 0.8801147829793662 and parameters: {'hidden_dim': 80, 'dropout': 0.27174054791700286, 'learning_rate': 0.0009300913287780889, 'batch_size': 16, 'weight_decay': 1.2832221283815414e-06}. Best is trial 27 with value: 0.9135419701825951.\n",
      "[I 2025-03-20 03:05:16,474] Trial 48 finished with value: 0.8498833824354657 and parameters: {'hidden_dim': 32, 'dropout': 0.2257645687807629, 'learning_rate': 0.0017585377580497657, 'batch_size': 64, 'weight_decay': 5.925094996765664e-06}. Best is trial 27 with value: 0.9135419701825951.\n",
      "[I 2025-03-20 03:05:17,850] Trial 49 finished with value: 0.8328858834067168 and parameters: {'hidden_dim': 72, 'dropout': 0.30871698930040264, 'learning_rate': 0.009999511468230528, 'batch_size': 64, 'weight_decay': 3.181729509806631e-06}. Best is trial 27 with value: 0.9135419701825951.\n",
      "[I 2025-03-20 03:05:19,303] Trial 50 finished with value: 0.8533846410148493 and parameters: {'hidden_dim': 53, 'dropout': 0.374736777367904, 'learning_rate': 0.004295270910074104, 'batch_size': 64, 'weight_decay': 2.0455495762736433e-06}. Best is trial 27 with value: 0.9135419701825951.\n",
      "[I 2025-03-20 03:05:20,698] Trial 51 finished with value: 0.8883466745445912 and parameters: {'hidden_dim': 67, 'dropout': 0.2859310803904955, 'learning_rate': 0.0019740872306234884, 'batch_size': 64, 'weight_decay': 4.208226308566398e-06}. Best is trial 27 with value: 0.9135419701825951.\n",
      "[I 2025-03-20 03:05:22,064] Trial 52 finished with value: 0.8642447107290857 and parameters: {'hidden_dim': 64, 'dropout': 0.26697871913074167, 'learning_rate': 0.0014390402757564207, 'batch_size': 64, 'weight_decay': 9.915609810515822e-06}. Best is trial 27 with value: 0.9135419701825951.\n",
      "[I 2025-03-20 03:05:23,305] Trial 53 finished with value: 0.9064872145601313 and parameters: {'hidden_dim': 70, 'dropout': 0.3466968968673355, 'learning_rate': 0.0030202303363159027, 'batch_size': 64, 'weight_decay': 5.240445279994774e-06}. Best is trial 27 with value: 0.9135419701825951.\n",
      "[I 2025-03-20 03:05:27,686] Trial 54 finished with value: 0.8790552088729172 and parameters: {'hidden_dim': 75, 'dropout': 0.34628470741387607, 'learning_rate': 0.0029633958054440736, 'batch_size': 64, 'weight_decay': 5.194185874727245e-06}. Best is trial 27 with value: 0.9135419701825951.\n",
      "[I 2025-03-20 03:05:29,020] Trial 55 finished with value: 0.8718580031080032 and parameters: {'hidden_dim': 70, 'dropout': 0.4019878829091252, 'learning_rate': 0.002270433708929638, 'batch_size': 64, 'weight_decay': 6.591108079174895e-06}. Best is trial 27 with value: 0.9135419701825951.\n",
      "[I 2025-03-20 03:05:31,034] Trial 56 finished with value: 0.8413948512906847 and parameters: {'hidden_dim': 58, 'dropout': 0.42284134212300384, 'learning_rate': 0.004043419635656621, 'batch_size': 32, 'weight_decay': 1.2430945891763684e-05}. Best is trial 27 with value: 0.9135419701825951.\n",
      "[I 2025-03-20 03:05:32,452] Trial 57 finished with value: 0.864859128140378 and parameters: {'hidden_dim': 87, 'dropout': 0.3230535020938028, 'learning_rate': 0.0016404687689011317, 'batch_size': 64, 'weight_decay': 1.710829066154596e-05}. Best is trial 27 with value: 0.9135419701825951.\n",
      "[I 2025-03-20 03:05:36,382] Trial 58 finished with value: 0.8718607684753518 and parameters: {'hidden_dim': 63, 'dropout': 0.24371182572736302, 'learning_rate': 0.0011732972240409746, 'batch_size': 16, 'weight_decay': 3.5581968503099347e-06}. Best is trial 27 with value: 0.9135419701825951.\n",
      "[I 2025-03-20 03:05:37,771] Trial 59 finished with value: 0.8521132127902962 and parameters: {'hidden_dim': 93, 'dropout': 0.3687914560185438, 'learning_rate': 0.004936516553617544, 'batch_size': 64, 'weight_decay': 9.254339217625982e-06}. Best is trial 27 with value: 0.9135419701825951.\n",
      "[I 2025-03-20 03:05:39,185] Trial 60 finished with value: 0.8799847432659932 and parameters: {'hidden_dim': 99, 'dropout': 0.45741509232994393, 'learning_rate': 0.0036434639883787968, 'batch_size': 64, 'weight_decay': 2.35061021713612e-06}. Best is trial 27 with value: 0.9135419701825951.\n",
      "[I 2025-03-20 03:05:40,563] Trial 61 finished with value: 0.8853377525252525 and parameters: {'hidden_dim': 68, 'dropout': 0.29005701989970883, 'learning_rate': 0.0024205960656229234, 'batch_size': 64, 'weight_decay': 4.914249488985338e-06}. Best is trial 27 with value: 0.9135419701825951.\n",
      "[I 2025-03-20 03:05:41,946] Trial 62 finished with value: 0.9077897363053613 and parameters: {'hidden_dim': 81, 'dropout': 0.2749514358290519, 'learning_rate': 0.003037018100846917, 'batch_size': 64, 'weight_decay': 7.3609643458204e-06}. Best is trial 27 with value: 0.9135419701825951.\n",
      "[I 2025-03-20 03:05:43,325] Trial 63 finished with value: 0.888278383460675 and parameters: {'hidden_dim': 81, 'dropout': 0.2611869257186974, 'learning_rate': 0.002865821949539897, 'batch_size': 64, 'weight_decay': 1.1565970672987816e-05}. Best is trial 27 with value: 0.9135419701825951.\n",
      "[I 2025-03-20 03:05:44,687] Trial 64 finished with value: 0.8976659287857204 and parameters: {'hidden_dim': 78, 'dropout': 0.32902534026769514, 'learning_rate': 0.0031747785589767486, 'batch_size': 64, 'weight_decay': 7.79579939863857e-06}. Best is trial 27 with value: 0.9135419701825951.\n",
      "[I 2025-03-20 03:05:48,480] Trial 65 finished with value: 0.8563681351441769 and parameters: {'hidden_dim': 84, 'dropout': 0.320174967781976, 'learning_rate': 0.005745977988212841, 'batch_size': 16, 'weight_decay': 7.238952593950299e-06}. Best is trial 27 with value: 0.9135419701825951.\n",
      "[I 2025-03-20 03:05:49,894] Trial 66 finished with value: 0.8878903214840715 and parameters: {'hidden_dim': 46, 'dropout': 0.33114183615661286, 'learning_rate': 0.0031839603366047822, 'batch_size': 64, 'weight_decay': 5.8898053814414124e-06}. Best is trial 27 with value: 0.9135419701825951.\n",
      "[I 2025-03-20 03:05:51,308] Trial 67 finished with value: 0.8661771629219546 and parameters: {'hidden_dim': 72, 'dropout': 0.3515891693920028, 'learning_rate': 0.006888923302789752, 'batch_size': 64, 'weight_decay': 8.445467988827784e-06}. Best is trial 27 with value: 0.9135419701825951.\n",
      "[I 2025-03-20 03:05:53,350] Trial 68 finished with value: 0.8873572800656134 and parameters: {'hidden_dim': 51, 'dropout': 0.3093338900876337, 'learning_rate': 0.00814536302174546, 'batch_size': 32, 'weight_decay': 2.309980450927176e-05}. Best is trial 27 with value: 0.9135419701825951.\n",
      "[I 2025-03-20 03:05:54,736] Trial 69 finished with value: 0.8976377018043685 and parameters: {'hidden_dim': 62, 'dropout': 0.47125471066173363, 'learning_rate': 0.0045419073459525465, 'batch_size': 64, 'weight_decay': 1.0487506393455639e-05}. Best is trial 27 with value: 0.9135419701825951.\n",
      "[I 2025-03-20 03:06:01,617] Trial 70 finished with value: 0.8118713510640593 and parameters: {'hidden_dim': 55, 'dropout': 0.3858129402070648, 'learning_rate': 0.0037117477229718187, 'batch_size': 16, 'weight_decay': 6.605068003740393e-06}. Best is trial 27 with value: 0.9135419701825951.\n",
      "[I 2025-03-20 03:06:02,987] Trial 71 finished with value: 0.8562027864111198 and parameters: {'hidden_dim': 57, 'dropout': 0.4967043022784297, 'learning_rate': 0.004550641476410134, 'batch_size': 64, 'weight_decay': 1.0526813187072667e-05}. Best is trial 27 with value: 0.9135419701825951.\n",
      "[I 2025-03-20 03:06:04,434] Trial 72 finished with value: 0.8883520029353363 and parameters: {'hidden_dim': 62, 'dropout': 0.4394353826396585, 'learning_rate': 0.00333006535032319, 'batch_size': 64, 'weight_decay': 5.8082780729957325e-05}. Best is trial 27 with value: 0.9135419701825951.\n",
      "[I 2025-03-20 03:06:05,921] Trial 73 finished with value: 0.8933189399335233 and parameters: {'hidden_dim': 66, 'dropout': 0.3412384000338289, 'learning_rate': 0.003900324785511384, 'batch_size': 64, 'weight_decay': 1.6066957777260342e-05}. Best is trial 27 with value: 0.9135419701825951.\n",
      "[I 2025-03-20 03:06:07,386] Trial 74 finished with value: 0.8653368284878701 and parameters: {'hidden_dim': 76, 'dropout': 0.4797475563206075, 'learning_rate': 0.0026556101173575955, 'batch_size': 64, 'weight_decay': 8.863982190379587e-06}. Best is trial 27 with value: 0.9135419701825951.\n",
      "[I 2025-03-20 03:06:08,837] Trial 75 finished with value: 0.8718223568483986 and parameters: {'hidden_dim': 70, 'dropout': 0.3647985769846153, 'learning_rate': 0.0052542676233933985, 'batch_size': 64, 'weight_decay': 4.207361668013801e-06}. Best is trial 27 with value: 0.9135419701825951.\n",
      "[I 2025-03-20 03:06:10,299] Trial 76 finished with value: 0.8646868997129413 and parameters: {'hidden_dim': 87, 'dropout': 0.4766081819034042, 'learning_rate': 0.0022854870409520717, 'batch_size': 64, 'weight_decay': 7.469022084442012e-06}. Best is trial 27 with value: 0.9135419701825951.\n",
      "[I 2025-03-20 03:06:11,690] Trial 77 finished with value: 0.8935886644219978 and parameters: {'hidden_dim': 43, 'dropout': 0.39631459266997876, 'learning_rate': 0.006239966133964507, 'batch_size': 64, 'weight_decay': 1.282298099884592e-05}. Best is trial 27 with value: 0.9135419701825951.\n",
      "[I 2025-03-20 03:06:15,517] Trial 78 finished with value: 0.8683162082901665 and parameters: {'hidden_dim': 78, 'dropout': 0.4705597039350056, 'learning_rate': 0.002987012389292693, 'batch_size': 16, 'weight_decay': 8.93670419572201e-05}. Best is trial 27 with value: 0.9135419701825951.\n",
      "[I 2025-03-20 03:06:16,980] Trial 79 finished with value: 0.8431180461128379 and parameters: {'hidden_dim': 37, 'dropout': 0.4239914879426934, 'learning_rate': 0.004638512040773063, 'batch_size': 64, 'weight_decay': 5.226400344565309e-06}. Best is trial 27 with value: 0.9135419701825951.\n",
      "[I 2025-03-20 03:06:18,413] Trial 80 finished with value: 0.7021484880859882 and parameters: {'hidden_dim': 74, 'dropout': 0.2914948197357245, 'learning_rate': 0.00010789015530993773, 'batch_size': 64, 'weight_decay': 3.08211976570485e-05}. Best is trial 27 with value: 0.9135419701825951.\n",
      "[I 2025-03-20 03:06:19,888] Trial 81 finished with value: 0.8731616377449711 and parameters: {'hidden_dim': 90, 'dropout': 0.27240945387961946, 'learning_rate': 0.002046899352983409, 'batch_size': 64, 'weight_decay': 3.1440216671433436e-06}. Best is trial 27 with value: 0.9135419701825951.\n",
      "[I 2025-03-20 03:06:21,481] Trial 82 finished with value: 0.8530595417314167 and parameters: {'hidden_dim': 80, 'dropout': 0.24879920194816588, 'learning_rate': 0.0015954386651549387, 'batch_size': 64, 'weight_decay': 2.7458009456168915e-06}. Best is trial 27 with value: 0.9135419701825951.\n",
      "[I 2025-03-20 03:06:22,814] Trial 83 finished with value: 0.8722055625701458 and parameters: {'hidden_dim': 83, 'dropout': 0.30780084311530415, 'learning_rate': 0.0025170970596274105, 'batch_size': 64, 'weight_decay': 3.94407842668803e-06}. Best is trial 27 with value: 0.9135419701825951.\n",
      "[I 2025-03-20 03:06:24,110] Trial 84 finished with value: 0.8538102040706207 and parameters: {'hidden_dim': 61, 'dropout': 0.2783212112884212, 'learning_rate': 0.0018581625741091211, 'batch_size': 64, 'weight_decay': 1.525572390929018e-06}. Best is trial 27 with value: 0.9135419701825951.\n",
      "[I 2025-03-20 03:06:25,982] Trial 85 finished with value: 0.8805268564383147 and parameters: {'hidden_dim': 72, 'dropout': 0.25744766866292246, 'learning_rate': 0.0033688525191153252, 'batch_size': 32, 'weight_decay': 4.322433695763931e-05}. Best is trial 27 with value: 0.9135419701825951.\n",
      "[I 2025-03-20 03:06:27,318] Trial 86 finished with value: 0.8456822498489166 and parameters: {'hidden_dim': 66, 'dropout': 0.32944636956248174, 'learning_rate': 0.002141544358629523, 'batch_size': 64, 'weight_decay': 5.905901451755845e-06}. Best is trial 27 with value: 0.9135419701825951.\n",
      "[I 2025-03-20 03:06:28,635] Trial 87 finished with value: 0.8553736483423983 and parameters: {'hidden_dim': 80, 'dropout': 0.29206923275865393, 'learning_rate': 0.0013299628384076737, 'batch_size': 64, 'weight_decay': 1.7429573078845426e-06}. Best is trial 27 with value: 0.9135419701825951.\n",
      "[I 2025-03-20 03:06:35,263] Trial 88 finished with value: 0.8722674123715791 and parameters: {'hidden_dim': 86, 'dropout': 0.22548882538143938, 'learning_rate': 0.0027464694603694484, 'batch_size': 16, 'weight_decay': 4.486831654311872e-06}. Best is trial 27 with value: 0.9135419701825951.\n",
      "[I 2025-03-20 03:06:36,619] Trial 89 finished with value: 0.8754899758806008 and parameters: {'hidden_dim': 93, 'dropout': 0.2348028181684943, 'learning_rate': 0.0011120954999349348, 'batch_size': 64, 'weight_decay': 9.99044753531142e-06}. Best is trial 27 with value: 0.9135419701825951.\n",
      "[I 2025-03-20 03:06:38,022] Trial 90 finished with value: 0.8902726854549772 and parameters: {'hidden_dim': 57, 'dropout': 0.4483670203939159, 'learning_rate': 0.003614647141317436, 'batch_size': 64, 'weight_decay': 2.5333629338174616e-06}. Best is trial 27 with value: 0.9135419701825951.\n",
      "[I 2025-03-20 03:06:39,408] Trial 91 finished with value: 0.8926676621989124 and parameters: {'hidden_dim': 69, 'dropout': 0.27731455780511755, 'learning_rate': 0.004195719547846613, 'batch_size': 64, 'weight_decay': 3.5211511807599247e-06}. Best is trial 27 with value: 0.9135419701825951.\n",
      "[I 2025-03-20 03:06:40,862] Trial 92 finished with value: 0.8900576275576276 and parameters: {'hidden_dim': 75, 'dropout': 0.2614960369372383, 'learning_rate': 0.0024887195055301185, 'batch_size': 64, 'weight_decay': 6.5657987667640685e-06}. Best is trial 27 with value: 0.9135419701825951.\n",
      "[I 2025-03-20 03:06:42,345] Trial 93 finished with value: 0.8938031827354743 and parameters: {'hidden_dim': 49, 'dropout': 0.3127492890563076, 'learning_rate': 0.0030648033802700516, 'batch_size': 64, 'weight_decay': 2.1523878062138262e-06}. Best is trial 27 with value: 0.9135419701825951.\n",
      "[I 2025-03-20 03:06:43,761] Trial 94 finished with value: 0.8671277073620823 and parameters: {'hidden_dim': 66, 'dropout': 0.3013198992441491, 'learning_rate': 0.0015101530320475974, 'batch_size': 64, 'weight_decay': 5.4197436345758245e-06}. Best is trial 27 with value: 0.9135419701825951.\n",
      "[I 2025-03-20 03:06:45,076] Trial 95 finished with value: 0.8456380039713371 and parameters: {'hidden_dim': 77, 'dropout': 0.28524899923455904, 'learning_rate': 0.0007906871088171522, 'batch_size': 64, 'weight_decay': 8.085753467518395e-06}. Best is trial 27 with value: 0.9135419701825951.\n",
      "[I 2025-03-20 03:06:46,416] Trial 96 finished with value: 0.8465528009798843 and parameters: {'hidden_dim': 72, 'dropout': 0.32075827560945336, 'learning_rate': 0.0022897774672219155, 'batch_size': 64, 'weight_decay': 1.956372626292333e-05}. Best is trial 27 with value: 0.9135419701825951.\n",
      "[I 2025-03-20 03:06:50,135] Trial 97 finished with value: 0.8936332812634896 and parameters: {'hidden_dim': 53, 'dropout': 0.37580954054455673, 'learning_rate': 0.0018728357102175928, 'batch_size': 16, 'weight_decay': 4.6089049019807235e-06}. Best is trial 27 with value: 0.9135419701825951.\n",
      "[I 2025-03-20 03:06:51,516] Trial 98 finished with value: 0.8650031295864627 and parameters: {'hidden_dim': 63, 'dropout': 0.23657376445228237, 'learning_rate': 0.0027194643578676387, 'batch_size': 64, 'weight_decay': 2.998438120147414e-06}. Best is trial 27 with value: 0.9135419701825951.\n",
      "[I 2025-03-20 03:06:53,517] Trial 99 finished with value: 0.9201578754964171 and parameters: {'hidden_dim': 82, 'dropout': 0.29492693921665286, 'learning_rate': 0.0034675890750654175, 'batch_size': 32, 'weight_decay': 1.4424846262497513e-05}. Best is trial 99 with value: 0.9201578754964171.\n",
      "[I 2025-03-20 03:06:53,530] A new study created in memory with name: no-name-7497baef-02d9-4778-99d8-c477aa5975d7\n",
      "[I 2025-03-20 03:06:53,676] Trial 0 finished with value: 0.7295625856271017 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.013661178428178952, 'n_estimators': 456, 'num_leaves': 48, 'max_depth': 6, 'subsample': 0.7552942184455931, 'colsample_bytree': 0.7030385741204636, 'reg_alpha': 1.3087232248047334, 'reg_lambda': 0.6869757398160233, 'min_child_samples': 49}. Best is trial 0 with value: 0.7295625856271017.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best LSTM Parameters:\n",
      "  hidden_dim: 82\n",
      "  dropout: 0.29492693921665286\n",
      "  learning_rate: 0.0034675890750654175\n",
      "  batch_size: 32\n",
      "  weight_decay: 1.4424846262497513e-05\n",
      "\n",
      "Optimizing LightGBM for fold 2 using min_max normalization\n",
      "Optimizing LightGBM hyperparameters with CV...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-20 03:06:53,763] Trial 1 finished with value: 0.7651905297597285 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.06323892443630524, 'n_estimators': 282, 'num_leaves': 42, 'max_depth': 3, 'subsample': 0.9077831487751247, 'colsample_bytree': 0.6012684467021177, 'reg_alpha': 0.31439409038438626, 'reg_lambda': 1.0912521853098582, 'min_child_samples': 47}. Best is trial 1 with value: 0.7651905297597285.\n",
      "[I 2025-03-20 03:06:53,855] Trial 2 finished with value: 0.757862830572508 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.019957907467756848, 'n_estimators': 199, 'num_leaves': 37, 'max_depth': 10, 'subsample': 0.7873081624297713, 'colsample_bytree': 0.6493149518105418, 'reg_alpha': 3.6000609130029044, 'reg_lambda': 4.050134848257446, 'min_child_samples': 21}. Best is trial 1 with value: 0.7651905297597285.\n",
      "[I 2025-03-20 03:06:53,926] Trial 3 finished with value: 0.7859902142368324 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.03308671790989007, 'n_estimators': 162, 'num_leaves': 10, 'max_depth': 5, 'subsample': 0.9963593754983149, 'colsample_bytree': 0.805256515122397, 'reg_alpha': 3.0841806167907238, 'reg_lambda': 0.1301677362213169, 'min_child_samples': 21}. Best is trial 3 with value: 0.7859902142368324.\n",
      "[I 2025-03-20 03:06:54,059] Trial 4 finished with value: 0.7717277918620271 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.029437387715603364, 'n_estimators': 405, 'num_leaves': 47, 'max_depth': 6, 'subsample': 0.9716350708762611, 'colsample_bytree': 0.7998448041733087, 'reg_alpha': 2.304933318498776, 'reg_lambda': 3.3362817514757888, 'min_child_samples': 29}. Best is trial 3 with value: 0.7859902142368324.\n",
      "[I 2025-03-20 03:06:54,111] Trial 5 finished with value: 0.7594885448850069 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.07045793365915588, 'n_estimators': 210, 'num_leaves': 23, 'max_depth': 3, 'subsample': 0.8092590874861125, 'colsample_bytree': 0.859403208540551, 'reg_alpha': 3.3760828530802196, 'reg_lambda': 0.15012918259918107, 'min_child_samples': 22}. Best is trial 3 with value: 0.7859902142368324.\n",
      "[I 2025-03-20 03:06:54,261] Trial 6 finished with value: 0.7947178561049529 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.011970252710206382, 'n_estimators': 476, 'num_leaves': 49, 'max_depth': 4, 'subsample': 0.9816084577717837, 'colsample_bytree': 0.7776193095921519, 'reg_alpha': 0.2802529145561249, 'reg_lambda': 1.3744727196612017, 'min_child_samples': 25}. Best is trial 6 with value: 0.7947178561049529.\n",
      "[I 2025-03-20 03:06:54,370] Trial 7 finished with value: 0.8014488808713575 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.0967088301559984, 'n_estimators': 367, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.6725825297010686, 'colsample_bytree': 0.7765487989776441, 'reg_alpha': 1.3901311581414446, 'reg_lambda': 1.2894120399825089, 'min_child_samples': 25}. Best is trial 7 with value: 0.8014488808713575.\n",
      "[I 2025-03-20 03:06:54,475] Trial 8 finished with value: 0.7774135827517722 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.04669085237595252, 'n_estimators': 388, 'num_leaves': 42, 'max_depth': 5, 'subsample': 0.6388242673991037, 'colsample_bytree': 0.9337670455562896, 'reg_alpha': 0.11037032003620384, 'reg_lambda': 0.25448376172072, 'min_child_samples': 45}. Best is trial 7 with value: 0.8014488808713575.\n",
      "[I 2025-03-20 03:06:54,560] Trial 9 finished with value: 0.7769623823317892 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.011232085595448875, 'n_estimators': 177, 'num_leaves': 29, 'max_depth': 4, 'subsample': 0.7436406503252848, 'colsample_bytree': 0.6580654068535353, 'reg_alpha': 0.1699984374960256, 'reg_lambda': 0.1466016632681982, 'min_child_samples': 16}. Best is trial 7 with value: 0.8014488808713575.\n",
      "[I 2025-03-20 03:06:54,675] Trial 10 finished with value: 0.7998458544764477 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.0987558719383339, 'n_estimators': 337, 'num_leaves': 18, 'max_depth': 10, 'subsample': 0.642242017563948, 'colsample_bytree': 0.9614634142305828, 'reg_alpha': 0.7548915517607346, 'reg_lambda': 0.47191940414066896, 'min_child_samples': 37}. Best is trial 7 with value: 0.8014488808713575.\n",
      "[I 2025-03-20 03:06:54,788] Trial 11 finished with value: 0.7991249542987316 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.08811492902543544, 'n_estimators': 327, 'num_leaves': 17, 'max_depth': 10, 'subsample': 0.6019793854602531, 'colsample_bytree': 0.993860589036455, 'reg_alpha': 0.7915653922317443, 'reg_lambda': 0.4908802288038389, 'min_child_samples': 38}. Best is trial 7 with value: 0.8014488808713575.\n",
      "[I 2025-03-20 03:06:54,901] Trial 12 finished with value: 0.8008894678832243 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.09822003027572318, 'n_estimators': 307, 'num_leaves': 30, 'max_depth': 8, 'subsample': 0.6801173039155465, 'colsample_bytree': 0.893626879385864, 'reg_alpha': 0.8750718436454238, 'reg_lambda': 1.8653713281408886, 'min_child_samples': 37}. Best is trial 7 with value: 0.8014488808713575.\n",
      "[I 2025-03-20 03:06:55,072] Trial 13 finished with value: 0.8155713816983328 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.05345803972760133, 'n_estimators': 280, 'num_leaves': 30, 'max_depth': 8, 'subsample': 0.6744176335855437, 'colsample_bytree': 0.8784839768898399, 'reg_alpha': 1.4639178782106737, 'reg_lambda': 2.0673304537938133, 'min_child_samples': 10}. Best is trial 13 with value: 0.8155713816983328.\n",
      "[I 2025-03-20 03:06:55,173] Trial 14 finished with value: 0.8197127723829076 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.0514136988240323, 'n_estimators': 106, 'num_leaves': 34, 'max_depth': 8, 'subsample': 0.7003547686087039, 'colsample_bytree': 0.7567506115224731, 'reg_alpha': 1.6036537578041012, 'reg_lambda': 2.327760318505606, 'min_child_samples': 10}. Best is trial 14 with value: 0.8197127723829076.\n",
      "[I 2025-03-20 03:06:55,264] Trial 15 finished with value: 0.817935288343197 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.043288657420412956, 'n_estimators': 102, 'num_leaves': 35, 'max_depth': 8, 'subsample': 0.7162209016787783, 'colsample_bytree': 0.8497272335544289, 'reg_alpha': 1.7337714184739639, 'reg_lambda': 2.4129838631039044, 'min_child_samples': 13}. Best is trial 14 with value: 0.8197127723829076.\n",
      "[I 2025-03-20 03:06:55,335] Trial 16 finished with value: 0.7542746401820283 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.04109638618124266, 'n_estimators': 103, 'num_leaves': 38, 'max_depth': 8, 'subsample': 0.8460344390937014, 'colsample_bytree': 0.7332836568252892, 'reg_alpha': 4.970526176538261, 'reg_lambda': 2.6533031074045117, 'min_child_samples': 10}. Best is trial 14 with value: 0.8197127723829076.\n",
      "[I 2025-03-20 03:06:55,433] Trial 17 finished with value: 0.8035156683366882 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.024514901988786787, 'n_estimators': 125, 'num_leaves': 35, 'max_depth': 7, 'subsample': 0.7196804203919662, 'colsample_bytree': 0.8514824173376508, 'reg_alpha': 2.0059984359337593, 'reg_lambda': 3.813415674909581, 'min_child_samples': 15}. Best is trial 14 with value: 0.8197127723829076.\n",
      "[I 2025-03-20 03:06:55,600] Trial 18 finished with value: 0.8299930145694974 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.037144471324082946, 'n_estimators': 227, 'num_leaves': 24, 'max_depth': 9, 'subsample': 0.7137351539393999, 'colsample_bytree': 0.7287996519197543, 'reg_alpha': 0.45729733448074894, 'reg_lambda': 4.824176851953528, 'min_child_samples': 15}. Best is trial 18 with value: 0.8299930145694974.\n",
      "[I 2025-03-20 03:06:55,745] Trial 19 finished with value: 0.8106451157564581 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.019113721561322468, 'n_estimators': 241, 'num_leaves': 25, 'max_depth': 9, 'subsample': 0.7941895058442429, 'colsample_bytree': 0.7222208280865605, 'reg_alpha': 0.42706293782677895, 'reg_lambda': 4.255688968928355, 'min_child_samples': 17}. Best is trial 18 with value: 0.8299930145694974.\n",
      "[I 2025-03-20 03:06:55,850] Trial 20 finished with value: 0.7768998442473989 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.03448357662735862, 'n_estimators': 253, 'num_leaves': 24, 'max_depth': 9, 'subsample': 0.8662068662276897, 'colsample_bytree': 0.683699001860462, 'reg_alpha': 0.4785139738442375, 'reg_lambda': 4.815902159571185, 'min_child_samples': 31}. Best is trial 18 with value: 0.8299930145694974.\n",
      "[I 2025-03-20 03:06:55,959] Trial 21 finished with value: 0.8302535205043009 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.04796891181125232, 'n_estimators': 140, 'num_leaves': 34, 'max_depth': 7, 'subsample': 0.7177198989806286, 'colsample_bytree': 0.7476579973236518, 'reg_alpha': 0.47030520300856754, 'reg_lambda': 2.402411476912158, 'min_child_samples': 12}. Best is trial 21 with value: 0.8302535205043009.\n",
      "[I 2025-03-20 03:06:56,071] Trial 22 finished with value: 0.8366355496272249 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.05691393488808102, 'n_estimators': 147, 'num_leaves': 33, 'max_depth': 7, 'subsample': 0.7140868333158419, 'colsample_bytree': 0.7621521881566689, 'reg_alpha': 0.5058214915040057, 'reg_lambda': 1.7260415524945665, 'min_child_samples': 13}. Best is trial 22 with value: 0.8366355496272249.\n",
      "[I 2025-03-20 03:06:56,170] Trial 23 finished with value: 0.8258412019868835 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.06550018786401357, 'n_estimators': 159, 'num_leaves': 27, 'max_depth': 7, 'subsample': 0.7738830569369699, 'colsample_bytree': 0.7448554954626562, 'reg_alpha': 0.457258697678428, 'reg_lambda': 1.675137388227885, 'min_child_samples': 18}. Best is trial 22 with value: 0.8366355496272249.\n",
      "[I 2025-03-20 03:06:56,277] Trial 24 finished with value: 0.8329716578478286 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.03914221839101109, 'n_estimators': 141, 'num_leaves': 21, 'max_depth': 7, 'subsample': 0.7396756451743561, 'colsample_bytree': 0.8125433826805081, 'reg_alpha': 0.25884478241560555, 'reg_lambda': 0.8227568369200018, 'min_child_samples': 14}. Best is trial 22 with value: 0.8366355496272249.\n",
      "[I 2025-03-20 03:06:56,383] Trial 25 finished with value: 0.8351342512424719 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.056539182308454124, 'n_estimators': 135, 'num_leaves': 19, 'max_depth': 7, 'subsample': 0.7423397846032438, 'colsample_bytree': 0.8172853988994906, 'reg_alpha': 0.22351524545390877, 'reg_lambda': 0.9688851193203756, 'min_child_samples': 13}. Best is trial 22 with value: 0.8366355496272249.\n",
      "[I 2025-03-20 03:06:56,489] Trial 26 finished with value: 0.8273078946346375 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.0771483911440346, 'n_estimators': 183, 'num_leaves': 18, 'max_depth': 6, 'subsample': 0.8411766197382218, 'colsample_bytree': 0.8211475835242629, 'reg_alpha': 0.1981151186970793, 'reg_lambda': 0.9786428051144711, 'min_child_samples': 19}. Best is trial 22 with value: 0.8366355496272249.\n",
      "[I 2025-03-20 03:06:56,592] Trial 27 finished with value: 0.840325474724018 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.05883480565766994, 'n_estimators': 135, 'num_leaves': 13, 'max_depth': 7, 'subsample': 0.8122806124009707, 'colsample_bytree': 0.8267484591369892, 'reg_alpha': 0.15808811854735966, 'reg_lambda': 0.6724340412993158, 'min_child_samples': 13}. Best is trial 27 with value: 0.840325474724018.\n",
      "[I 2025-03-20 03:06:56,670] Trial 28 finished with value: 0.8070605680751364 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.05704498744164297, 'n_estimators': 138, 'num_leaves': 10, 'max_depth': 5, 'subsample': 0.8804686058791398, 'colsample_bytree': 0.910423244744483, 'reg_alpha': 0.1028504294924159, 'reg_lambda': 0.4697727481183875, 'min_child_samples': 25}. Best is trial 27 with value: 0.840325474724018.\n",
      "[I 2025-03-20 03:06:56,788] Trial 29 finished with value: 0.8308681325892564 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.0772710694737384, 'n_estimators': 205, 'num_leaves': 14, 'max_depth': 6, 'subsample': 0.8154322758311401, 'colsample_bytree': 0.7032288894084813, 'reg_alpha': 0.14717468711068732, 'reg_lambda': 0.6440961910927886, 'min_child_samples': 19}. Best is trial 27 with value: 0.840325474724018.\n",
      "[I 2025-03-20 03:06:56,871] Trial 30 finished with value: 0.800388437344733 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.05921540648291128, 'n_estimators': 166, 'num_leaves': 13, 'max_depth': 7, 'subsample': 0.7697720387073888, 'colsample_bytree': 0.8374681760700159, 'reg_alpha': 0.20417594048667156, 'reg_lambda': 0.24582514361630925, 'min_child_samples': 30}. Best is trial 27 with value: 0.840325474724018.\n",
      "[I 2025-03-20 03:06:56,982] Trial 31 finished with value: 0.8367302359591641 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.04050585260407289, 'n_estimators': 131, 'num_leaves': 21, 'max_depth': 7, 'subsample': 0.7586781148255216, 'colsample_bytree': 0.7803628869865951, 'reg_alpha': 0.28549842694867744, 'reg_lambda': 0.7964644882985981, 'min_child_samples': 13}. Best is trial 27 with value: 0.840325474724018.\n",
      "[I 2025-03-20 03:06:57,092] Trial 32 finished with value: 0.8378345406503576 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.06804673650216124, 'n_estimators': 126, 'num_leaves': 15, 'max_depth': 6, 'subsample': 0.7577581168119656, 'colsample_bytree': 0.7790211478702708, 'reg_alpha': 0.1311991840883291, 'reg_lambda': 0.6351819948699057, 'min_child_samples': 13}. Best is trial 27 with value: 0.840325474724018.\n",
      "[I 2025-03-20 03:06:57,236] Trial 33 finished with value: 0.8426023125846227 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.028356052139604872, 'n_estimators': 194, 'num_leaves': 14, 'max_depth': 6, 'subsample': 0.823933313575341, 'colsample_bytree': 0.7837185366763677, 'reg_alpha': 0.13443395035965247, 'reg_lambda': 0.5956602999915758, 'min_child_samples': 12}. Best is trial 33 with value: 0.8426023125846227.\n",
      "[I 2025-03-20 03:06:57,381] Trial 34 finished with value: 0.8344264969592754 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.027069572527092703, 'n_estimators': 191, 'num_leaves': 14, 'max_depth': 6, 'subsample': 0.9350814517375146, 'colsample_bytree': 0.792364239675844, 'reg_alpha': 0.13720552707897762, 'reg_lambda': 0.630644245752737, 'min_child_samples': 11}. Best is trial 33 with value: 0.8426023125846227.\n",
      "[I 2025-03-20 03:06:57,468] Trial 35 finished with value: 0.7775137304689854 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.02163655073657856, 'n_estimators': 119, 'num_leaves': 12, 'max_depth': 5, 'subsample': 0.8168359013496314, 'colsample_bytree': 0.7738166113326118, 'reg_alpha': 0.3438486054853424, 'reg_lambda': 0.31558636903333975, 'min_child_samples': 22}. Best is trial 33 with value: 0.8426023125846227.\n",
      "[I 2025-03-20 03:06:57,588] Trial 36 finished with value: 0.821167701222852 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.03236031358922, 'n_estimators': 168, 'num_leaves': 16, 'max_depth': 6, 'subsample': 0.9013524233332678, 'colsample_bytree': 0.7943163752819814, 'reg_alpha': 0.13612571568045906, 'reg_lambda': 0.339806657674805, 'min_child_samples': 18}. Best is trial 33 with value: 0.8426023125846227.\n",
      "[I 2025-03-20 03:06:57,712] Trial 37 finished with value: 0.804363701742474 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.0181752568574581, 'n_estimators': 218, 'num_leaves': 21, 'max_depth': 6, 'subsample': 0.8295544333641782, 'colsample_bytree': 0.7013004667386881, 'reg_alpha': 0.17010714258241172, 'reg_lambda': 0.7424780574021025, 'min_child_samples': 20}. Best is trial 33 with value: 0.8426023125846227.\n",
      "[I 2025-03-20 03:06:57,824] Trial 38 finished with value: 0.8229175488852908 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.02935514360029792, 'n_estimators': 193, 'num_leaves': 10, 'max_depth': 5, 'subsample': 0.7777291916003832, 'colsample_bytree': 0.8708838298126357, 'reg_alpha': 0.11886719888274751, 'reg_lambda': 0.5653934969963305, 'min_child_samples': 16}. Best is trial 33 with value: 0.8426023125846227.\n",
      "[I 2025-03-20 03:06:57,987] Trial 39 finished with value: 0.7970536897831382 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.015805522226546066, 'n_estimators': 434, 'num_leaves': 16, 'max_depth': 4, 'subsample': 0.7932744940366798, 'colsample_bytree': 0.60951827827375, 'reg_alpha': 0.33982390179046523, 'reg_lambda': 1.2043220829573837, 'min_child_samples': 23}. Best is trial 33 with value: 0.8426023125846227.\n",
      "[I 2025-03-20 03:06:58,091] Trial 40 finished with value: 0.8021642875222479 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.0689166449071245, 'n_estimators': 262, 'num_leaves': 20, 'max_depth': 6, 'subsample': 0.7625785768668903, 'colsample_bytree': 0.8411623217148714, 'reg_alpha': 0.250222669328795, 'reg_lambda': 0.9116841597434181, 'min_child_samples': 34}. Best is trial 33 with value: 0.8426023125846227.\n",
      "[I 2025-03-20 03:06:58,204] Trial 41 finished with value: 0.8283432289134683 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.0802105216030138, 'n_estimators': 150, 'num_leaves': 15, 'max_depth': 7, 'subsample': 0.8568114086015312, 'colsample_bytree': 0.7631614379939149, 'reg_alpha': 0.9934455312924253, 'reg_lambda': 1.5610258916261666, 'min_child_samples': 13}. Best is trial 33 with value: 0.8426023125846227.\n",
      "[I 2025-03-20 03:06:58,302] Trial 42 finished with value: 0.8332569355441363 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.04545704229114224, 'n_estimators': 127, 'num_leaves': 12, 'max_depth': 6, 'subsample': 0.7501158617542235, 'colsample_bytree': 0.7877070490284679, 'reg_alpha': 0.17788684444652836, 'reg_lambda': 0.3894359791634076, 'min_child_samples': 14}. Best is trial 33 with value: 0.8426023125846227.\n",
      "[I 2025-03-20 03:06:58,370] Trial 43 finished with value: 0.7585899595150376 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.06418443841981039, 'n_estimators': 157, 'num_leaves': 41, 'max_depth': 7, 'subsample': 0.8042442353741162, 'colsample_bytree': 0.8306076910954077, 'reg_alpha': 0.6210278503995007, 'reg_lambda': 0.7582498146806043, 'min_child_samples': 50}. Best is trial 33 with value: 0.8426023125846227.\n",
      "[I 2025-03-20 03:06:58,433] Trial 44 finished with value: 0.7530541960125727 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.05152031324712323, 'n_estimators': 118, 'num_leaves': 22, 'max_depth': 5, 'subsample': 0.7578389877390594, 'colsample_bytree': 0.8071349539523239, 'reg_alpha': 0.30705442606352856, 'reg_lambda': 0.5498324391174616, 'min_child_samples': 45}. Best is trial 33 with value: 0.8426023125846227.\n",
      "[I 2025-03-20 03:06:58,575] Trial 45 finished with value: 0.8332372475046773 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.03638484615704035, 'n_estimators': 176, 'num_leaves': 28, 'max_depth': 8, 'subsample': 0.8260083060345035, 'colsample_bytree': 0.7743384407266947, 'reg_alpha': 0.1179022872866858, 'reg_lambda': 1.0800294677519784, 'min_child_samples': 12}. Best is trial 33 with value: 0.8426023125846227.\n",
      "[I 2025-03-20 03:06:58,657] Trial 46 finished with value: 0.7780940421616801 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.023805185234108378, 'n_estimators': 151, 'num_leaves': 12, 'max_depth': 6, 'subsample': 0.6948758947196713, 'colsample_bytree': 0.7091557397947391, 'reg_alpha': 0.5905353068432418, 'reg_lambda': 0.22000142450849106, 'min_child_samples': 27}. Best is trial 33 with value: 0.8426023125846227.\n",
      "[I 2025-03-20 03:06:58,743] Trial 47 finished with value: 0.8204215659095991 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.02960070095834647, 'n_estimators': 100, 'num_leaves': 31, 'max_depth': 7, 'subsample': 0.6381131886829216, 'colsample_bytree': 0.7534966957842459, 'reg_alpha': 0.15701026819768543, 'reg_lambda': 0.4137166748707009, 'min_child_samples': 16}. Best is trial 33 with value: 0.8426023125846227.\n",
      "[I 2025-03-20 03:06:58,852] Trial 48 finished with value: 0.8307392275581662 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.08654742671541144, 'n_estimators': 225, 'num_leaves': 32, 'max_depth': 8, 'subsample': 0.7340174651679425, 'colsample_bytree': 0.7710947174152837, 'reg_alpha': 1.0985008230952682, 'reg_lambda': 0.11123155755853965, 'min_child_samples': 11}. Best is trial 33 with value: 0.8426023125846227.\n",
      "[I 2025-03-20 03:06:58,952] Trial 49 finished with value: 0.8070180448026442 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.07115595987045323, 'n_estimators': 205, 'num_leaves': 26, 'max_depth': 4, 'subsample': 0.7835535635130332, 'colsample_bytree': 0.7950510436414103, 'reg_alpha': 0.38788405207879256, 'reg_lambda': 1.420835487241947, 'min_child_samples': 21}. Best is trial 33 with value: 0.8426023125846227.\n",
      "[I 2025-03-20 03:06:58,985] A new study created in memory with name: no-name-e4841115-d1bc-45b7-bb93-996aa08ec497\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best LightGBM Parameters:\n",
      "  boosting_type: gbdt\n",
      "  learning_rate: 0.028356052139604872\n",
      "  n_estimators: 194\n",
      "  num_leaves: 14\n",
      "  max_depth: 6\n",
      "  subsample: 0.823933313575341\n",
      "  colsample_bytree: 0.7837185366763677\n",
      "  reg_alpha: 0.13443395035965247\n",
      "  reg_lambda: 0.5956602999915758\n",
      "  min_child_samples: 12\n",
      "\n",
      "Optimizing LSTM for fold 2 using min_max normalization\n",
      "Created LSTM sequences with lookback=10: 298 train, 145 test\n",
      "Optimizing LSTM hyperparameters with CV...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-20 03:07:10,316] Trial 0 finished with value: 0.7647054024969847 and parameters: {'hidden_dim': 45, 'dropout': 0.4551406810921512, 'learning_rate': 0.007331811314274292, 'batch_size': 16, 'weight_decay': 2.064121088592392e-05}. Best is trial 0 with value: 0.7647054024969847.\n",
      "[I 2025-03-20 03:07:14,984] Trial 1 finished with value: 0.8473310308503006 and parameters: {'hidden_dim': 79, 'dropout': 0.48569536770002286, 'learning_rate': 0.003999161563860724, 'batch_size': 32, 'weight_decay': 3.45872269711161e-05}. Best is trial 1 with value: 0.8473310308503006.\n",
      "[I 2025-03-20 03:07:23,367] Trial 2 finished with value: 0.8378526476903758 and parameters: {'hidden_dim': 32, 'dropout': 0.21712375681979076, 'learning_rate': 0.0016665895921660098, 'batch_size': 16, 'weight_decay': 2.1517123363927774e-05}. Best is trial 1 with value: 0.8473310308503006.\n",
      "[I 2025-03-20 03:07:27,889] Trial 3 finished with value: 0.7079241555154335 and parameters: {'hidden_dim': 127, 'dropout': 0.2873081624297713, 'learning_rate': 0.00017643094449433023, 'batch_size': 32, 'weight_decay': 1.0947309020486406e-05}. Best is trial 1 with value: 0.8473310308503006.\n",
      "[I 2025-03-20 03:07:36,775] Trial 4 finished with value: 0.811948031496713 and parameters: {'hidden_dim': 47, 'dropout': 0.10585094112968818, 'learning_rate': 0.0004451295365396247, 'batch_size': 16, 'weight_decay': 1.3639281514957935e-06}. Best is trial 1 with value: 0.8473310308503006.\n",
      "[I 2025-03-20 03:07:41,324] Trial 5 finished with value: 0.8273933254409928 and parameters: {'hidden_dim': 59, 'dropout': 0.2875597071705984, 'learning_rate': 0.0033384615669657483, 'batch_size': 64, 'weight_decay': 9.98214837316597e-06}. Best is trial 1 with value: 0.8473310308503006.\n",
      "[I 2025-03-20 03:07:49,163] Trial 6 finished with value: 0.7953451701930403 and parameters: {'hidden_dim': 109, 'dropout': 0.4586320455614753, 'learning_rate': 0.0009209968619749436, 'batch_size': 16, 'weight_decay': 1.6223673683559225e-06}. Best is trial 1 with value: 0.8473310308503006.\n",
      "[I 2025-03-20 03:07:53,450] Trial 7 finished with value: 0.7941034990477182 and parameters: {'hidden_dim': 82, 'dropout': 0.3594032085405511, 'learning_rate': 0.006298297451196278, 'batch_size': 32, 'weight_decay': 7.511737052942637e-05}. Best is trial 1 with value: 0.8473310308503006.\n",
      "[I 2025-03-20 03:07:56,057] Trial 8 finished with value: 0.7830165252071946 and parameters: {'hidden_dim': 125, 'dropout': 0.17649687394806254, 'learning_rate': 0.00809174687672524, 'batch_size': 64, 'weight_decay': 5.656354626844694e-06}. Best is trial 1 with value: 0.8473310308503006.\n",
      "[I 2025-03-20 03:08:04,119] Trial 9 finished with value: 0.7241511812505728 and parameters: {'hidden_dim': 127, 'dropout': 0.3668293205677101, 'learning_rate': 0.009614679235250567, 'batch_size': 16, 'weight_decay': 2.2160868002868673e-05}. Best is trial 1 with value: 0.8473310308503006.\n",
      "[I 2025-03-20 03:08:08,315] Trial 10 finished with value: 0.8408351124121914 and parameters: {'hidden_dim': 81, 'dropout': 0.3850400329025248, 'learning_rate': 0.00229500940300285, 'batch_size': 32, 'weight_decay': 8.469738945067809e-05}. Best is trial 1 with value: 0.8473310308503006.\n",
      "[I 2025-03-20 03:08:16,186] Trial 11 finished with value: 0.8338230443960667 and parameters: {'hidden_dim': 80, 'dropout': 0.4864413695393805, 'learning_rate': 0.002181551031131038, 'batch_size': 32, 'weight_decay': 7.585251739735352e-05}. Best is trial 1 with value: 0.8473310308503006.\n",
      "[I 2025-03-20 03:08:20,616] Trial 12 finished with value: 0.796889346661152 and parameters: {'hidden_dim': 97, 'dropout': 0.39121170409630657, 'learning_rate': 0.0008592895778069696, 'batch_size': 32, 'weight_decay': 4.418290988186971e-05}. Best is trial 1 with value: 0.8473310308503006.\n",
      "[I 2025-03-20 03:08:24,856] Trial 13 finished with value: 0.843406180627276 and parameters: {'hidden_dim': 67, 'dropout': 0.4158292438981242, 'learning_rate': 0.003399534777244384, 'batch_size': 32, 'weight_decay': 4.18012810875491e-05}. Best is trial 1 with value: 0.8473310308503006.\n",
      "[I 2025-03-20 03:08:29,169] Trial 14 finished with value: 0.8255768281376801 and parameters: {'hidden_dim': 65, 'dropout': 0.4990559726193295, 'learning_rate': 0.004351118630391938, 'batch_size': 32, 'weight_decay': 3.821863404982552e-05}. Best is trial 1 with value: 0.8473310308503006.\n",
      "[I 2025-03-20 03:08:33,339] Trial 15 finished with value: 0.8263998481797671 and parameters: {'hidden_dim': 69, 'dropout': 0.42580142494740547, 'learning_rate': 0.0038949815178919477, 'batch_size': 32, 'weight_decay': 3.7504371664630406e-05}. Best is trial 1 with value: 0.8473310308503006.\n",
      "[I 2025-03-20 03:08:37,671] Trial 16 finished with value: 0.7746152587176929 and parameters: {'hidden_dim': 96, 'dropout': 0.32180814792851586, 'learning_rate': 0.00046120972793413676, 'batch_size': 32, 'weight_decay': 4.5281394266958185e-06}. Best is trial 1 with value: 0.8473310308503006.\n",
      "[I 2025-03-20 03:08:40,255] Trial 17 finished with value: 0.8202227398474863 and parameters: {'hidden_dim': 94, 'dropout': 0.4193360406518387, 'learning_rate': 0.0013451095609937336, 'batch_size': 64, 'weight_decay': 1.2590147439511592e-05}. Best is trial 1 with value: 0.8473310308503006.\n",
      "[I 2025-03-20 03:08:47,995] Trial 18 finished with value: 0.8484464018439678 and parameters: {'hidden_dim': 56, 'dropout': 0.4439213695777281, 'learning_rate': 0.0032284878090172676, 'batch_size': 32, 'weight_decay': 4.8604070414660265e-05}. Best is trial 18 with value: 0.8484464018439678.\n",
      "[I 2025-03-20 03:08:52,634] Trial 19 finished with value: 0.5976696130854346 and parameters: {'hidden_dim': 52, 'dropout': 0.327392532265835, 'learning_rate': 0.00011600174401008022, 'batch_size': 32, 'weight_decay': 5.402261967089256e-05}. Best is trial 18 with value: 0.8484464018439678.\n",
      "[I 2025-03-20 03:08:55,438] Trial 20 finished with value: 0.6574512961683348 and parameters: {'hidden_dim': 40, 'dropout': 0.44802071171540514, 'learning_rate': 0.0005265287236936856, 'batch_size': 64, 'weight_decay': 2.4160440148416682e-05}. Best is trial 18 with value: 0.8484464018439678.\n",
      "[I 2025-03-20 03:08:59,962] Trial 21 finished with value: 0.7983204215962836 and parameters: {'hidden_dim': 68, 'dropout': 0.41776639032857393, 'learning_rate': 0.00284387422508719, 'batch_size': 32, 'weight_decay': 3.0688972445372824e-05}. Best is trial 18 with value: 0.8484464018439678.\n",
      "[I 2025-03-20 03:09:04,557] Trial 22 finished with value: 0.8433899274416516 and parameters: {'hidden_dim': 57, 'dropout': 0.47528889001440844, 'learning_rate': 0.005437707796657205, 'batch_size': 32, 'weight_decay': 5.6159876334565605e-05}. Best is trial 18 with value: 0.8484464018439678.\n",
      "[I 2025-03-20 03:09:09,320] Trial 23 finished with value: 0.8405072314808623 and parameters: {'hidden_dim': 74, 'dropout': 0.49848175316745474, 'learning_rate': 0.0014548570208501549, 'batch_size': 32, 'weight_decay': 9.527475608374498e-05}. Best is trial 18 with value: 0.8484464018439678.\n",
      "[I 2025-03-20 03:09:14,015] Trial 24 finished with value: 0.8206793253699948 and parameters: {'hidden_dim': 90, 'dropout': 0.4256716256791634, 'learning_rate': 0.004774143328057438, 'batch_size': 32, 'weight_decay': 1.5807599393858592e-05}. Best is trial 18 with value: 0.8484464018439678.\n",
      "[I 2025-03-20 03:09:21,508] Trial 25 finished with value: 0.8226752991205323 and parameters: {'hidden_dim': 63, 'dropout': 0.397904162020369, 'learning_rate': 0.0026321678891999853, 'batch_size': 32, 'weight_decay': 6.152308135003427e-06}. Best is trial 18 with value: 0.8484464018439678.\n",
      "[I 2025-03-20 03:09:25,941] Trial 26 finished with value: 0.8170625220320961 and parameters: {'hidden_dim': 75, 'dropout': 0.35066510746147644, 'learning_rate': 0.001711491820145518, 'batch_size': 32, 'weight_decay': 3.273959797874742e-05}. Best is trial 18 with value: 0.8484464018439678.\n",
      "[I 2025-03-20 03:09:30,384] Trial 27 finished with value: 0.8202156916406409 and parameters: {'hidden_dim': 53, 'dropout': 0.452324815730481, 'learning_rate': 0.0034718728681609797, 'batch_size': 32, 'weight_decay': 5.6042971628636865e-05}. Best is trial 18 with value: 0.8484464018439678.\n",
      "[I 2025-03-20 03:09:32,990] Trial 28 finished with value: 0.7940577321408965 and parameters: {'hidden_dim': 107, 'dropout': 0.2574861476582606, 'learning_rate': 0.005781365578326072, 'batch_size': 64, 'weight_decay': 3.14011717940646e-06}. Best is trial 18 with value: 0.8484464018439678.\n",
      "[I 2025-03-20 03:09:37,316] Trial 29 finished with value: 0.7750393069105037 and parameters: {'hidden_dim': 41, 'dropout': 0.4679389748062319, 'learning_rate': 0.00966677059319195, 'batch_size': 32, 'weight_decay': 2.7557222702729444e-05}. Best is trial 18 with value: 0.8484464018439678.\n",
      "[I 2025-03-20 03:09:45,248] Trial 30 finished with value: 0.8240410930066102 and parameters: {'hidden_dim': 86, 'dropout': 0.4410656741454405, 'learning_rate': 0.0006571980116980218, 'batch_size': 16, 'weight_decay': 1.4374740702263345e-05}. Best is trial 18 with value: 0.8484464018439678.\n",
      "[I 2025-03-20 03:09:52,720] Trial 31 finished with value: 0.771448044292872 and parameters: {'hidden_dim': 55, 'dropout': 0.47529345195041006, 'learning_rate': 0.0056222568971966095, 'batch_size': 32, 'weight_decay': 5.619148274493082e-05}. Best is trial 18 with value: 0.8484464018439678.\n",
      "[I 2025-03-20 03:09:57,125] Trial 32 finished with value: 0.7876003260131048 and parameters: {'hidden_dim': 60, 'dropout': 0.4732305381417601, 'learning_rate': 0.0071096489098099475, 'batch_size': 32, 'weight_decay': 5.376340839684544e-05}. Best is trial 18 with value: 0.8484464018439678.\n",
      "[I 2025-03-20 03:10:01,431] Trial 33 finished with value: 0.829773503860725 and parameters: {'hidden_dim': 73, 'dropout': 0.40099284460719675, 'learning_rate': 0.004352987317951419, 'batch_size': 32, 'weight_decay': 1.8076931900171943e-05}. Best is trial 18 with value: 0.8484464018439678.\n",
      "[I 2025-03-20 03:10:05,755] Trial 34 finished with value: 0.859894774296397 and parameters: {'hidden_dim': 34, 'dropout': 0.45309935929808925, 'learning_rate': 0.001958545338827777, 'batch_size': 32, 'weight_decay': 7.22298639898742e-05}. Best is trial 34 with value: 0.859894774296397.\n",
      "[I 2025-03-20 03:10:13,753] Trial 35 finished with value: 0.8373252292369938 and parameters: {'hidden_dim': 36, 'dropout': 0.43872619735770246, 'learning_rate': 0.0017177067175062383, 'batch_size': 16, 'weight_decay': 4.191750395509523e-05}. Best is trial 34 with value: 0.859894774296397.\n",
      "[I 2025-03-20 03:10:18,140] Trial 36 finished with value: 0.7285601493765794 and parameters: {'hidden_dim': 32, 'dropout': 0.2546232321589963, 'learning_rate': 0.00030635383176865627, 'batch_size': 32, 'weight_decay': 6.712400079388522e-05}. Best is trial 34 with value: 0.859894774296397.\n",
      "[I 2025-03-20 03:10:25,900] Trial 37 finished with value: 0.8436362225408879 and parameters: {'hidden_dim': 46, 'dropout': 0.16589883693649712, 'learning_rate': 0.001264143156657443, 'batch_size': 32, 'weight_decay': 9.693226551747323e-05}. Best is trial 34 with value: 0.859894774296397.\n",
      "[I 2025-03-20 03:10:33,952] Trial 38 finished with value: 0.8472371751529968 and parameters: {'hidden_dim': 47, 'dropout': 0.1399216444007724, 'learning_rate': 0.001993727477152352, 'batch_size': 16, 'weight_decay': 9.238346234705445e-05}. Best is trial 34 with value: 0.859894774296397.\n",
      "[I 2025-03-20 03:10:41,854] Trial 39 finished with value: 0.8568181339733063 and parameters: {'hidden_dim': 49, 'dropout': 0.12429336082410652, 'learning_rate': 0.0021188351467055057, 'batch_size': 16, 'weight_decay': 8.033787949783035e-06}. Best is trial 34 with value: 0.859894774296397.\n",
      "[I 2025-03-20 03:10:49,678] Trial 40 finished with value: 0.8304324750825766 and parameters: {'hidden_dim': 40, 'dropout': 0.2276161279924873, 'learning_rate': 0.0010757134687448117, 'batch_size': 16, 'weight_decay': 9.16780391013495e-06}. Best is trial 34 with value: 0.859894774296397.\n",
      "[I 2025-03-20 03:11:00,898] Trial 41 finished with value: 0.8472499093949399 and parameters: {'hidden_dim': 49, 'dropout': 0.12241288984073462, 'learning_rate': 0.0018285367885149512, 'batch_size': 16, 'weight_decay': 8.156271254562448e-06}. Best is trial 34 with value: 0.859894774296397.\n",
      "[I 2025-03-20 03:11:08,964] Trial 42 finished with value: 0.8639533959767225 and parameters: {'hidden_dim': 49, 'dropout': 0.11285998363654516, 'learning_rate': 0.0028135812961768984, 'batch_size': 16, 'weight_decay': 7.503477631876396e-06}. Best is trial 42 with value: 0.8639533959767225.\n",
      "[I 2025-03-20 03:11:17,125] Trial 43 finished with value: 0.8446825355547465 and parameters: {'hidden_dim': 32, 'dropout': 0.10989966674254059, 'learning_rate': 0.0027688597595214885, 'batch_size': 16, 'weight_decay': 3.693269749092597e-06}. Best is trial 42 with value: 0.8639533959767225.\n",
      "[I 2025-03-20 03:11:25,316] Trial 44 finished with value: 0.8715368228045713 and parameters: {'hidden_dim': 43, 'dropout': 0.1626932075937906, 'learning_rate': 0.0023218804950543865, 'batch_size': 16, 'weight_decay': 2.394079281488213e-06}. Best is trial 44 with value: 0.8715368228045713.\n",
      "[I 2025-03-20 03:11:36,301] Trial 45 finished with value: 0.8355951369643053 and parameters: {'hidden_dim': 42, 'dropout': 0.16236712898351485, 'learning_rate': 0.002195686408894806, 'batch_size': 16, 'weight_decay': 2.3006820206178384e-06}. Best is trial 44 with value: 0.8715368228045713.\n",
      "[I 2025-03-20 03:11:44,064] Trial 46 finished with value: 0.8260673338005994 and parameters: {'hidden_dim': 37, 'dropout': 0.13448060846045945, 'learning_rate': 0.00279052830367328, 'batch_size': 16, 'weight_decay': 1.5557713701610666e-06}. Best is trial 44 with value: 0.8715368228045713.\n",
      "[I 2025-03-20 03:11:51,915] Trial 47 finished with value: 0.8487585249248536 and parameters: {'hidden_dim': 49, 'dropout': 0.19615280538338178, 'learning_rate': 0.001120892750944069, 'batch_size': 16, 'weight_decay': 6.258814590863016e-06}. Best is trial 44 with value: 0.8715368228045713.\n",
      "[I 2025-03-20 03:12:00,274] Trial 48 finished with value: 0.7905154767477282 and parameters: {'hidden_dim': 50, 'dropout': 0.19603730445451786, 'learning_rate': 0.0007752786686780675, 'batch_size': 16, 'weight_decay': 7.135210684956339e-06}. Best is trial 44 with value: 0.8715368228045713.\n",
      "[I 2025-03-20 03:12:11,784] Trial 49 finished with value: 0.8253045279414448 and parameters: {'hidden_dim': 46, 'dropout': 0.1001371746411079, 'learning_rate': 0.001073857276998066, 'batch_size': 16, 'weight_decay': 2.195041930350694e-06}. Best is trial 44 with value: 0.8715368228045713.\n",
      "[I 2025-03-20 03:12:19,799] Trial 50 finished with value: 0.8748025057355687 and parameters: {'hidden_dim': 36, 'dropout': 0.19050735829303594, 'learning_rate': 0.001354250340464109, 'batch_size': 16, 'weight_decay': 1.025194793488667e-06}. Best is trial 50 with value: 0.8748025057355687.\n",
      "[I 2025-03-20 03:12:28,159] Trial 51 finished with value: 0.8372811960033055 and parameters: {'hidden_dim': 35, 'dropout': 0.18742505224288417, 'learning_rate': 0.0013616174462995991, 'batch_size': 16, 'weight_decay': 1.1213720307837932e-06}. Best is trial 50 with value: 0.8748025057355687.\n",
      "[I 2025-03-20 03:12:39,652] Trial 52 finished with value: 0.8485349842854912 and parameters: {'hidden_dim': 43, 'dropout': 0.1489322427619982, 'learning_rate': 0.0022327232133972415, 'batch_size': 16, 'weight_decay': 4.773336587482316e-06}. Best is trial 50 with value: 0.8748025057355687.\n",
      "[I 2025-03-20 03:12:47,615] Trial 53 finished with value: 0.8556405261780515 and parameters: {'hidden_dim': 37, 'dropout': 0.22267196998302993, 'learning_rate': 0.001514810352193557, 'batch_size': 16, 'weight_decay': 2.1021258479744017e-06}. Best is trial 50 with value: 0.8748025057355687.\n",
      "[I 2025-03-20 03:12:55,664] Trial 54 finished with value: 0.8433106634932193 and parameters: {'hidden_dim': 38, 'dropout': 0.21290651978641842, 'learning_rate': 0.0015114851447527835, 'batch_size': 16, 'weight_decay': 1.0244242630912548e-06}. Best is trial 50 with value: 0.8748025057355687.\n",
      "[I 2025-03-20 03:13:03,822] Trial 55 finished with value: 0.8220903289108157 and parameters: {'hidden_dim': 44, 'dropout': 0.12142187147249787, 'learning_rate': 0.0008281123118630522, 'batch_size': 16, 'weight_decay': 2.071219001915473e-06}. Best is trial 50 with value: 0.8748025057355687.\n",
      "[I 2025-03-20 03:13:15,127] Trial 56 finished with value: 0.8523019361001105 and parameters: {'hidden_dim': 35, 'dropout': 0.15285481525098524, 'learning_rate': 0.001983465782986659, 'batch_size': 16, 'weight_decay': 2.9941829464423103e-06}. Best is trial 50 with value: 0.8748025057355687.\n",
      "[I 2025-03-20 03:13:23,042] Trial 57 finished with value: 0.8456617977282278 and parameters: {'hidden_dim': 61, 'dropout': 0.17423901318979426, 'learning_rate': 0.0035582978961120376, 'batch_size': 16, 'weight_decay': 1.376730635973334e-06}. Best is trial 50 with value: 0.8748025057355687.\n",
      "[I 2025-03-20 03:13:31,032] Trial 58 finished with value: 0.8406187850914018 and parameters: {'hidden_dim': 32, 'dropout': 0.23660174219060934, 'learning_rate': 0.00237065982975658, 'batch_size': 16, 'weight_decay': 1.0854827664305396e-05}. Best is trial 50 with value: 0.8748025057355687.\n",
      "[I 2025-03-20 03:13:33,610] Trial 59 finished with value: 0.7710563889569975 and parameters: {'hidden_dim': 40, 'dropout': 0.2781624991473492, 'learning_rate': 0.0016121311639234596, 'batch_size': 64, 'weight_decay': 1.7582721484052059e-06}. Best is trial 50 with value: 0.8748025057355687.\n",
      "[I 2025-03-20 03:13:44,991] Trial 60 finished with value: 0.8723278214911074 and parameters: {'hidden_dim': 44, 'dropout': 0.21005012950803137, 'learning_rate': 0.0012590900815606107, 'batch_size': 16, 'weight_decay': 4.141871928899893e-06}. Best is trial 50 with value: 0.8748025057355687.\n",
      "[I 2025-03-20 03:13:53,199] Trial 61 finished with value: 0.839476366732959 and parameters: {'hidden_dim': 44, 'dropout': 0.21417495234027403, 'learning_rate': 0.0009180743968771122, 'batch_size': 16, 'weight_decay': 4.913372600971364e-06}. Best is trial 50 with value: 0.8748025057355687.\n",
      "[I 2025-03-20 03:14:01,420] Trial 62 finished with value: 0.8633450934160872 and parameters: {'hidden_dim': 37, 'dropout': 0.18329479422642064, 'learning_rate': 0.001291569580778625, 'batch_size': 16, 'weight_decay': 2.63293172580204e-06}. Best is trial 50 with value: 0.8748025057355687.\n",
      "[I 2025-03-20 03:14:09,591] Trial 63 finished with value: 0.8465109209024018 and parameters: {'hidden_dim': 52, 'dropout': 0.17918061911552344, 'learning_rate': 0.0007223456318925999, 'batch_size': 16, 'weight_decay': 3.8730125177723115e-06}. Best is trial 50 with value: 0.8748025057355687.\n",
      "[I 2025-03-20 03:14:20,663] Trial 64 finished with value: 0.8038940775249092 and parameters: {'hidden_dim': 39, 'dropout': 0.1279033244489235, 'learning_rate': 0.0006212268041617824, 'batch_size': 16, 'weight_decay': 2.686965976971645e-06}. Best is trial 50 with value: 0.8748025057355687.\n",
      "[I 2025-03-20 03:14:28,560] Trial 65 finished with value: 0.8593135810174349 and parameters: {'hidden_dim': 54, 'dropout': 0.15075602787937206, 'learning_rate': 0.0012723364985793564, 'batch_size': 16, 'weight_decay': 1.2558064027560627e-05}. Best is trial 50 with value: 0.8748025057355687.\n",
      "[I 2025-03-20 03:14:31,132] Trial 66 finished with value: 0.7906113241052389 and parameters: {'hidden_dim': 119, 'dropout': 0.15076079558899297, 'learning_rate': 0.001200308020585357, 'batch_size': 64, 'weight_decay': 3.629159260126858e-06}. Best is trial 50 with value: 0.8748025057355687.\n",
      "[I 2025-03-20 03:14:38,889] Trial 67 finished with value: 0.7942465683591444 and parameters: {'hidden_dim': 56, 'dropout': 0.2041344078935754, 'learning_rate': 0.00036643839139570785, 'batch_size': 16, 'weight_decay': 2.756685177807547e-06}. Best is trial 50 with value: 0.8748025057355687.\n",
      "[I 2025-03-20 03:14:49,949] Trial 68 finished with value: 0.8189995818545515 and parameters: {'hidden_dim': 35, 'dropout': 0.16763883634646642, 'learning_rate': 0.0009279461677437043, 'batch_size': 16, 'weight_decay': 1.2506770977727964e-06}. Best is trial 50 with value: 0.8748025057355687.\n",
      "[I 2025-03-20 03:14:57,904] Trial 69 finished with value: 0.8454451453437254 and parameters: {'hidden_dim': 42, 'dropout': 0.1838052957689855, 'learning_rate': 0.002530828042152304, 'batch_size': 16, 'weight_decay': 4.2676238676269356e-06}. Best is trial 50 with value: 0.8748025057355687.\n",
      "[I 2025-03-20 03:15:05,940] Trial 70 finished with value: 0.8268233752386897 and parameters: {'hidden_dim': 52, 'dropout': 0.3207352127064794, 'learning_rate': 0.0031163468826483644, 'batch_size': 16, 'weight_decay': 3.2971722590929515e-06}. Best is trial 50 with value: 0.8748025057355687.\n",
      "[I 2025-03-20 03:15:14,064] Trial 71 finished with value: 0.8614672158282706 and parameters: {'hidden_dim': 48, 'dropout': 0.1099831960498762, 'learning_rate': 0.0018848306419049852, 'batch_size': 16, 'weight_decay': 1.2538803221094931e-05}. Best is trial 50 with value: 0.8748025057355687.\n",
      "[I 2025-03-20 03:15:25,277] Trial 72 finished with value: 0.851155957520055 and parameters: {'hidden_dim': 46, 'dropout': 0.11400623052584943, 'learning_rate': 0.001822821617977136, 'batch_size': 16, 'weight_decay': 1.7464183439103026e-05}. Best is trial 50 with value: 0.8748025057355687.\n",
      "[I 2025-03-20 03:15:33,166] Trial 73 finished with value: 0.8465948389376381 and parameters: {'hidden_dim': 43, 'dropout': 0.13439840875044345, 'learning_rate': 0.0012193507350741876, 'batch_size': 16, 'weight_decay': 1.2757725416841374e-05}. Best is trial 50 with value: 0.8748025057355687.\n",
      "[I 2025-03-20 03:15:40,986] Trial 74 finished with value: 0.8631716951443117 and parameters: {'hidden_dim': 34, 'dropout': 0.14172726535417643, 'learning_rate': 0.0013643332147668442, 'batch_size': 16, 'weight_decay': 5.321091306557127e-06}. Best is trial 50 with value: 0.8748025057355687.\n",
      "[I 2025-03-20 03:15:49,118] Trial 75 finished with value: 0.8149608664568097 and parameters: {'hidden_dim': 34, 'dropout': 0.11386058290124162, 'learning_rate': 0.001489338608839943, 'batch_size': 16, 'weight_decay': 5.2557094312642475e-06}. Best is trial 50 with value: 0.8748025057355687.\n",
      "[I 2025-03-20 03:15:51,810] Trial 76 finished with value: 0.738818768002338 and parameters: {'hidden_dim': 38, 'dropout': 0.1405472048232842, 'learning_rate': 0.0018939489084232584, 'batch_size': 64, 'weight_decay': 6.928220270367047e-06}. Best is trial 50 with value: 0.8748025057355687.\n",
      "[I 2025-03-20 03:16:03,133] Trial 77 finished with value: 0.8606080775959072 and parameters: {'hidden_dim': 33, 'dropout': 0.24346629039925355, 'learning_rate': 0.0010005962012011966, 'batch_size': 16, 'weight_decay': 5.543260695796428e-06}. Best is trial 50 with value: 0.8748025057355687.\n",
      "[I 2025-03-20 03:16:11,300] Trial 78 finished with value: 0.8761028740998315 and parameters: {'hidden_dim': 41, 'dropout': 0.24516633378016855, 'learning_rate': 0.0010847094119055844, 'batch_size': 16, 'weight_decay': 5.782211158231535e-06}. Best is trial 78 with value: 0.8761028740998315.\n",
      "[I 2025-03-20 03:16:19,302] Trial 79 finished with value: 0.8360760971055088 and parameters: {'hidden_dim': 41, 'dropout': 0.20055217092234845, 'learning_rate': 0.0013627216945165392, 'batch_size': 16, 'weight_decay': 9.525012588053956e-06}. Best is trial 78 with value: 0.8761028740998315.\n",
      "[I 2025-03-20 03:16:30,637] Trial 80 finished with value: 0.8403166099920664 and parameters: {'hidden_dim': 48, 'dropout': 0.26430644028768957, 'learning_rate': 0.0016044841436199868, 'batch_size': 16, 'weight_decay': 4.2164807383998855e-06}. Best is trial 78 with value: 0.8761028740998315.\n",
      "[I 2025-03-20 03:16:38,678] Trial 81 finished with value: 0.8049004025423905 and parameters: {'hidden_dim': 39, 'dropout': 0.24504547542043342, 'learning_rate': 0.0009709389594101939, 'batch_size': 16, 'weight_decay': 5.644231977915015e-06}. Best is trial 78 with value: 0.8761028740998315.\n",
      "[I 2025-03-20 03:16:46,649] Trial 82 finished with value: 0.7588073381430379 and parameters: {'hidden_dim': 37, 'dropout': 0.23151299574205836, 'learning_rate': 0.0005922430502333082, 'batch_size': 16, 'weight_decay': 7.97183359824792e-06}. Best is trial 78 with value: 0.8761028740998315.\n",
      "[I 2025-03-20 03:16:54,550] Trial 83 finished with value: 0.8552695923639129 and parameters: {'hidden_dim': 32, 'dropout': 0.27448417452113755, 'learning_rate': 0.0010565314670409852, 'batch_size': 16, 'weight_decay': 5.9017016427780485e-06}. Best is trial 78 with value: 0.8761028740998315.\n",
      "[I 2025-03-20 03:17:05,848] Trial 84 finished with value: 0.8512869014390313 and parameters: {'hidden_dim': 45, 'dropout': 0.16023928843829316, 'learning_rate': 0.0006983406279384726, 'batch_size': 16, 'weight_decay': 6.699256307615192e-06}. Best is trial 78 with value: 0.8761028740998315.\n",
      "[I 2025-03-20 03:17:13,789] Trial 85 finished with value: 0.8411687722539649 and parameters: {'hidden_dim': 58, 'dropout': 0.24236613674297808, 'learning_rate': 0.0011240542607919592, 'batch_size': 16, 'weight_decay': 2.5541606185058435e-06}. Best is trial 78 with value: 0.8761028740998315.\n",
      "[I 2025-03-20 03:17:21,625] Trial 86 finished with value: 0.8620921533953988 and parameters: {'hidden_dim': 51, 'dropout': 0.18905688918908953, 'learning_rate': 0.0008541741530013634, 'batch_size': 16, 'weight_decay': 1.7479369903558086e-06}. Best is trial 78 with value: 0.8761028740998315.\n",
      "[I 2025-03-20 03:17:29,438] Trial 87 finished with value: 0.8379298064642892 and parameters: {'hidden_dim': 48, 'dropout': 0.18722186649111364, 'learning_rate': 0.0008734168623773422, 'batch_size': 16, 'weight_decay': 1.8943392411370128e-06}. Best is trial 78 with value: 0.8761028740998315.\n",
      "[I 2025-03-20 03:17:40,487] Trial 88 finished with value: 0.8535733892731865 and parameters: {'hidden_dim': 50, 'dropout': 0.1725180230659831, 'learning_rate': 0.0024782727797444575, 'batch_size': 16, 'weight_decay': 1.4298267629674109e-06}. Best is trial 78 with value: 0.8761028740998315.\n",
      "[I 2025-03-20 03:17:48,335] Trial 89 finished with value: 0.8498609346479529 and parameters: {'hidden_dim': 42, 'dropout': 0.20392259618192837, 'learning_rate': 0.003041427270475568, 'batch_size': 16, 'weight_decay': 1.6055052171373408e-06}. Best is trial 78 with value: 0.8761028740998315.\n",
      "[I 2025-03-20 03:17:56,225] Trial 90 finished with value: 0.8475061421562436 and parameters: {'hidden_dim': 63, 'dropout': 0.10262685302159874, 'learning_rate': 0.0014027279166454907, 'batch_size': 16, 'weight_decay': 3.338443752296114e-06}. Best is trial 78 with value: 0.8761028740998315.\n",
      "[I 2025-03-20 03:18:04,202] Trial 91 finished with value: 0.820099535540712 and parameters: {'hidden_dim': 45, 'dropout': 0.21935283909353592, 'learning_rate': 0.0007956528969312923, 'batch_size': 16, 'weight_decay': 2.40042089319498e-06}. Best is trial 78 with value: 0.8761028740998315.\n",
      "[I 2025-03-20 03:18:15,767] Trial 92 finished with value: 0.8009133567957097 and parameters: {'hidden_dim': 36, 'dropout': 0.29687562530746303, 'learning_rate': 0.0005266748729864536, 'batch_size': 16, 'weight_decay': 4.944464032481522e-06}. Best is trial 78 with value: 0.8761028740998315.\n",
      "[I 2025-03-20 03:18:24,155] Trial 93 finished with value: 0.8677082636768235 and parameters: {'hidden_dim': 40, 'dropout': 0.19033240571835133, 'learning_rate': 0.0009878011026311518, 'batch_size': 16, 'weight_decay': 8.703050582266606e-06}. Best is trial 78 with value: 0.8761028740998315.\n",
      "[I 2025-03-20 03:18:32,225] Trial 94 finished with value: 0.8320573189487996 and parameters: {'hidden_dim': 40, 'dropout': 0.1933397305678244, 'learning_rate': 0.0016813661995107112, 'batch_size': 16, 'weight_decay': 7.759148314224408e-06}. Best is trial 78 with value: 0.8761028740998315.\n",
      "[I 2025-03-20 03:18:43,518] Trial 95 finished with value: 0.8146690005209275 and parameters: {'hidden_dim': 51, 'dropout': 0.15985635906568219, 'learning_rate': 0.0011870336908343189, 'batch_size': 16, 'weight_decay': 1.0323311488093715e-05}. Best is trial 78 with value: 0.8761028740998315.\n",
      "[I 2025-03-20 03:18:51,596] Trial 96 finished with value: 0.8575670601279121 and parameters: {'hidden_dim': 47, 'dropout': 0.14213094638594842, 'learning_rate': 0.0013409938171340479, 'batch_size': 16, 'weight_decay': 1.8508320097291112e-06}. Best is trial 78 with value: 0.8761028740998315.\n",
      "[I 2025-03-20 03:18:59,716] Trial 97 finished with value: 0.8803320355551593 and parameters: {'hidden_dim': 44, 'dropout': 0.21278521272207102, 'learning_rate': 0.002100548251322848, 'batch_size': 16, 'weight_decay': 1.1620798961854362e-05}. Best is trial 97 with value: 0.8803320355551593.\n",
      "[I 2025-03-20 03:19:02,438] Trial 98 finished with value: 0.7789610612886474 and parameters: {'hidden_dim': 44, 'dropout': 0.17920150565783907, 'learning_rate': 0.0007651429838386861, 'batch_size': 64, 'weight_decay': 6.460242500546724e-06}. Best is trial 97 with value: 0.8803320355551593.\n",
      "[I 2025-03-20 03:19:13,792] Trial 99 finished with value: 0.8358495122186805 and parameters: {'hidden_dim': 39, 'dropout': 0.20859203304514592, 'learning_rate': 0.002125648552897958, 'batch_size': 16, 'weight_decay': 8.876142864030716e-06}. Best is trial 97 with value: 0.8803320355551593.\n",
      "[I 2025-03-20 03:19:13,805] A new study created in memory with name: no-name-d5c0c197-9c8f-459e-9e24-2a9c3867ef59\n",
      "[I 2025-03-20 03:19:13,956] Trial 0 finished with value: 0.7520905550655581 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.013661178428178952, 'n_estimators': 456, 'num_leaves': 48, 'max_depth': 6, 'subsample': 0.7552942184455931, 'colsample_bytree': 0.7030385741204636, 'reg_alpha': 1.3087232248047334, 'reg_lambda': 0.6869757398160233, 'min_child_samples': 49}. Best is trial 0 with value: 0.7520905550655581.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best LSTM Parameters:\n",
      "  hidden_dim: 44\n",
      "  dropout: 0.21278521272207102\n",
      "  learning_rate: 0.002100548251322848\n",
      "  batch_size: 16\n",
      "  weight_decay: 1.1620798961854362e-05\n",
      "\n",
      "Optimizing LightGBM for fold 3 using min_max normalization\n",
      "Optimizing LightGBM hyperparameters with CV...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-20 03:19:14,049] Trial 1 finished with value: 0.7880030383949126 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.06323892443630524, 'n_estimators': 282, 'num_leaves': 42, 'max_depth': 3, 'subsample': 0.9077831487751247, 'colsample_bytree': 0.6012684467021177, 'reg_alpha': 0.31439409038438626, 'reg_lambda': 1.0912521853098582, 'min_child_samples': 47}. Best is trial 1 with value: 0.7880030383949126.\n",
      "[I 2025-03-20 03:19:14,164] Trial 2 finished with value: 0.7655191621069479 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.019957907467756848, 'n_estimators': 199, 'num_leaves': 37, 'max_depth': 10, 'subsample': 0.7873081624297713, 'colsample_bytree': 0.6493149518105418, 'reg_alpha': 3.6000609130029044, 'reg_lambda': 4.050134848257446, 'min_child_samples': 21}. Best is trial 1 with value: 0.7880030383949126.\n",
      "[I 2025-03-20 03:19:14,254] Trial 3 finished with value: 0.7896381925193945 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.03308671790989007, 'n_estimators': 162, 'num_leaves': 10, 'max_depth': 5, 'subsample': 0.9963593754983149, 'colsample_bytree': 0.805256515122397, 'reg_alpha': 3.0841806167907238, 'reg_lambda': 0.1301677362213169, 'min_child_samples': 21}. Best is trial 3 with value: 0.7896381925193945.\n",
      "[I 2025-03-20 03:19:14,452] Trial 4 finished with value: 0.7797188226244035 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.029437387715603364, 'n_estimators': 405, 'num_leaves': 47, 'max_depth': 6, 'subsample': 0.9716350708762611, 'colsample_bytree': 0.7998448041733087, 'reg_alpha': 2.304933318498776, 'reg_lambda': 3.3362817514757888, 'min_child_samples': 29}. Best is trial 3 with value: 0.7896381925193945.\n",
      "[I 2025-03-20 03:19:14,512] Trial 5 finished with value: 0.7633359417922463 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.07045793365915588, 'n_estimators': 210, 'num_leaves': 23, 'max_depth': 3, 'subsample': 0.8092590874861125, 'colsample_bytree': 0.859403208540551, 'reg_alpha': 3.3760828530802196, 'reg_lambda': 0.15012918259918107, 'min_child_samples': 22}. Best is trial 3 with value: 0.7896381925193945.\n",
      "[I 2025-03-20 03:19:14,702] Trial 6 finished with value: 0.7949132420377651 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.011970252710206382, 'n_estimators': 476, 'num_leaves': 49, 'max_depth': 4, 'subsample': 0.9816084577717837, 'colsample_bytree': 0.7776193095921519, 'reg_alpha': 0.2802529145561249, 'reg_lambda': 1.3744727196612017, 'min_child_samples': 25}. Best is trial 6 with value: 0.7949132420377651.\n",
      "[I 2025-03-20 03:19:14,827] Trial 7 finished with value: 0.8229468221353724 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.0967088301559984, 'n_estimators': 367, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.6725825297010686, 'colsample_bytree': 0.7765487989776441, 'reg_alpha': 1.3901311581414446, 'reg_lambda': 1.2894120399825089, 'min_child_samples': 25}. Best is trial 7 with value: 0.8229468221353724.\n",
      "[I 2025-03-20 03:19:14,970] Trial 8 finished with value: 0.8047708545568181 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.04669085237595252, 'n_estimators': 388, 'num_leaves': 42, 'max_depth': 5, 'subsample': 0.6388242673991037, 'colsample_bytree': 0.9337670455562896, 'reg_alpha': 0.11037032003620384, 'reg_lambda': 0.25448376172072, 'min_child_samples': 45}. Best is trial 7 with value: 0.8229468221353724.\n",
      "[I 2025-03-20 03:19:15,063] Trial 9 finished with value: 0.7915462230828828 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.011232085595448875, 'n_estimators': 177, 'num_leaves': 29, 'max_depth': 4, 'subsample': 0.7436406503252848, 'colsample_bytree': 0.6580654068535353, 'reg_alpha': 0.1699984374960256, 'reg_lambda': 0.1466016632681982, 'min_child_samples': 16}. Best is trial 7 with value: 0.8229468221353724.\n",
      "[I 2025-03-20 03:19:15,220] Trial 10 finished with value: 0.8263355427711302 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.0987558719383339, 'n_estimators': 337, 'num_leaves': 18, 'max_depth': 10, 'subsample': 0.642242017563948, 'colsample_bytree': 0.9614634142305828, 'reg_alpha': 0.7548915517607346, 'reg_lambda': 0.47191940414066896, 'min_child_samples': 37}. Best is trial 10 with value: 0.8263355427711302.\n",
      "[I 2025-03-20 03:19:15,374] Trial 11 finished with value: 0.8184050135059792 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.08811492902543544, 'n_estimators': 327, 'num_leaves': 17, 'max_depth': 10, 'subsample': 0.6019793854602531, 'colsample_bytree': 0.993860589036455, 'reg_alpha': 0.7915653922317443, 'reg_lambda': 0.4908802288038389, 'min_child_samples': 38}. Best is trial 10 with value: 0.8263355427711302.\n",
      "[I 2025-03-20 03:19:15,519] Trial 12 finished with value: 0.8188655520792546 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.09822003027572318, 'n_estimators': 307, 'num_leaves': 30, 'max_depth': 8, 'subsample': 0.6801173039155465, 'colsample_bytree': 0.893626879385864, 'reg_alpha': 0.8750718436454238, 'reg_lambda': 1.8653713281408886, 'min_child_samples': 37}. Best is trial 10 with value: 0.8263355427711302.\n",
      "[I 2025-03-20 03:19:15,709] Trial 13 finished with value: 0.8375268806679731 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.05345803972760133, 'n_estimators': 371, 'num_leaves': 19, 'max_depth': 8, 'subsample': 0.6866546830080261, 'colsample_bytree': 0.739487019699413, 'reg_alpha': 1.3765039473276297, 'reg_lambda': 0.36073977073087093, 'min_child_samples': 10}. Best is trial 13 with value: 0.8375268806679731.\n",
      "[I 2025-03-20 03:19:15,942] Trial 14 finished with value: 0.851574054099142 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.05100525278048549, 'n_estimators': 257, 'num_leaves': 16, 'max_depth': 8, 'subsample': 0.7213915181789433, 'colsample_bytree': 0.9955930766794112, 'reg_alpha': 0.4759657006669087, 'reg_lambda': 0.3531473318787954, 'min_child_samples': 10}. Best is trial 14 with value: 0.851574054099142.\n",
      "[I 2025-03-20 03:19:16,047] Trial 15 finished with value: 0.8348285791439494 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.043288657420412956, 'n_estimators': 128, 'num_leaves': 11, 'max_depth': 8, 'subsample': 0.728281809019484, 'colsample_bytree': 0.7201040728875937, 'reg_alpha': 0.40032058910065316, 'reg_lambda': 0.27407685686214406, 'min_child_samples': 13}. Best is trial 14 with value: 0.851574054099142.\n",
      "[I 2025-03-20 03:19:16,295] Trial 16 finished with value: 0.8568752443232881 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.049153270642365854, 'n_estimators': 257, 'num_leaves': 23, 'max_depth': 8, 'subsample': 0.8460344390937014, 'colsample_bytree': 0.8679612440467525, 'reg_alpha': 0.4703040391963052, 'reg_lambda': 0.2514535341033357, 'min_child_samples': 10}. Best is trial 16 with value: 0.8568752443232881.\n",
      "[I 2025-03-20 03:19:16,503] Trial 17 finished with value: 0.850697646048434 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.03350416889348262, 'n_estimators': 255, 'num_leaves': 25, 'max_depth': 7, 'subsample': 0.872602340863694, 'colsample_bytree': 0.8654355879743639, 'reg_alpha': 0.4952065943462705, 'reg_lambda': 0.22075145628542162, 'min_child_samples': 15}. Best is trial 16 with value: 0.8568752443232881.\n",
      "[I 2025-03-20 03:19:16,720] Trial 18 finished with value: 0.8547579456028501 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.0276669503148614, 'n_estimators': 247, 'num_leaves': 14, 'max_depth': 9, 'subsample': 0.8556167667539123, 'colsample_bytree': 0.9117968576699139, 'reg_alpha': 0.2193792490608938, 'reg_lambda': 0.6912140904160914, 'min_child_samples': 10}. Best is trial 16 with value: 0.8568752443232881.\n",
      "[I 2025-03-20 03:19:16,934] Trial 19 finished with value: 0.8430588984075691 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.02268851777434901, 'n_estimators': 236, 'num_leaves': 24, 'max_depth': 9, 'subsample': 0.8566733671392915, 'colsample_bytree': 0.9103587281284006, 'reg_alpha': 0.14718132961011152, 'reg_lambda': 0.7268115000906161, 'min_child_samples': 17}. Best is trial 16 with value: 0.8568752443232881.\n",
      "[I 2025-03-20 03:19:17,013] Trial 20 finished with value: 0.7594793181027747 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.01939122134584428, 'n_estimators': 102, 'num_leaves': 13, 'max_depth': 9, 'subsample': 0.917783483703512, 'colsample_bytree': 0.8396404212791115, 'reg_alpha': 0.231201863633108, 'reg_lambda': 0.10341899854233196, 'min_child_samples': 31}. Best is trial 16 with value: 0.8568752443232881.\n",
      "[I 2025-03-20 03:19:17,268] Trial 21 finished with value: 0.8537798114011622 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.03874967976830049, 'n_estimators': 274, 'num_leaves': 15, 'max_depth': 7, 'subsample': 0.8362444070837092, 'colsample_bytree': 0.9990162550266966, 'reg_alpha': 0.4851853443851495, 'reg_lambda': 0.6708340206397443, 'min_child_samples': 10}. Best is trial 16 with value: 0.8568752443232881.\n",
      "[I 2025-03-20 03:19:17,567] Trial 22 finished with value: 0.8596451443384033 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.038261080720092266, 'n_estimators': 297, 'num_leaves': 22, 'max_depth': 7, 'subsample': 0.8363068228380048, 'colsample_bytree': 0.9485703106943153, 'reg_alpha': 0.20836809016002875, 'reg_lambda': 0.8007942833689408, 'min_child_samples': 12}. Best is trial 22 with value: 0.8596451443384033.\n",
      "[I 2025-03-20 03:19:17,772] Trial 23 finished with value: 0.8334544505279231 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.024573230187368317, 'n_estimators': 226, 'num_leaves': 22, 'max_depth': 9, 'subsample': 0.9032042430937963, 'colsample_bytree': 0.9424799839672464, 'reg_alpha': 0.19030637771004824, 'reg_lambda': 2.593560466402131, 'min_child_samples': 14}. Best is trial 22 with value: 0.8596451443384033.\n",
      "[I 2025-03-20 03:19:17,986] Trial 24 finished with value: 0.8473964170987255 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.028200311646237337, 'n_estimators': 305, 'num_leaves': 34, 'max_depth': 7, 'subsample': 0.8041100302663126, 'colsample_bytree': 0.8910864011293338, 'reg_alpha': 0.11974739894585185, 'reg_lambda': 0.9095659496080455, 'min_child_samples': 18}. Best is trial 22 with value: 0.8596451443384033.\n",
      "[I 2025-03-20 03:19:18,357] Trial 25 finished with value: 0.847390430152284 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.038649356513073406, 'n_estimators': 426, 'num_leaves': 26, 'max_depth': 9, 'subsample': 0.9381892423135044, 'colsample_bytree': 0.9306719574768028, 'reg_alpha': 0.32910675150462587, 'reg_lambda': 2.0491204012186, 'min_child_samples': 13}. Best is trial 22 with value: 0.8596451443384033.\n",
      "[I 2025-03-20 03:19:18,604] Trial 26 finished with value: 0.8376662898262264 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.016236598545921726, 'n_estimators': 348, 'num_leaves': 20, 'max_depth': 7, 'subsample': 0.8711405729105965, 'colsample_bytree': 0.8398323788872903, 'reg_alpha': 0.24368736736346555, 'reg_lambda': 0.46145237339925765, 'min_child_samples': 19}. Best is trial 22 with value: 0.8596451443384033.\n",
      "[I 2025-03-20 03:19:18,877] Trial 27 finished with value: 0.8560663192990592 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.06339622234305062, 'n_estimators': 292, 'num_leaves': 28, 'max_depth': 8, 'subsample': 0.8247539939838564, 'colsample_bytree': 0.9666101985593151, 'reg_alpha': 0.20209768644723336, 'reg_lambda': 0.19162343172746513, 'min_child_samples': 12}. Best is trial 22 with value: 0.8596451443384033.\n",
      "[I 2025-03-20 03:19:19,120] Trial 28 finished with value: 0.855073991093646 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.06405780828170501, 'n_estimators': 309, 'num_leaves': 29, 'max_depth': 6, 'subsample': 0.7854608637116649, 'colsample_bytree': 0.9576271686336337, 'reg_alpha': 0.14212250851978403, 'reg_lambda': 0.18386666651483977, 'min_child_samples': 13}. Best is trial 22 with value: 0.8596451443384033.\n",
      "[I 2025-03-20 03:19:19,296] Trial 29 finished with value: 0.8352609763501494 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.07100932147957231, 'n_estimators': 286, 'num_leaves': 33, 'max_depth': 6, 'subsample': 0.7594198842677128, 'colsample_bytree': 0.9611303673491199, 'reg_alpha': 0.59998402374673, 'reg_lambda': 0.31588427804003605, 'min_child_samples': 24}. Best is trial 22 with value: 0.8596451443384033.\n",
      "[I 2025-03-20 03:19:19,428] Trial 30 finished with value: 0.8145103779245572 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.056595538328310095, 'n_estimators': 190, 'num_leaves': 26, 'max_depth': 8, 'subsample': 0.834950384334098, 'colsample_bytree': 0.874810809235518, 'reg_alpha': 1.006479387826592, 'reg_lambda': 0.19460830538811472, 'min_child_samples': 30}. Best is trial 22 with value: 0.8596451443384033.\n",
      "[I 2025-03-20 03:19:19,680] Trial 31 finished with value: 0.861292236822857 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.0695047657232799, 'n_estimators': 316, 'num_leaves': 29, 'max_depth': 6, 'subsample': 0.7735182246208606, 'colsample_bytree': 0.9605942242393898, 'reg_alpha': 0.14568751194733093, 'reg_lambda': 0.18609839616575088, 'min_child_samples': 13}. Best is trial 31 with value: 0.861292236822857.\n",
      "[I 2025-03-20 03:19:19,926] Trial 32 finished with value: 0.859868907283178 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.07587641539606522, 'n_estimators': 268, 'num_leaves': 32, 'max_depth': 7, 'subsample': 0.8351881336148554, 'colsample_bytree': 0.9648472250748434, 'reg_alpha': 0.10165090283616454, 'reg_lambda': 0.1780446607995051, 'min_child_samples': 13}. Best is trial 31 with value: 0.861292236822857.\n",
      "[I 2025-03-20 03:19:20,101] Trial 33 finished with value: 0.8520916026158192 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.08644342577130426, 'n_estimators': 270, 'num_leaves': 33, 'max_depth': 5, 'subsample': 0.7592117426478897, 'colsample_bytree': 0.9148354302725099, 'reg_alpha': 0.10139573553788836, 'reg_lambda': 0.11942786604693309, 'min_child_samples': 19}. Best is trial 31 with value: 0.861292236822857.\n",
      "[I 2025-03-20 03:19:20,298] Trial 34 finished with value: 0.8549680908347046 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.07923781116698583, 'n_estimators': 216, 'num_leaves': 39, 'max_depth': 7, 'subsample': 0.7840997785027541, 'colsample_bytree': 0.9332292713691073, 'reg_alpha': 0.1426062470714311, 'reg_lambda': 0.16196406421905932, 'min_child_samples': 15}. Best is trial 31 with value: 0.861292236822857.\n",
      "[I 2025-03-20 03:19:20,529] Trial 35 finished with value: 0.8534866412244432 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.04288398412048482, 'n_estimators': 323, 'num_leaves': 36, 'max_depth': 6, 'subsample': 0.8757607203381023, 'colsample_bytree': 0.9753183335378762, 'reg_alpha': 0.34141341514533297, 'reg_lambda': 0.10195611732775527, 'min_child_samples': 17}. Best is trial 31 with value: 0.861292236822857.\n",
      "[I 2025-03-20 03:19:20,725] Trial 36 finished with value: 0.8461487565343384 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.0747332609635698, 'n_estimators': 355, 'num_leaves': 22, 'max_depth': 5, 'subsample': 0.8935740782222928, 'colsample_bytree': 0.8288956413653737, 'reg_alpha': 0.17148036687009216, 'reg_lambda': 0.22432082362293987, 'min_child_samples': 22}. Best is trial 31 with value: 0.861292236822857.\n",
      "[I 2025-03-20 03:19:21,090] Trial 37 finished with value: 0.8488726244665561 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.057539922345067766, 'n_estimators': 422, 'num_leaves': 31, 'max_depth': 6, 'subsample': 0.8169343110323913, 'colsample_bytree': 0.8759441262601572, 'reg_alpha': 0.2685716989745317, 'reg_lambda': 4.843323637172309, 'min_child_samples': 12}. Best is trial 31 with value: 0.861292236822857.\n",
      "[I 2025-03-20 03:19:21,269] Trial 38 finished with value: 0.8229766719757183 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.03629954661234423, 'n_estimators': 272, 'num_leaves': 27, 'max_depth': 7, 'subsample': 0.9448734468113322, 'colsample_bytree': 0.9811886561000722, 'reg_alpha': 0.12182272277184703, 'reg_lambda': 1.010265836985336, 'min_child_samples': 27}. Best is trial 31 with value: 0.861292236822857.\n",
      "[I 2025-03-20 03:19:21,432] Trial 39 finished with value: 0.8511271673676607 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.04932929239740631, 'n_estimators': 233, 'num_leaves': 46, 'max_depth': 6, 'subsample': 0.7830659559786121, 'colsample_bytree': 0.943265460033535, 'reg_alpha': 0.38291199135337395, 'reg_lambda': 0.5890314527823054, 'min_child_samples': 20}. Best is trial 31 with value: 0.861292236822857.\n",
      "[I 2025-03-20 03:19:21,560] Trial 40 finished with value: 0.8201907579565795 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.06392147774756182, 'n_estimators': 203, 'num_leaves': 21, 'max_depth': 5, 'subsample': 0.8490862151537418, 'colsample_bytree': 0.8944949745439137, 'reg_alpha': 1.6605656039138235, 'reg_lambda': 0.28047697653431103, 'min_child_samples': 16}. Best is trial 31 with value: 0.861292236822857.\n",
      "[I 2025-03-20 03:19:21,844] Trial 41 finished with value: 0.8578487721236108 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.06101131248458437, 'n_estimators': 287, 'num_leaves': 28, 'max_depth': 8, 'subsample': 0.8221244134805158, 'colsample_bytree': 0.9714889945874916, 'reg_alpha': 0.18637640303795683, 'reg_lambda': 0.1382370624920571, 'min_child_samples': 12}. Best is trial 31 with value: 0.861292236822857.\n",
      "[I 2025-03-20 03:19:22,083] Trial 42 finished with value: 0.860088304662443 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.08131406368961124, 'n_estimators': 321, 'num_leaves': 31, 'max_depth': 7, 'subsample': 0.8010189900733448, 'colsample_bytree': 0.9482418776560027, 'reg_alpha': 0.15949528715547848, 'reg_lambda': 0.1273119405868242, 'min_child_samples': 11}. Best is trial 31 with value: 0.861292236822857.\n",
      "[I 2025-03-20 03:19:22,338] Trial 43 finished with value: 0.8563321898418984 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.08500315524381467, 'n_estimators': 326, 'num_leaves': 31, 'max_depth': 7, 'subsample': 0.7969258193313069, 'colsample_bytree': 0.951973089840402, 'reg_alpha': 0.10033447560762772, 'reg_lambda': 0.14286087927749486, 'min_child_samples': 12}. Best is trial 31 with value: 0.861292236822857.\n",
      "[I 2025-03-20 03:19:22,431] Trial 44 finished with value: 0.7179853223273748 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.07726449297039549, 'n_estimators': 387, 'num_leaves': 38, 'max_depth': 7, 'subsample': 0.7738757524904507, 'colsample_bytree': 0.9821062027305634, 'reg_alpha': 4.673879544484267, 'reg_lambda': 0.11693499215976914, 'min_child_samples': 34}. Best is trial 31 with value: 0.861292236822857.\n",
      "[I 2025-03-20 03:19:22,660] Trial 45 finished with value: 0.8591112524382597 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.057799337598184286, 'n_estimators': 296, 'num_leaves': 36, 'max_depth': 6, 'subsample': 0.8129139353737993, 'colsample_bytree': 0.9233394469008651, 'reg_alpha': 0.16718535035694054, 'reg_lambda': 0.1647593239912947, 'min_child_samples': 15}. Best is trial 31 with value: 0.861292236822857.\n",
      "[I 2025-03-20 03:19:22,920] Trial 46 finished with value: 0.8494706756782175 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.06636972590276712, 'n_estimators': 342, 'num_leaves': 42, 'max_depth': 6, 'subsample': 0.7375183219639961, 'colsample_bytree': 0.924680820547826, 'reg_alpha': 0.14661293030261738, 'reg_lambda': 1.2770802404446837, 'min_child_samples': 15}. Best is trial 31 with value: 0.861292236822857.\n",
      "[I 2025-03-20 03:19:23,052] Trial 47 finished with value: 0.8116764392464748 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.08695980423833646, 'n_estimators': 300, 'num_leaves': 36, 'max_depth': 6, 'subsample': 0.8065784068475574, 'colsample_bytree': 0.6350829276676312, 'reg_alpha': 0.126257697214795, 'reg_lambda': 0.16556965182759417, 'min_child_samples': 46}. Best is trial 31 with value: 0.861292236822857.\n",
      "[I 2025-03-20 03:19:23,179] Trial 48 finished with value: 0.7971700363233004 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.07101680906138097, 'n_estimators': 317, 'num_leaves': 41, 'max_depth': 4, 'subsample': 0.7124930486025107, 'colsample_bytree': 0.8964975758384066, 'reg_alpha': 0.1671405632577758, 'reg_lambda': 0.12731741347850342, 'min_child_samples': 49}. Best is trial 31 with value: 0.861292236822857.\n",
      "[I 2025-03-20 03:19:23,394] Trial 49 finished with value: 0.8401158075871595 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.04386440677618629, 'n_estimators': 372, 'num_leaves': 34, 'max_depth': 5, 'subsample': 0.7652181761756363, 'colsample_bytree': 0.7757613575253909, 'reg_alpha': 0.2841673912599838, 'reg_lambda': 0.3939688443065976, 'min_child_samples': 21}. Best is trial 31 with value: 0.861292236822857.\n",
      "[I 2025-03-20 03:19:23,463] A new study created in memory with name: no-name-af137a03-fa8b-4347-94f9-bda48382bf95\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best LightGBM Parameters:\n",
      "  boosting_type: gbdt\n",
      "  learning_rate: 0.0695047657232799\n",
      "  n_estimators: 316\n",
      "  num_leaves: 29\n",
      "  max_depth: 6\n",
      "  subsample: 0.7735182246208606\n",
      "  colsample_bytree: 0.9605942242393898\n",
      "  reg_alpha: 0.14568751194733093\n",
      "  reg_lambda: 0.18609839616575088\n",
      "  min_child_samples: 13\n",
      "\n",
      "Optimizing LSTM for fold 3 using min_max normalization\n",
      "Created LSTM sequences with lookback=10: 453 train, 145 test\n",
      "Optimizing LSTM hyperparameters with CV...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-20 03:19:35,206] Trial 0 finished with value: 0.7360190119021798 and parameters: {'hidden_dim': 45, 'dropout': 0.4551406810921512, 'learning_rate': 0.007331811314274292, 'batch_size': 16, 'weight_decay': 2.064121088592392e-05}. Best is trial 0 with value: 0.7360190119021798.\n",
      "[I 2025-03-20 03:19:41,518] Trial 1 finished with value: 0.7602867078276914 and parameters: {'hidden_dim': 79, 'dropout': 0.48569536770002286, 'learning_rate': 0.003999161563860724, 'batch_size': 32, 'weight_decay': 3.45872269711161e-05}. Best is trial 1 with value: 0.7602867078276914.\n",
      "[I 2025-03-20 03:19:56,473] Trial 2 finished with value: 0.8122610101743096 and parameters: {'hidden_dim': 32, 'dropout': 0.21712375681979076, 'learning_rate': 0.0016665895921660098, 'batch_size': 16, 'weight_decay': 2.1517123363927774e-05}. Best is trial 2 with value: 0.8122610101743096.\n",
      "[I 2025-03-20 03:20:02,728] Trial 3 finished with value: 0.6639936725280756 and parameters: {'hidden_dim': 127, 'dropout': 0.2873081624297713, 'learning_rate': 0.00017643094449433023, 'batch_size': 32, 'weight_decay': 1.0947309020486406e-05}. Best is trial 2 with value: 0.8122610101743096.\n",
      "[I 2025-03-20 03:20:14,231] Trial 4 finished with value: 0.7280983411091931 and parameters: {'hidden_dim': 47, 'dropout': 0.10585094112968818, 'learning_rate': 0.0004451295365396247, 'batch_size': 16, 'weight_decay': 1.3639281514957935e-06}. Best is trial 2 with value: 0.8122610101743096.\n",
      "[I 2025-03-20 03:20:20,645] Trial 5 finished with value: 0.7990239555120645 and parameters: {'hidden_dim': 59, 'dropout': 0.2875597071705984, 'learning_rate': 0.0033384615669657483, 'batch_size': 64, 'weight_decay': 9.98214837316597e-06}. Best is trial 2 with value: 0.8122610101743096.\n",
      "[I 2025-03-20 03:20:32,162] Trial 6 finished with value: 0.7267373865647936 and parameters: {'hidden_dim': 109, 'dropout': 0.4586320455614753, 'learning_rate': 0.0009209968619749436, 'batch_size': 16, 'weight_decay': 1.6223673683559225e-06}. Best is trial 2 with value: 0.8122610101743096.\n",
      "[I 2025-03-20 03:20:38,535] Trial 7 finished with value: 0.7242945474358543 and parameters: {'hidden_dim': 82, 'dropout': 0.3594032085405511, 'learning_rate': 0.006298297451196278, 'batch_size': 32, 'weight_decay': 7.511737052942637e-05}. Best is trial 2 with value: 0.8122610101743096.\n",
      "[I 2025-03-20 03:20:41,913] Trial 8 finished with value: 0.7392123619900115 and parameters: {'hidden_dim': 125, 'dropout': 0.17649687394806254, 'learning_rate': 0.00809174687672524, 'batch_size': 64, 'weight_decay': 5.656354626844694e-06}. Best is trial 2 with value: 0.8122610101743096.\n",
      "[I 2025-03-20 03:20:56,519] Trial 9 finished with value: 0.6597686973249776 and parameters: {'hidden_dim': 127, 'dropout': 0.3668293205677101, 'learning_rate': 0.009614679235250567, 'batch_size': 16, 'weight_decay': 2.2160868002868673e-05}. Best is trial 2 with value: 0.8122610101743096.\n",
      "[I 2025-03-20 03:21:08,371] Trial 10 finished with value: 0.8050694102241089 and parameters: {'hidden_dim': 32, 'dropout': 0.198627869896562, 'learning_rate': 0.0015689723478599755, 'batch_size': 16, 'weight_decay': 8.469738945067809e-05}. Best is trial 2 with value: 0.8122610101743096.\n",
      "[I 2025-03-20 03:21:19,984] Trial 11 finished with value: 0.8169292858769884 and parameters: {'hidden_dim': 35, 'dropout': 0.19058312272398745, 'learning_rate': 0.0019833844976595914, 'batch_size': 16, 'weight_decay': 7.238871454280833e-05}. Best is trial 11 with value: 0.8169292858769884.\n",
      "[I 2025-03-20 03:21:34,999] Trial 12 finished with value: 0.8003700946641376 and parameters: {'hidden_dim': 33, 'dropout': 0.19858417871335965, 'learning_rate': 0.0015088018581849542, 'batch_size': 16, 'weight_decay': 4.505430918133612e-05}. Best is trial 11 with value: 0.8169292858769884.\n",
      "[I 2025-03-20 03:21:47,069] Trial 13 finished with value: 0.7952840074059192 and parameters: {'hidden_dim': 66, 'dropout': 0.1318560556035414, 'learning_rate': 0.0007285120693189867, 'batch_size': 16, 'weight_decay': 4.459010219894359e-06}. Best is trial 11 with value: 0.8169292858769884.\n",
      "[I 2025-03-20 03:22:01,969] Trial 14 finished with value: 0.7952180183824146 and parameters: {'hidden_dim': 50, 'dropout': 0.23755223498704398, 'learning_rate': 0.003174392682478581, 'batch_size': 16, 'weight_decay': 4.4060877591817896e-05}. Best is trial 11 with value: 0.8169292858769884.\n",
      "[I 2025-03-20 03:22:05,356] Trial 15 finished with value: 0.6566199898513453 and parameters: {'hidden_dim': 75, 'dropout': 0.24012784951072286, 'learning_rate': 0.0003399790241608852, 'batch_size': 64, 'weight_decay': 9.688940904195156e-05}. Best is trial 11 with value: 0.8169292858769884.\n",
      "[I 2025-03-20 03:22:17,079] Trial 16 finished with value: 0.8136180554097895 and parameters: {'hidden_dim': 98, 'dropout': 0.15463121208619401, 'learning_rate': 0.0016532604402274915, 'batch_size': 16, 'weight_decay': 1.9921687411113018e-05}. Best is trial 11 with value: 0.8169292858769884.\n",
      "[I 2025-03-20 03:22:28,938] Trial 17 finished with value: 0.6506261266333998 and parameters: {'hidden_dim': 96, 'dropout': 0.14639652501452285, 'learning_rate': 0.00010728531826263386, 'batch_size': 16, 'weight_decay': 1.1223829274855612e-05}. Best is trial 11 with value: 0.8169292858769884.\n",
      "[I 2025-03-20 03:22:38,566] Trial 18 finished with value: 0.80091588194509 and parameters: {'hidden_dim': 96, 'dropout': 0.15598298481736675, 'learning_rate': 0.002302075572047397, 'batch_size': 32, 'weight_decay': 2.7706777476763417e-06}. Best is trial 11 with value: 0.8169292858769884.\n",
      "[I 2025-03-20 03:22:41,860] Trial 19 finished with value: 0.7090715346891749 and parameters: {'hidden_dim': 97, 'dropout': 0.1014253301056214, 'learning_rate': 0.0007559790188628007, 'batch_size': 64, 'weight_decay': 5.659909112491279e-05}. Best is trial 11 with value: 0.8169292858769884.\n",
      "[I 2025-03-20 03:22:53,260] Trial 20 finished with value: 0.6856291860563392 and parameters: {'hidden_dim': 113, 'dropout': 0.3334610357759126, 'learning_rate': 0.0004158017143329979, 'batch_size': 16, 'weight_decay': 2.9198087772471702e-05}. Best is trial 11 with value: 0.8169292858769884.\n",
      "[I 2025-03-20 03:23:07,934] Trial 21 finished with value: 0.8086597245336566 and parameters: {'hidden_dim': 37, 'dropout': 0.23948740921333983, 'learning_rate': 0.0015689824420569813, 'batch_size': 16, 'weight_decay': 1.683711044094791e-05}. Best is trial 11 with value: 0.8169292858769884.\n",
      "[I 2025-03-20 03:23:19,501] Trial 22 finished with value: 0.8137845550423477 and parameters: {'hidden_dim': 58, 'dropout': 0.20155166752657272, 'learning_rate': 0.0021079415465908758, 'batch_size': 16, 'weight_decay': 1.5152107291720501e-05}. Best is trial 11 with value: 0.8169292858769884.\n",
      "[I 2025-03-20 03:23:30,916] Trial 23 finished with value: 0.8350646921213766 and parameters: {'hidden_dim': 59, 'dropout': 0.17697596120629389, 'learning_rate': 0.0022231274219150095, 'batch_size': 16, 'weight_decay': 7.595089344824128e-06}. Best is trial 23 with value: 0.8350646921213766.\n",
      "[I 2025-03-20 03:23:45,575] Trial 24 finished with value: 0.7703030777811429 and parameters: {'hidden_dim': 58, 'dropout': 0.25315206909388654, 'learning_rate': 0.0047794948021269885, 'batch_size': 16, 'weight_decay': 5.022782034128995e-06}. Best is trial 23 with value: 0.8350646921213766.\n",
      "[I 2025-03-20 03:23:56,907] Trial 25 finished with value: 0.7947600322917802 and parameters: {'hidden_dim': 63, 'dropout': 0.18130980663016705, 'learning_rate': 0.002552635490016211, 'batch_size': 16, 'weight_decay': 7.202905954529353e-06}. Best is trial 23 with value: 0.8350646921213766.\n",
      "[I 2025-03-20 03:24:08,333] Trial 26 finished with value: 0.7917174918473696 and parameters: {'hidden_dim': 72, 'dropout': 0.2697804063040586, 'learning_rate': 0.0011257142597659155, 'batch_size': 16, 'weight_decay': 3.538708743904431e-06}. Best is trial 23 with value: 0.8350646921213766.\n",
      "[I 2025-03-20 03:24:23,223] Trial 27 finished with value: 0.835227743343652 and parameters: {'hidden_dim': 42, 'dropout': 0.3104167454995045, 'learning_rate': 0.0023823155077880463, 'batch_size': 16, 'weight_decay': 2.5032956355233365e-06}. Best is trial 27 with value: 0.835227743343652.\n",
      "[I 2025-03-20 03:24:26,619] Trial 28 finished with value: 0.8123204424982305 and parameters: {'hidden_dim': 40, 'dropout': 0.31455466292239975, 'learning_rate': 0.004452598717358968, 'batch_size': 64, 'weight_decay': 1.8844985691545417e-06}. Best is trial 27 with value: 0.835227743343652.\n",
      "[I 2025-03-20 03:24:32,994] Trial 29 finished with value: 0.7684060134389158 and parameters: {'hidden_dim': 51, 'dropout': 0.4136761646993473, 'learning_rate': 0.0011783045687170392, 'batch_size': 32, 'weight_decay': 3.0566180567572233e-06}. Best is trial 27 with value: 0.835227743343652.\n",
      "[I 2025-03-20 03:24:48,205] Trial 30 finished with value: 0.8036416017771364 and parameters: {'hidden_dim': 41, 'dropout': 0.39531626808507236, 'learning_rate': 0.0027443120920818084, 'batch_size': 16, 'weight_decay': 1.0353633098111883e-06}. Best is trial 27 with value: 0.835227743343652.\n",
      "[I 2025-03-20 03:24:59,702] Trial 31 finished with value: 0.8369782363663685 and parameters: {'hidden_dim': 55, 'dropout': 0.2088370558201038, 'learning_rate': 0.002254292382637437, 'batch_size': 16, 'weight_decay': 1.4840972389397792e-05}. Best is trial 31 with value: 0.8369782363663685.\n",
      "[I 2025-03-20 03:25:11,224] Trial 32 finished with value: 0.7746312200075764 and parameters: {'hidden_dim': 44, 'dropout': 0.3130839595578089, 'learning_rate': 0.005507352458556795, 'batch_size': 16, 'weight_decay': 7.0203121618885154e-06}. Best is trial 31 with value: 0.8369782363663685.\n",
      "[I 2025-03-20 03:25:25,832] Trial 33 finished with value: 0.773068541791123 and parameters: {'hidden_dim': 54, 'dropout': 0.2697905993695227, 'learning_rate': 0.0035522687418733144, 'batch_size': 16, 'weight_decay': 2.245358684458668e-06}. Best is trial 31 with value: 0.8369782363663685.\n",
      "[I 2025-03-20 03:25:37,326] Trial 34 finished with value: 0.8251206971363979 and parameters: {'hidden_dim': 47, 'dropout': 0.22447637087977707, 'learning_rate': 0.0021680057274791275, 'batch_size': 16, 'weight_decay': 3.198995001946066e-05}. Best is trial 31 with value: 0.8369782363663685.\n",
      "[I 2025-03-20 03:25:43,756] Trial 35 finished with value: 0.7658718865325307 and parameters: {'hidden_dim': 68, 'dropout': 0.2207547090254368, 'learning_rate': 0.00403413957487142, 'batch_size': 32, 'weight_decay': 3.07069243299609e-05}. Best is trial 31 with value: 0.8369782363663685.\n",
      "[I 2025-03-20 03:25:58,362] Trial 36 finished with value: 0.8159533177427428 and parameters: {'hidden_dim': 47, 'dropout': 0.2707431698722924, 'learning_rate': 0.0028060328808230933, 'batch_size': 16, 'weight_decay': 1.0014358568206149e-05}. Best is trial 31 with value: 0.8369782363663685.\n",
      "[I 2025-03-20 03:26:10,075] Trial 37 finished with value: 0.7863697043996051 and parameters: {'hidden_dim': 82, 'dropout': 0.21852528320375408, 'learning_rate': 0.0013129185599813063, 'batch_size': 16, 'weight_decay': 2.57962285798017e-05}. Best is trial 31 with value: 0.8369782363663685.\n",
      "[I 2025-03-20 03:26:25,254] Trial 38 finished with value: 0.8043965801210087 and parameters: {'hidden_dim': 54, 'dropout': 0.2927756345522359, 'learning_rate': 0.0008744476366374167, 'batch_size': 16, 'weight_decay': 1.3552592399545205e-05}. Best is trial 31 with value: 0.8369782363663685.\n",
      "[I 2025-03-20 03:26:31,631] Trial 39 finished with value: 0.6725073144058369 and parameters: {'hidden_dim': 44, 'dropout': 0.1266051535718195, 'learning_rate': 0.000575801391856934, 'batch_size': 32, 'weight_decay': 7.631983380033869e-06}. Best is trial 31 with value: 0.8369782363663685.\n",
      "[I 2025-03-20 03:26:35,007] Trial 40 finished with value: 0.8050988105594432 and parameters: {'hidden_dim': 61, 'dropout': 0.16833474863431344, 'learning_rate': 0.0019714957407649582, 'batch_size': 64, 'weight_decay': 3.682086959468894e-05}. Best is trial 31 with value: 0.8369782363663685.\n",
      "[I 2025-03-20 03:26:46,295] Trial 41 finished with value: 0.8113647608452504 and parameters: {'hidden_dim': 37, 'dropout': 0.19042658737285767, 'learning_rate': 0.0020205842243222233, 'batch_size': 16, 'weight_decay': 6.176059795590168e-05}. Best is trial 31 with value: 0.8369782363663685.\n",
      "[I 2025-03-20 03:27:00,843] Trial 42 finished with value: 0.7934485549383957 and parameters: {'hidden_dim': 48, 'dropout': 0.33489253310616635, 'learning_rate': 0.0031987823210029077, 'batch_size': 16, 'weight_decay': 5.9067443366268126e-05}. Best is trial 31 with value: 0.8369782363663685.\n",
      "[I 2025-03-20 03:27:12,422] Trial 43 finished with value: 0.8105715417970094 and parameters: {'hidden_dim': 39, 'dropout': 0.21508370325722745, 'learning_rate': 0.0020412877568422665, 'batch_size': 16, 'weight_decay': 4.1483113546927214e-05}. Best is trial 31 with value: 0.8369782363663685.\n",
      "[I 2025-03-20 03:27:24,004] Trial 44 finished with value: 0.7486454397300623 and parameters: {'hidden_dim': 53, 'dropout': 0.1695035677436937, 'learning_rate': 0.005981956482151496, 'batch_size': 16, 'weight_decay': 2.0329462033470753e-05}. Best is trial 31 with value: 0.8369782363663685.\n",
      "[I 2025-03-20 03:27:38,814] Trial 45 finished with value: 0.8197017050139884 and parameters: {'hidden_dim': 35, 'dropout': 0.13716569691332808, 'learning_rate': 0.0012623279651572169, 'batch_size': 16, 'weight_decay': 1.2453035033581023e-05}. Best is trial 31 with value: 0.8369782363663685.\n",
      "[I 2025-03-20 03:27:50,741] Trial 46 finished with value: 0.8374650966460018 and parameters: {'hidden_dim': 44, 'dropout': 0.12113807652547057, 'learning_rate': 0.0010678127284445532, 'batch_size': 16, 'weight_decay': 1.2306041014896444e-05}. Best is trial 46 with value: 0.8374650966460018.\n",
      "[I 2025-03-20 03:28:05,335] Trial 47 finished with value: 0.7942057530922689 and parameters: {'hidden_dim': 43, 'dropout': 0.12575445568745927, 'learning_rate': 0.0009297080994705731, 'batch_size': 16, 'weight_decay': 8.022908610092988e-06}. Best is trial 46 with value: 0.8374650966460018.\n",
      "[I 2025-03-20 03:28:16,711] Trial 48 finished with value: 0.6874205588445949 and parameters: {'hidden_dim': 56, 'dropout': 0.11541885782622224, 'learning_rate': 0.0002803345209285929, 'batch_size': 16, 'weight_decay': 6.037983290986282e-06}. Best is trial 46 with value: 0.8374650966460018.\n",
      "[I 2025-03-20 03:28:28,386] Trial 49 finished with value: 0.7642911506684307 and parameters: {'hidden_dim': 48, 'dropout': 0.15941578087681504, 'learning_rate': 0.0006062082333565724, 'batch_size': 16, 'weight_decay': 9.201034585987026e-06}. Best is trial 46 with value: 0.8374650966460018.\n",
      "[I 2025-03-20 03:28:31,716] Trial 50 finished with value: 0.7609407618643361 and parameters: {'hidden_dim': 65, 'dropout': 0.3614653247298948, 'learning_rate': 0.007840466958884075, 'batch_size': 64, 'weight_decay': 1.8438410388220326e-05}. Best is trial 46 with value: 0.8374650966460018.\n",
      "[I 2025-03-20 03:28:46,375] Trial 51 finished with value: 0.8114317383019761 and parameters: {'hidden_dim': 35, 'dropout': 0.13584622484236608, 'learning_rate': 0.0012722032594874335, 'batch_size': 16, 'weight_decay': 1.2678030768933016e-05}. Best is trial 46 with value: 0.8374650966460018.\n",
      "[I 2025-03-20 03:28:57,876] Trial 52 finished with value: 0.8064014433790468 and parameters: {'hidden_dim': 32, 'dropout': 0.14499613538550835, 'learning_rate': 0.0014117465628381489, 'batch_size': 16, 'weight_decay': 1.1750299343684644e-05}. Best is trial 46 with value: 0.8374650966460018.\n",
      "[I 2025-03-20 03:29:12,542] Trial 53 finished with value: 0.8291523635381867 and parameters: {'hidden_dim': 44, 'dropout': 0.11526076864256554, 'learning_rate': 0.001700856575662567, 'batch_size': 16, 'weight_decay': 1.449218085865924e-05}. Best is trial 46 with value: 0.8374650966460018.\n",
      "[I 2025-03-20 03:29:24,186] Trial 54 finished with value: 0.8266103229189121 and parameters: {'hidden_dim': 49, 'dropout': 0.11415794743770642, 'learning_rate': 0.0017076582166543567, 'batch_size': 16, 'weight_decay': 2.3673032076828554e-05}. Best is trial 46 with value: 0.8374650966460018.\n",
      "[I 2025-03-20 03:29:35,653] Trial 55 finished with value: 0.8171750475808429 and parameters: {'hidden_dim': 51, 'dropout': 0.1094667684149064, 'learning_rate': 0.0017257368870228066, 'batch_size': 16, 'weight_decay': 2.509979198342724e-05}. Best is trial 46 with value: 0.8374650966460018.\n",
      "[I 2025-03-20 03:29:44,957] Trial 56 finished with value: 0.7616283615475488 and parameters: {'hidden_dim': 69, 'dropout': 0.12012488327525842, 'learning_rate': 0.0010558430839293109, 'batch_size': 32, 'weight_decay': 1.4521078566393873e-05}. Best is trial 46 with value: 0.8374650966460018.\n",
      "[I 2025-03-20 03:29:56,608] Trial 57 finished with value: 0.8370937234046215 and parameters: {'hidden_dim': 42, 'dropout': 0.11288978762913365, 'learning_rate': 0.001737257092615968, 'batch_size': 16, 'weight_decay': 4.040500198242192e-06}. Best is trial 46 with value: 0.8374650966460018.\n",
      "[I 2025-03-20 03:30:08,108] Trial 58 finished with value: 0.7935917902957849 and parameters: {'hidden_dim': 86, 'dropout': 0.10462296616346176, 'learning_rate': 0.0027464396124118884, 'batch_size': 16, 'weight_decay': 4.26072294940193e-06}. Best is trial 46 with value: 0.8374650966460018.\n",
      "[I 2025-03-20 03:30:22,716] Trial 59 finished with value: 0.7704250951422505 and parameters: {'hidden_dim': 43, 'dropout': 0.1516706942470436, 'learning_rate': 0.0007575898779743291, 'batch_size': 16, 'weight_decay': 3.950692816537805e-06}. Best is trial 46 with value: 0.8374650966460018.\n",
      "[I 2025-03-20 03:30:34,151] Trial 60 finished with value: 0.7888575290402234 and parameters: {'hidden_dim': 61, 'dropout': 0.10030376993912539, 'learning_rate': 0.0036434639883787968, 'batch_size': 16, 'weight_decay': 5.873461363949098e-06}. Best is trial 46 with value: 0.8374650966460018.\n",
      "[I 2025-03-20 03:30:45,617] Trial 61 finished with value: 0.8240916423639814 and parameters: {'hidden_dim': 39, 'dropout': 0.11693537371472054, 'learning_rate': 0.0016589366084898275, 'batch_size': 16, 'weight_decay': 2.3168151763925553e-06}. Best is trial 46 with value: 0.8374650966460018.\n",
      "[I 2025-03-20 03:31:00,390] Trial 62 finished with value: 0.7844388042667885 and parameters: {'hidden_dim': 57, 'dropout': 0.4837977098982009, 'learning_rate': 0.0017906007028913803, 'batch_size': 16, 'weight_decay': 1.642875590413459e-05}. Best is trial 46 with value: 0.8374650966460018.\n",
      "[I 2025-03-20 03:31:11,825] Trial 63 finished with value: 0.824545379024714 and parameters: {'hidden_dim': 51, 'dropout': 0.13840849858287343, 'learning_rate': 0.0014649525032868742, 'batch_size': 16, 'weight_decay': 9.11159402644134e-06}. Best is trial 46 with value: 0.8374650966460018.\n",
      "[I 2025-03-20 03:31:26,598] Trial 64 finished with value: 0.8044019082203104 and parameters: {'hidden_dim': 46, 'dropout': 0.17864451759600694, 'learning_rate': 0.0024017509810901803, 'batch_size': 16, 'weight_decay': 1.3535418114880587e-06}. Best is trial 46 with value: 0.8374650966460018.\n",
      "[I 2025-03-20 03:31:30,144] Trial 65 finished with value: 0.7680759100610174 and parameters: {'hidden_dim': 41, 'dropout': 0.15877902874880728, 'learning_rate': 0.00242382644220601, 'batch_size': 64, 'weight_decay': 2.3753031863617614e-05}. Best is trial 46 with value: 0.8374650966460018.\n",
      "[I 2025-03-20 03:31:41,699] Trial 66 finished with value: 0.8083435314097978 and parameters: {'hidden_dim': 49, 'dropout': 0.3430217908095853, 'learning_rate': 0.0010154824161570201, 'batch_size': 16, 'weight_decay': 4.979494030956068e-06}. Best is trial 46 with value: 0.8374650966460018.\n",
      "[I 2025-03-20 03:31:56,556] Trial 67 finished with value: 0.8275863257593805 and parameters: {'hidden_dim': 53, 'dropout': 0.12650097146517786, 'learning_rate': 0.0018233234681958328, 'batch_size': 16, 'weight_decay': 3.2547249481765676e-06}. Best is trial 46 with value: 0.8374650966460018.\n",
      "[I 2025-03-20 03:32:07,960] Trial 68 finished with value: 0.8105046670707027 and parameters: {'hidden_dim': 60, 'dropout': 0.18828766749333029, 'learning_rate': 0.002925401554380544, 'batch_size': 16, 'weight_decay': 3.213903444862597e-06}. Best is trial 46 with value: 0.8374650966460018.\n",
      "[I 2025-03-20 03:32:14,137] Trial 69 finished with value: 0.8311182530964336 and parameters: {'hidden_dim': 55, 'dropout': 0.13092500029462398, 'learning_rate': 0.001842795280078948, 'batch_size': 32, 'weight_decay': 2.4476001144900783e-06}. Best is trial 46 with value: 0.8374650966460018.\n",
      "[I 2025-03-20 03:32:20,439] Trial 70 finished with value: 0.7667576559705975 and parameters: {'hidden_dim': 75, 'dropout': 0.31468246778158737, 'learning_rate': 0.004179102692815556, 'batch_size': 32, 'weight_decay': 2.5423826544468874e-06}. Best is trial 46 with value: 0.8374650966460018.\n",
      "[I 2025-03-20 03:32:29,845] Trial 71 finished with value: 0.8098955145566782 and parameters: {'hidden_dim': 53, 'dropout': 0.14405150450462226, 'learning_rate': 0.0019067324650490745, 'batch_size': 32, 'weight_decay': 1.8796225520228835e-06}. Best is trial 46 with value: 0.8374650966460018.\n",
      "[I 2025-03-20 03:32:36,422] Trial 72 finished with value: 0.8256737602298673 and parameters: {'hidden_dim': 45, 'dropout': 0.12874413891590408, 'learning_rate': 0.0022717599692472713, 'batch_size': 32, 'weight_decay': 2.957419835052888e-06}. Best is trial 46 with value: 0.8374650966460018.\n",
      "[I 2025-03-20 03:32:42,713] Trial 73 finished with value: 0.820379384270518 and parameters: {'hidden_dim': 56, 'dropout': 0.16558559725144767, 'learning_rate': 0.0015067411991787599, 'batch_size': 32, 'weight_decay': 3.5872879742412046e-06}. Best is trial 46 with value: 0.8374650966460018.\n",
      "[I 2025-03-20 03:32:48,759] Trial 74 finished with value: 0.8309963356892472 and parameters: {'hidden_dim': 42, 'dropout': 0.2009726500163924, 'learning_rate': 0.0033615875726547657, 'batch_size': 32, 'weight_decay': 1.4619859922210379e-06}. Best is trial 46 with value: 0.8374650966460018.\n",
      "[I 2025-03-20 03:32:55,328] Trial 75 finished with value: 0.8106704746611811 and parameters: {'hidden_dim': 37, 'dropout': 0.2552210973751425, 'learning_rate': 0.004908056623226558, 'batch_size': 32, 'weight_decay': 1.3621497461080391e-06}. Best is trial 46 with value: 0.8374650966460018.\n",
      "[I 2025-03-20 03:33:05,359] Trial 76 finished with value: 0.8224637539316598 and parameters: {'hidden_dim': 43, 'dropout': 0.17541136018356004, 'learning_rate': 0.0034136612450315867, 'batch_size': 32, 'weight_decay': 1.1020065123444903e-06}. Best is trial 46 with value: 0.8374650966460018.\n",
      "[I 2025-03-20 03:33:11,974] Trial 77 finished with value: 0.7949373172300903 and parameters: {'hidden_dim': 41, 'dropout': 0.20517405207096545, 'learning_rate': 0.0024450889003183214, 'batch_size': 32, 'weight_decay': 1.0418136875659028e-05}. Best is trial 46 with value: 0.8374650966460018.\n",
      "[I 2025-03-20 03:33:18,537] Trial 78 finished with value: 0.8452648176412896 and parameters: {'hidden_dim': 46, 'dropout': 0.20823070018643636, 'learning_rate': 0.002921602795527635, 'batch_size': 32, 'weight_decay': 1.6383383134508966e-06}. Best is trial 78 with value: 0.8452648176412896.\n",
      "[I 2025-03-20 03:33:24,897] Trial 79 finished with value: 0.8010651881149456 and parameters: {'hidden_dim': 38, 'dropout': 0.24812479208370403, 'learning_rate': 0.003130820725442757, 'batch_size': 32, 'weight_decay': 1.7546865469562335e-06}. Best is trial 78 with value: 0.8452648176412896.\n",
      "[I 2025-03-20 03:33:31,287] Trial 80 finished with value: 0.7998964630083311 and parameters: {'hidden_dim': 64, 'dropout': 0.2790286629380528, 'learning_rate': 0.0038820280625234335, 'batch_size': 32, 'weight_decay': 2.1428898986310415e-06}. Best is trial 78 with value: 0.8452648176412896.\n",
      "[I 2025-03-20 03:33:41,155] Trial 81 finished with value: 0.8119831354967583 and parameters: {'hidden_dim': 41, 'dropout': 0.23225851369421782, 'learning_rate': 0.002131149089920331, 'batch_size': 32, 'weight_decay': 2.702399805610489e-06}. Best is trial 78 with value: 0.8452648176412896.\n",
      "[I 2025-03-20 03:33:47,991] Trial 82 finished with value: 0.7884078537016658 and parameters: {'hidden_dim': 46, 'dropout': 0.2092244708814651, 'learning_rate': 0.0014131526371858724, 'batch_size': 32, 'weight_decay': 1.5124044297779203e-06}. Best is trial 78 with value: 0.8452648176412896.\n",
      "[I 2025-03-20 03:33:54,304] Trial 83 finished with value: 0.8092656632514634 and parameters: {'hidden_dim': 34, 'dropout': 0.19572510544442842, 'learning_rate': 0.002683800587062197, 'batch_size': 32, 'weight_decay': 1.1369466901962696e-06}. Best is trial 78 with value: 0.8452648176412896.\n",
      "[I 2025-03-20 03:34:00,581] Trial 84 finished with value: 0.836093789929509 and parameters: {'hidden_dim': 51, 'dropout': 0.18312441674875937, 'learning_rate': 0.0029890144947123058, 'batch_size': 32, 'weight_decay': 2.0893081554650068e-06}. Best is trial 78 with value: 0.8452648176412896.\n",
      "[I 2025-03-20 03:34:10,004] Trial 85 finished with value: 0.8134313421790332 and parameters: {'hidden_dim': 50, 'dropout': 0.18472668700297032, 'learning_rate': 0.003094022004875771, 'batch_size': 32, 'weight_decay': 2.071420357320169e-06}. Best is trial 78 with value: 0.8452648176412896.\n",
      "[I 2025-03-20 03:34:16,470] Trial 86 finished with value: 0.7553558948213763 and parameters: {'hidden_dim': 113, 'dropout': 0.23064891859656106, 'learning_rate': 0.004910641670692485, 'batch_size': 32, 'weight_decay': 1.5947395484733223e-06}. Best is trial 78 with value: 0.8452648176412896.\n",
      "[I 2025-03-20 03:34:22,947] Trial 87 finished with value: 0.6276156067053088 and parameters: {'hidden_dim': 55, 'dropout': 0.3027728150355337, 'learning_rate': 0.00011092627208190724, 'batch_size': 32, 'weight_decay': 1.2545489956111503e-06}. Best is trial 78 with value: 0.8452648176412896.\n",
      "[I 2025-03-20 03:34:29,439] Trial 88 finished with value: 0.8045298256392691 and parameters: {'hidden_dim': 51, 'dropout': 0.2040407415075126, 'learning_rate': 0.0035611736575898124, 'batch_size': 32, 'weight_decay': 1.5351420852155034e-06}. Best is trial 78 with value: 0.8452648176412896.\n",
      "[I 2025-03-20 03:34:29,454] A new study created in memory with name: no-name-320252d1-41c4-4844-a357-95634bdafe6e\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best LSTM Parameters:\n",
      "  hidden_dim: 46\n",
      "  dropout: 0.20823070018643636\n",
      "  learning_rate: 0.002921602795527635\n",
      "  batch_size: 32\n",
      "  weight_decay: 1.6383383134508966e-06\n",
      "\n",
      "Optimizing LightGBM for fold 4 using min_max normalization\n",
      "Optimizing LightGBM hyperparameters with CV...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-20 03:34:29,650] Trial 0 finished with value: 0.7079161247417418 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.013661178428178952, 'n_estimators': 456, 'num_leaves': 48, 'max_depth': 6, 'subsample': 0.7552942184455931, 'colsample_bytree': 0.7030385741204636, 'reg_alpha': 1.3087232248047334, 'reg_lambda': 0.6869757398160233, 'min_child_samples': 49}. Best is trial 0 with value: 0.7079161247417418.\n",
      "[I 2025-03-20 03:34:29,744] Trial 1 finished with value: 0.7248946429641542 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.06323892443630524, 'n_estimators': 282, 'num_leaves': 42, 'max_depth': 3, 'subsample': 0.9077831487751247, 'colsample_bytree': 0.6012684467021177, 'reg_alpha': 0.31439409038438626, 'reg_lambda': 1.0912521853098582, 'min_child_samples': 47}. Best is trial 1 with value: 0.7248946429641542.\n",
      "[I 2025-03-20 03:34:29,895] Trial 2 finished with value: 0.7465996476669382 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.019957907467756848, 'n_estimators': 199, 'num_leaves': 37, 'max_depth': 10, 'subsample': 0.7873081624297713, 'colsample_bytree': 0.6493149518105418, 'reg_alpha': 3.6000609130029044, 'reg_lambda': 4.050134848257446, 'min_child_samples': 21}. Best is trial 2 with value: 0.7465996476669382.\n",
      "[I 2025-03-20 03:34:29,997] Trial 3 finished with value: 0.7505225074295953 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.03308671790989007, 'n_estimators': 162, 'num_leaves': 10, 'max_depth': 5, 'subsample': 0.9963593754983149, 'colsample_bytree': 0.805256515122397, 'reg_alpha': 3.0841806167907238, 'reg_lambda': 0.1301677362213169, 'min_child_samples': 21}. Best is trial 3 with value: 0.7505225074295953.\n",
      "[I 2025-03-20 03:34:30,220] Trial 4 finished with value: 0.7677197995113432 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.029437387715603364, 'n_estimators': 405, 'num_leaves': 47, 'max_depth': 6, 'subsample': 0.9716350708762611, 'colsample_bytree': 0.7998448041733087, 'reg_alpha': 2.304933318498776, 'reg_lambda': 3.3362817514757888, 'min_child_samples': 29}. Best is trial 4 with value: 0.7677197995113432.\n",
      "[I 2025-03-20 03:34:30,301] Trial 5 finished with value: 0.7307820673848363 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.07045793365915588, 'n_estimators': 210, 'num_leaves': 23, 'max_depth': 3, 'subsample': 0.8092590874861125, 'colsample_bytree': 0.859403208540551, 'reg_alpha': 3.3760828530802196, 'reg_lambda': 0.15012918259918107, 'min_child_samples': 22}. Best is trial 4 with value: 0.7677197995113432.\n",
      "[I 2025-03-20 03:34:30,509] Trial 6 finished with value: 0.7441998584800948 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.011970252710206382, 'n_estimators': 476, 'num_leaves': 49, 'max_depth': 4, 'subsample': 0.9816084577717837, 'colsample_bytree': 0.7776193095921519, 'reg_alpha': 0.2802529145561249, 'reg_lambda': 1.3744727196612017, 'min_child_samples': 25}. Best is trial 4 with value: 0.7677197995113432.\n",
      "[I 2025-03-20 03:34:30,664] Trial 7 finished with value: 0.7937307664969954 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.0967088301559984, 'n_estimators': 367, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.6725825297010686, 'colsample_bytree': 0.7765487989776441, 'reg_alpha': 1.3901311581414446, 'reg_lambda': 1.2894120399825089, 'min_child_samples': 25}. Best is trial 7 with value: 0.7937307664969954.\n",
      "[I 2025-03-20 03:34:30,842] Trial 8 finished with value: 0.7750319127619975 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.04669085237595252, 'n_estimators': 388, 'num_leaves': 42, 'max_depth': 5, 'subsample': 0.6388242673991037, 'colsample_bytree': 0.9337670455562896, 'reg_alpha': 0.11037032003620384, 'reg_lambda': 0.25448376172072, 'min_child_samples': 45}. Best is trial 7 with value: 0.7937307664969954.\n",
      "[I 2025-03-20 03:34:30,935] Trial 9 finished with value: 0.7314006195441269 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.011232085595448875, 'n_estimators': 177, 'num_leaves': 29, 'max_depth': 4, 'subsample': 0.7436406503252848, 'colsample_bytree': 0.6580654068535353, 'reg_alpha': 0.1699984374960256, 'reg_lambda': 0.1466016632681982, 'min_child_samples': 16}. Best is trial 7 with value: 0.7937307664969954.\n",
      "[I 2025-03-20 03:34:31,157] Trial 10 finished with value: 0.797534840290694 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.0987558719383339, 'n_estimators': 337, 'num_leaves': 18, 'max_depth': 10, 'subsample': 0.642242017563948, 'colsample_bytree': 0.9614634142305828, 'reg_alpha': 0.7548915517607346, 'reg_lambda': 0.47191940414066896, 'min_child_samples': 37}. Best is trial 10 with value: 0.797534840290694.\n",
      "[I 2025-03-20 03:34:31,356] Trial 11 finished with value: 0.7908606691234452 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.08811492902543544, 'n_estimators': 327, 'num_leaves': 17, 'max_depth': 10, 'subsample': 0.6019793854602531, 'colsample_bytree': 0.993860589036455, 'reg_alpha': 0.7915653922317443, 'reg_lambda': 0.4908802288038389, 'min_child_samples': 38}. Best is trial 10 with value: 0.797534840290694.\n",
      "[I 2025-03-20 03:34:31,555] Trial 12 finished with value: 0.7877234209307469 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.09822003027572318, 'n_estimators': 307, 'num_leaves': 30, 'max_depth': 8, 'subsample': 0.6801173039155465, 'colsample_bytree': 0.893626879385864, 'reg_alpha': 0.8750718436454238, 'reg_lambda': 1.8653713281408886, 'min_child_samples': 37}. Best is trial 10 with value: 0.797534840290694.\n",
      "[I 2025-03-20 03:34:31,807] Trial 13 finished with value: 0.816658404728172 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.05345803972760133, 'n_estimators': 371, 'num_leaves': 19, 'max_depth': 8, 'subsample': 0.6866546830080261, 'colsample_bytree': 0.739487019699413, 'reg_alpha': 1.3765039473276297, 'reg_lambda': 0.36073977073087093, 'min_child_samples': 10}. Best is trial 13 with value: 0.816658404728172.\n",
      "[I 2025-03-20 03:34:32,071] Trial 14 finished with value: 0.8269353560322836 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.05100525278048549, 'n_estimators': 257, 'num_leaves': 16, 'max_depth': 8, 'subsample': 0.7213915181789433, 'colsample_bytree': 0.9955930766794112, 'reg_alpha': 0.4759657006669087, 'reg_lambda': 0.3531473318787954, 'min_child_samples': 10}. Best is trial 14 with value: 0.8269353560322836.\n",
      "[I 2025-03-20 03:34:32,193] Trial 15 finished with value: 0.7798893229740798 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.043288657420412956, 'n_estimators': 128, 'num_leaves': 11, 'max_depth': 8, 'subsample': 0.728281809019484, 'colsample_bytree': 0.7201040728875937, 'reg_alpha': 0.40032058910065316, 'reg_lambda': 0.27407685686214406, 'min_child_samples': 13}. Best is trial 14 with value: 0.8269353560322836.\n",
      "[I 2025-03-20 03:34:32,509] Trial 16 finished with value: 0.8277764640072883 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.049153270642365854, 'n_estimators': 257, 'num_leaves': 23, 'max_depth': 8, 'subsample': 0.8460344390937014, 'colsample_bytree': 0.8679612440467525, 'reg_alpha': 0.4703040391963052, 'reg_lambda': 0.2514535341033357, 'min_child_samples': 10}. Best is trial 16 with value: 0.8277764640072883.\n",
      "[I 2025-03-20 03:34:32,788] Trial 17 finished with value: 0.8210476964965393 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.03350416889348262, 'n_estimators': 255, 'num_leaves': 25, 'max_depth': 7, 'subsample': 0.872602340863694, 'colsample_bytree': 0.8654355879743639, 'reg_alpha': 0.4952065943462705, 'reg_lambda': 0.22075145628542162, 'min_child_samples': 15}. Best is trial 16 with value: 0.8277764640072883.\n",
      "[I 2025-03-20 03:34:33,023] Trial 18 finished with value: 0.8014344999752983 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.0276669503148614, 'n_estimators': 247, 'num_leaves': 14, 'max_depth': 9, 'subsample': 0.8556167667539123, 'colsample_bytree': 0.9117968576699139, 'reg_alpha': 0.2193792490608938, 'reg_lambda': 0.6912140904160914, 'min_child_samples': 10}. Best is trial 16 with value: 0.8277764640072883.\n",
      "[I 2025-03-20 03:34:33,270] Trial 19 finished with value: 0.7985999420434674 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.019720789477715744, 'n_estimators': 241, 'num_leaves': 24, 'max_depth': 7, 'subsample': 0.8211640614930323, 'colsample_bytree': 0.9966144955579284, 'reg_alpha': 0.5553562322861813, 'reg_lambda': 0.38401393858894123, 'min_child_samples': 17}. Best is trial 16 with value: 0.8277764640072883.\n",
      "[I 2025-03-20 03:34:33,373] Trial 20 finished with value: 0.7942533826660656 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.06837882431300933, 'n_estimators': 102, 'num_leaves': 36, 'max_depth': 9, 'subsample': 0.9350067851755174, 'colsample_bytree': 0.8461262288632136, 'reg_alpha': 0.1682598346533869, 'reg_lambda': 0.10341899854233196, 'min_child_samples': 31}. Best is trial 16 with value: 0.8277764640072883.\n",
      "[I 2025-03-20 03:34:33,638] Trial 21 finished with value: 0.822095150005391 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.03874967976830049, 'n_estimators': 274, 'num_leaves': 25, 'max_depth': 7, 'subsample': 0.8660759529289149, 'colsample_bytree': 0.8633132535489565, 'reg_alpha': 0.4851853443851495, 'reg_lambda': 0.23847026255178824, 'min_child_samples': 16}. Best is trial 16 with value: 0.8277764640072883.\n",
      "[I 2025-03-20 03:34:33,917] Trial 22 finished with value: 0.8215038253187691 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.040613550290868924, 'n_estimators': 257, 'num_leaves': 21, 'max_depth': 7, 'subsample': 0.8497923699075266, 'colsample_bytree': 0.9517719818142399, 'reg_alpha': 0.3777879582535491, 'reg_lambda': 0.21113806297, 'min_child_samples': 12}. Best is trial 16 with value: 0.8277764640072883.\n",
      "[I 2025-03-20 03:34:34,176] Trial 23 finished with value: 0.822253369217256 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.05530052949795767, 'n_estimators': 289, 'num_leaves': 15, 'max_depth': 9, 'subsample': 0.9034998290341414, 'colsample_bytree': 0.8921835573648496, 'reg_alpha': 0.560415345510661, 'reg_lambda': 0.3418710302470147, 'min_child_samples': 18}. Best is trial 16 with value: 0.8277764640072883.\n",
      "[I 2025-03-20 03:34:34,372] Trial 24 finished with value: 0.8166151685815791 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.05713035493487364, 'n_estimators': 216, 'num_leaves': 14, 'max_depth': 9, 'subsample': 0.9131639376355544, 'colsample_bytree': 0.9060472041175802, 'reg_alpha': 0.9800634394236548, 'reg_lambda': 0.3480326185101311, 'min_child_samples': 19}. Best is trial 16 with value: 0.8277764640072883.\n",
      "[I 2025-03-20 03:34:34,678] Trial 25 finished with value: 0.8218764867898484 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.05039377002814852, 'n_estimators': 296, 'num_leaves': 15, 'max_depth': 8, 'subsample': 0.9381892423135044, 'colsample_bytree': 0.9656562621130906, 'reg_alpha': 0.5750351119275827, 'reg_lambda': 0.5449512514378998, 'min_child_samples': 13}. Best is trial 16 with value: 0.8277764640072883.\n",
      "[I 2025-03-20 03:34:35,053] Trial 26 finished with value: 0.8303801180414954 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.0725535726119176, 'n_estimators': 329, 'num_leaves': 21, 'max_depth': 9, 'subsample': 0.781004413676614, 'colsample_bytree': 0.8212722772769379, 'reg_alpha': 0.25406524866114133, 'reg_lambda': 0.9602434972897838, 'min_child_samples': 11}. Best is trial 26 with value: 0.8303801180414954.\n",
      "[I 2025-03-20 03:34:35,456] Trial 27 finished with value: 0.830152739465424 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.08073177395534831, 'n_estimators': 435, 'num_leaves': 28, 'max_depth': 8, 'subsample': 0.7759775336629043, 'colsample_bytree': 0.8267339579941567, 'reg_alpha': 0.23733777101137832, 'reg_lambda': 0.8584447324093051, 'min_child_samples': 10}. Best is trial 26 with value: 0.8303801180414954.\n",
      "[I 2025-03-20 03:34:35,964] Trial 28 finished with value: 0.8370275129702451 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.08161162970270688, 'n_estimators': 420, 'num_leaves': 29, 'max_depth': 9, 'subsample': 0.7927640746343508, 'colsample_bytree': 0.8286362360751653, 'reg_alpha': 0.10523475272795739, 'reg_lambda': 0.9097489246635381, 'min_child_samples': 14}. Best is trial 28 with value: 0.8370275129702451.\n",
      "[I 2025-03-20 03:34:36,473] Trial 29 finished with value: 0.8331988150280083 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.07863272820324091, 'n_estimators': 431, 'num_leaves': 30, 'max_depth': 9, 'subsample': 0.7848555808565313, 'colsample_bytree': 0.8298541601769395, 'reg_alpha': 0.10691283282827799, 'reg_lambda': 0.8868588432747507, 'min_child_samples': 14}. Best is trial 28 with value: 0.8370275129702451.\n",
      "[I 2025-03-20 03:34:36,782] Trial 30 finished with value: 0.8154796855650123 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.07795617178825999, 'n_estimators': 425, 'num_leaves': 33, 'max_depth': 9, 'subsample': 0.7635270001335205, 'colsample_bytree': 0.7492964883639511, 'reg_alpha': 0.10375174710797096, 'reg_lambda': 2.0103842730476247, 'min_child_samples': 27}. Best is trial 28 with value: 0.8370275129702451.\n",
      "[I 2025-03-20 03:34:37,281] Trial 31 finished with value: 0.8342432236355585 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.0799007138401909, 'n_estimators': 452, 'num_leaves': 28, 'max_depth': 9, 'subsample': 0.7762805453153975, 'colsample_bytree': 0.8279205699475636, 'reg_alpha': 0.14507218546139516, 'reg_lambda': 0.877833126977965, 'min_child_samples': 15}. Best is trial 28 with value: 0.8370275129702451.\n",
      "[I 2025-03-20 03:34:41,014] Trial 32 finished with value: 0.832112854513914 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.07482775610076889, 'n_estimators': 495, 'num_leaves': 33, 'max_depth': 9, 'subsample': 0.8121889890189787, 'colsample_bytree': 0.8261506145366456, 'reg_alpha': 0.13671465482313225, 'reg_lambda': 0.9531283063397826, 'min_child_samples': 13}. Best is trial 28 with value: 0.8370275129702451.\n",
      "[I 2025-03-20 03:34:41,558] Trial 33 finished with value: 0.8328299048608414 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.06284737009604652, 'n_estimators': 499, 'num_leaves': 33, 'max_depth': 10, 'subsample': 0.8170820902015196, 'colsample_bytree': 0.7767653532262795, 'reg_alpha': 0.13443395035965247, 'reg_lambda': 0.7678942307055372, 'min_child_samples': 14}. Best is trial 28 with value: 0.8370275129702451.\n",
      "[I 2025-03-20 03:34:41,969] Trial 34 finished with value: 0.821679131261404 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.061414855226453596, 'n_estimators': 455, 'num_leaves': 32, 'max_depth': 10, 'subsample': 0.822144197065979, 'colsample_bytree': 0.770328402711686, 'reg_alpha': 0.14304316826781252, 'reg_lambda': 0.6534336375620594, 'min_child_samples': 20}. Best is trial 28 with value: 0.8370275129702451.\n",
      "[I 2025-03-20 03:34:42,344] Trial 35 finished with value: 0.8181578067289432 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.06389267487128826, 'n_estimators': 472, 'num_leaves': 37, 'max_depth': 10, 'subsample': 0.7503381068856299, 'colsample_bytree': 0.6778666061291503, 'reg_alpha': 0.19061448038669582, 'reg_lambda': 1.7474641831677669, 'min_child_samples': 23}. Best is trial 28 with value: 0.8370275129702451.\n",
      "[I 2025-03-20 03:34:42,806] Trial 36 finished with value: 0.829514431970505 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.08963612815485236, 'n_estimators': 430, 'num_leaves': 27, 'max_depth': 10, 'subsample': 0.7973895546891232, 'colsample_bytree': 0.7900134344961934, 'reg_alpha': 0.11712322753741632, 'reg_lambda': 2.616334277005541, 'min_child_samples': 15}. Best is trial 28 with value: 0.8370275129702451.\n",
      "[I 2025-03-20 03:34:43,103] Trial 37 finished with value: 0.8090302748357642 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.08380782804669332, 'n_estimators': 488, 'num_leaves': 40, 'max_depth': 6, 'subsample': 0.7140579358387672, 'colsample_bytree': 0.7539547955136732, 'reg_alpha': 0.1372618829725515, 'reg_lambda': 1.2931847477056726, 'min_child_samples': 32}. Best is trial 28 with value: 0.8370275129702451.\n",
      "[I 2025-03-20 03:34:43,525] Trial 38 finished with value: 0.8160115558322154 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.019044247857628416, 'n_estimators': 450, 'num_leaves': 36, 'max_depth': 10, 'subsample': 0.7967545867059774, 'colsample_bytree': 0.8056578832319851, 'reg_alpha': 0.3153623634253133, 'reg_lambda': 0.7824314494276792, 'min_child_samples': 19}. Best is trial 28 with value: 0.8370275129702451.\n",
      "[I 2025-03-20 03:34:43,856] Trial 39 finished with value: 0.8136624089931328 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.02448691445775541, 'n_estimators': 408, 'num_leaves': 46, 'max_depth': 9, 'subsample': 0.8335981354302656, 'colsample_bytree': 0.60951827827375, 'reg_alpha': 0.20028983070202747, 'reg_lambda': 1.1848568190940958, 'min_child_samples': 23}. Best is trial 28 with value: 0.8370275129702451.\n",
      "[I 2025-03-20 03:34:44,383] Trial 40 finished with value: 0.8306964180129333 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.06366978526726544, 'n_estimators': 473, 'num_leaves': 31, 'max_depth': 10, 'subsample': 0.7652683511662106, 'colsample_bytree': 0.7084985573938939, 'reg_alpha': 0.12629617119075542, 'reg_lambda': 1.5741005153783705, 'min_child_samples': 14}. Best is trial 28 with value: 0.8370275129702451.\n",
      "[I 2025-03-20 03:34:44,911] Trial 41 finished with value: 0.8309896342121201 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.07468326149978946, 'n_estimators': 497, 'num_leaves': 33, 'max_depth': 9, 'subsample': 0.8112150453973066, 'colsample_bytree': 0.8356847249465785, 'reg_alpha': 0.15283912476064193, 'reg_lambda': 0.9545265799113191, 'min_child_samples': 14}. Best is trial 28 with value: 0.8370275129702451.\n",
      "[I 2025-03-20 03:34:45,378] Trial 42 finished with value: 0.8272582693181292 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.07061728074901534, 'n_estimators': 495, 'num_leaves': 34, 'max_depth': 9, 'subsample': 0.8817146120829957, 'colsample_bytree': 0.8065144918235563, 'reg_alpha': 0.1019007030062178, 'reg_lambda': 0.5901232579872585, 'min_child_samples': 17}. Best is trial 28 with value: 0.8370275129702451.\n",
      "[I 2025-03-20 03:34:45,560] Trial 43 finished with value: 0.8047526392311977 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.08500315524381467, 'n_estimators': 411, 'num_leaves': 27, 'max_depth': 9, 'subsample': 0.7869110358662916, 'colsample_bytree': 0.8431544004916417, 'reg_alpha': 1.9768957255486517, 'reg_lambda': 1.0570684316206826, 'min_child_samples': 13}. Best is trial 28 with value: 0.8370275129702451.\n",
      "[I 2025-03-20 03:34:45,682] Trial 44 finished with value: 0.746121158512914 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.09139054662962572, 'n_estimators': 450, 'num_leaves': 38, 'max_depth': 10, 'subsample': 0.7478414959622504, 'colsample_bytree': 0.7879572364568634, 'reg_alpha': 4.673879544484267, 'reg_lambda': 0.7841346939518266, 'min_child_samples': 21}. Best is trial 28 with value: 0.8370275129702451.\n",
      "[I 2025-03-20 03:34:46,081] Trial 45 finished with value: 0.8147141781862872 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.015329423109695761, 'n_estimators': 386, 'num_leaves': 30, 'max_depth': 10, 'subsample': 0.8336524759621167, 'colsample_bytree': 0.8146304364503378, 'reg_alpha': 0.1280729887899219, 'reg_lambda': 1.399650784403024, 'min_child_samples': 17}. Best is trial 28 with value: 0.8370275129702451.\n",
      "[I 2025-03-20 03:34:46,606] Trial 46 finished with value: 0.8339879858023025 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.05893265867975794, 'n_estimators': 471, 'num_leaves': 35, 'max_depth': 9, 'subsample': 0.8069935533586405, 'colsample_bytree': 0.767051953845024, 'reg_alpha': 0.1728968767219544, 'reg_lambda': 0.4466257976980025, 'min_child_samples': 12}. Best is trial 28 with value: 0.8370275129702451.\n",
      "[I 2025-03-20 03:34:46,791] Trial 47 finished with value: 0.7710086669031873 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.061769111449550274, 'n_estimators': 357, 'num_leaves': 39, 'max_depth': 5, 'subsample': 0.7335165008914666, 'colsample_bytree': 0.767124427401129, 'reg_alpha': 0.1746562076590726, 'reg_lambda': 0.4481472737159364, 'min_child_samples': 46}. Best is trial 28 with value: 0.8370275129702451.\n",
      "[I 2025-03-20 03:34:47,032] Trial 48 finished with value: 0.7880250942425406 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.06686220213778493, 'n_estimators': 470, 'num_leaves': 35, 'max_depth': 8, 'subsample': 0.7066083646773722, 'colsample_bytree': 0.7906688906580686, 'reg_alpha': 0.2828742316367011, 'reg_lambda': 0.6021025613800635, 'min_child_samples': 49}. Best is trial 28 with value: 0.8370275129702451.\n",
      "[I 2025-03-20 03:34:47,460] Trial 49 finished with value: 0.8325615609425558 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.04592418658362258, 'n_estimators': 392, 'num_leaves': 44, 'max_depth': 10, 'subsample': 0.7703294162148383, 'colsample_bytree': 0.8816294629837637, 'reg_alpha': 0.11852928395317112, 'reg_lambda': 0.738477091125083, 'min_child_samples': 15}. Best is trial 28 with value: 0.8370275129702451.\n",
      "[I 2025-03-20 03:34:47,578] A new study created in memory with name: no-name-8f97234d-ef1b-4d3f-9adf-a76e8881719a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best LightGBM Parameters:\n",
      "  boosting_type: gbdt\n",
      "  learning_rate: 0.08161162970270688\n",
      "  n_estimators: 420\n",
      "  num_leaves: 29\n",
      "  max_depth: 9\n",
      "  subsample: 0.7927640746343508\n",
      "  colsample_bytree: 0.8286362360751653\n",
      "  reg_alpha: 0.10523475272795739\n",
      "  reg_lambda: 0.9097489246635381\n",
      "  min_child_samples: 14\n",
      "\n",
      "Optimizing LSTM for fold 4 using min_max normalization\n",
      "Created LSTM sequences with lookback=10: 608 train, 145 test\n",
      "Optimizing LSTM hyperparameters with CV...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-20 03:35:03,477] Trial 0 finished with value: 0.5754726009718998 and parameters: {'hidden_dim': 45, 'dropout': 0.4551406810921512, 'learning_rate': 0.007331811314274292, 'batch_size': 16, 'weight_decay': 2.064121088592392e-05}. Best is trial 0 with value: 0.5754726009718998.\n",
      "[I 2025-03-20 03:35:15,493] Trial 1 finished with value: 0.6835778163308509 and parameters: {'hidden_dim': 79, 'dropout': 0.48569536770002286, 'learning_rate': 0.003999161563860724, 'batch_size': 32, 'weight_decay': 3.45872269711161e-05}. Best is trial 1 with value: 0.6835778163308509.\n",
      "[I 2025-03-20 03:35:31,801] Trial 2 finished with value: 0.7121915131941408 and parameters: {'hidden_dim': 32, 'dropout': 0.21712375681979076, 'learning_rate': 0.0016665895921660098, 'batch_size': 16, 'weight_decay': 2.1517123363927774e-05}. Best is trial 2 with value: 0.7121915131941408.\n",
      "[I 2025-03-20 03:35:40,215] Trial 3 finished with value: 0.6373089601388842 and parameters: {'hidden_dim': 127, 'dropout': 0.2873081624297713, 'learning_rate': 0.00017643094449433023, 'batch_size': 32, 'weight_decay': 1.0947309020486406e-05}. Best is trial 2 with value: 0.7121915131941408.\n",
      "[I 2025-03-20 03:35:59,588] Trial 4 finished with value: 0.6819383838727134 and parameters: {'hidden_dim': 47, 'dropout': 0.10585094112968818, 'learning_rate': 0.0004451295365396247, 'batch_size': 16, 'weight_decay': 1.3639281514957935e-06}. Best is trial 2 with value: 0.7121915131941408.\n",
      "[I 2025-03-20 03:36:04,370] Trial 5 finished with value: 0.6899680564783649 and parameters: {'hidden_dim': 59, 'dropout': 0.2875597071705984, 'learning_rate': 0.0033384615669657483, 'batch_size': 64, 'weight_decay': 9.98214837316597e-06}. Best is trial 2 with value: 0.7121915131941408.\n",
      "[I 2025-03-20 03:36:23,572] Trial 6 finished with value: 0.6500151654382194 and parameters: {'hidden_dim': 109, 'dropout': 0.4586320455614753, 'learning_rate': 0.0009209968619749436, 'batch_size': 16, 'weight_decay': 1.6223673683559225e-06}. Best is trial 2 with value: 0.7121915131941408.\n",
      "[I 2025-03-20 03:36:31,866] Trial 7 finished with value: 0.6324577911397068 and parameters: {'hidden_dim': 82, 'dropout': 0.3594032085405511, 'learning_rate': 0.006298297451196278, 'batch_size': 32, 'weight_decay': 7.511737052942637e-05}. Best is trial 2 with value: 0.7121915131941408.\n",
      "[I 2025-03-20 03:36:36,541] Trial 8 finished with value: 0.6319819973462154 and parameters: {'hidden_dim': 125, 'dropout': 0.17649687394806254, 'learning_rate': 0.00809174687672524, 'batch_size': 64, 'weight_decay': 5.656354626844694e-06}. Best is trial 2 with value: 0.7121915131941408.\n",
      "[I 2025-03-20 03:36:55,822] Trial 9 finished with value: 0.5985045420237322 and parameters: {'hidden_dim': 127, 'dropout': 0.3668293205677101, 'learning_rate': 0.009614679235250567, 'batch_size': 16, 'weight_decay': 2.2160868002868673e-05}. Best is trial 2 with value: 0.7121915131941408.\n",
      "[I 2025-03-20 03:37:11,529] Trial 10 finished with value: 0.6804630060009913 and parameters: {'hidden_dim': 32, 'dropout': 0.198627869896562, 'learning_rate': 0.0015689723478599755, 'batch_size': 16, 'weight_decay': 8.469738945067809e-05}. Best is trial 2 with value: 0.7121915131941408.\n",
      "[I 2025-03-20 03:37:16,354] Trial 11 finished with value: 0.714365164093552 and parameters: {'hidden_dim': 64, 'dropout': 0.25668451047832225, 'learning_rate': 0.0020832659212191686, 'batch_size': 64, 'weight_decay': 4.899133576690419e-06}. Best is trial 11 with value: 0.714365164093552.\n",
      "[I 2025-03-20 03:37:21,200] Trial 12 finished with value: 0.677213004220274 and parameters: {'hidden_dim': 72, 'dropout': 0.21598500798518633, 'learning_rate': 0.0015088018581849542, 'batch_size': 64, 'weight_decay': 3.460656555538206e-06}. Best is trial 11 with value: 0.714365164093552.\n",
      "[I 2025-03-20 03:37:29,280] Trial 13 finished with value: 0.6232077362531769 and parameters: {'hidden_dim': 95, 'dropout': 0.24296708365322092, 'learning_rate': 0.0007285120693189867, 'batch_size': 64, 'weight_decay': 4.459010219894359e-06}. Best is trial 11 with value: 0.714365164093552.\n",
      "[I 2025-03-20 03:37:34,037] Trial 14 finished with value: 0.7086120433171387 and parameters: {'hidden_dim': 33, 'dropout': 0.11485150758934834, 'learning_rate': 0.0017038860393305435, 'batch_size': 64, 'weight_decay': 1.2545792342299691e-05}. Best is trial 11 with value: 0.714365164093552.\n",
      "[I 2025-03-20 03:37:50,153] Trial 15 finished with value: 0.6413311727720871 and parameters: {'hidden_dim': 58, 'dropout': 0.3402754772779238, 'learning_rate': 0.0003539798922574453, 'batch_size': 16, 'weight_decay': 2.5886593912338396e-06}. Best is trial 11 with value: 0.714365164093552.\n",
      "[I 2025-03-20 03:37:54,920] Trial 16 finished with value: 0.6753998924453652 and parameters: {'hidden_dim': 61, 'dropout': 0.26430609192606264, 'learning_rate': 0.0024684247055058992, 'batch_size': 64, 'weight_decay': 4.4383979493096764e-05}. Best is trial 11 with value: 0.714365164093552.\n",
      "[I 2025-03-20 03:38:14,326] Trial 17 finished with value: 0.604792942002994 and parameters: {'hidden_dim': 90, 'dropout': 0.1572378497520306, 'learning_rate': 0.00010728531826263386, 'batch_size': 16, 'weight_decay': 5.847918834978513e-06}. Best is trial 11 with value: 0.714365164093552.\n",
      "[I 2025-03-20 03:38:19,014] Trial 18 finished with value: 0.6538739754675406 and parameters: {'hidden_dim': 43, 'dropout': 0.32294830382545214, 'learning_rate': 0.0006275250989672774, 'batch_size': 64, 'weight_decay': 1.7445159426190412e-05}. Best is trial 11 with value: 0.714365164093552.\n",
      "[I 2025-03-20 03:38:27,118] Trial 19 finished with value: 0.679317249646247 and parameters: {'hidden_dim': 70, 'dropout': 0.3982201913987795, 'learning_rate': 0.0025483949776746854, 'batch_size': 32, 'weight_decay': 7.823169758168759e-06}. Best is trial 11 with value: 0.714365164093552.\n",
      "[I 2025-03-20 03:38:34,960] Trial 20 finished with value: 0.7208837966595434 and parameters: {'hidden_dim': 52, 'dropout': 0.23524611020501152, 'learning_rate': 0.004681922702699792, 'batch_size': 64, 'weight_decay': 3.3438390648003014e-05}. Best is trial 20 with value: 0.7208837966595434.\n",
      "[I 2025-03-20 03:38:39,737] Trial 21 finished with value: 0.6486531193568928 and parameters: {'hidden_dim': 52, 'dropout': 0.23263476623991738, 'learning_rate': 0.004881505957897184, 'batch_size': 64, 'weight_decay': 3.478261170247822e-05}. Best is trial 20 with value: 0.7208837966595434.\n",
      "[I 2025-03-20 03:38:44,599] Trial 22 finished with value: 0.6752254187897434 and parameters: {'hidden_dim': 38, 'dropout': 0.1593592420234631, 'learning_rate': 0.002318999954988156, 'batch_size': 64, 'weight_decay': 5.957050939957761e-05}. Best is trial 20 with value: 0.7208837966595434.\n",
      "[I 2025-03-20 03:38:49,247] Trial 23 finished with value: 0.6822544446140043 and parameters: {'hidden_dim': 66, 'dropout': 0.2555819116296019, 'learning_rate': 0.0013374201487084808, 'batch_size': 64, 'weight_decay': 2.6934926307977124e-05}. Best is trial 20 with value: 0.7208837966595434.\n",
      "[I 2025-03-20 03:38:53,867] Trial 24 finished with value: 0.7268495182481997 and parameters: {'hidden_dim': 53, 'dropout': 0.19423905211637288, 'learning_rate': 0.004880040523791641, 'batch_size': 64, 'weight_decay': 1.3986612110065837e-05}. Best is trial 24 with value: 0.7268495182481997.\n",
      "[I 2025-03-20 03:38:58,598] Trial 25 finished with value: 0.746154607645331 and parameters: {'hidden_dim': 55, 'dropout': 0.18438257487142248, 'learning_rate': 0.004697852565029639, 'batch_size': 64, 'weight_decay': 1.4909521958280094e-05}. Best is trial 25 with value: 0.746154607645331.\n",
      "[I 2025-03-20 03:39:06,647] Trial 26 finished with value: 0.7154582862902092 and parameters: {'hidden_dim': 52, 'dropout': 0.13366729650566153, 'learning_rate': 0.005009906107160121, 'batch_size': 64, 'weight_decay': 1.4916503610592851e-05}. Best is trial 25 with value: 0.746154607645331.\n",
      "[I 2025-03-20 03:39:11,481] Trial 27 finished with value: 0.687462940353957 and parameters: {'hidden_dim': 53, 'dropout': 0.18731708219015683, 'learning_rate': 0.003383836781772956, 'batch_size': 64, 'weight_decay': 8.435281121384504e-06}. Best is trial 25 with value: 0.746154607645331.\n",
      "[I 2025-03-20 03:39:16,037] Trial 28 finished with value: 0.6507187141872894 and parameters: {'hidden_dim': 75, 'dropout': 0.14936473131964567, 'learning_rate': 0.00623973190826259, 'batch_size': 64, 'weight_decay': 3.031369713639327e-05}. Best is trial 25 with value: 0.746154607645331.\n",
      "[I 2025-03-20 03:39:20,813] Trial 29 finished with value: 0.6310487935123233 and parameters: {'hidden_dim': 43, 'dropout': 0.19913619807977329, 'learning_rate': 0.009777962062434373, 'batch_size': 64, 'weight_decay': 1.4224891712957988e-05}. Best is trial 25 with value: 0.746154607645331.\n",
      "[I 2025-03-20 03:39:25,512] Trial 30 finished with value: 0.6583335356615818 and parameters: {'hidden_dim': 48, 'dropout': 0.30347745635750045, 'learning_rate': 0.003910307993144254, 'batch_size': 64, 'weight_decay': 5.5010173144763924e-05}. Best is trial 25 with value: 0.746154607645331.\n",
      "[I 2025-03-20 03:39:30,011] Trial 31 finished with value: 0.6876588697405307 and parameters: {'hidden_dim': 54, 'dropout': 0.13340119811184512, 'learning_rate': 0.004711880153865995, 'batch_size': 64, 'weight_decay': 1.6166760426684973e-05}. Best is trial 25 with value: 0.746154607645331.\n",
      "[I 2025-03-20 03:39:34,540] Trial 32 finished with value: 0.6661751620888909 and parameters: {'hidden_dim': 39, 'dropout': 0.17710877613752257, 'learning_rate': 0.0056123225315516095, 'batch_size': 64, 'weight_decay': 2.1728967041535217e-05}. Best is trial 25 with value: 0.746154607645331.\n",
      "[I 2025-03-20 03:39:42,310] Trial 33 finished with value: 0.6696011748706109 and parameters: {'hidden_dim': 52, 'dropout': 0.12991987565042104, 'learning_rate': 0.006972815628155757, 'batch_size': 64, 'weight_decay': 4.017685738427029e-05}. Best is trial 25 with value: 0.746154607645331.\n",
      "[I 2025-03-20 03:39:50,453] Trial 34 finished with value: 0.6787785483773362 and parameters: {'hidden_dim': 67, 'dropout': 0.22229432754066142, 'learning_rate': 0.002987876894037972, 'batch_size': 32, 'weight_decay': 7.349469360853257e-06}. Best is trial 25 with value: 0.746154607645331.\n",
      "[I 2025-03-20 03:39:54,780] Trial 35 finished with value: 0.7156644641613289 and parameters: {'hidden_dim': 81, 'dropout': 0.10214055723548332, 'learning_rate': 0.004527822428490007, 'batch_size': 64, 'weight_decay': 2.5686769020987364e-05}. Best is trial 25 with value: 0.746154607645331.\n",
      "[I 2025-03-20 03:40:02,837] Trial 36 finished with value: 0.6994613353286404 and parameters: {'hidden_dim': 90, 'dropout': 0.1084149606736535, 'learning_rate': 0.00395526492920058, 'batch_size': 32, 'weight_decay': 2.5848649712030152e-05}. Best is trial 25 with value: 0.746154607645331.\n",
      "[I 2025-03-20 03:40:07,426] Trial 37 finished with value: 0.63309800163855 and parameters: {'hidden_dim': 80, 'dropout': 0.20779889406856303, 'learning_rate': 0.007226103949730325, 'batch_size': 64, 'weight_decay': 9.95184279129232e-06}. Best is trial 25 with value: 0.746154607645331.\n",
      "[I 2025-03-20 03:40:15,472] Trial 38 finished with value: 0.6683052702186445 and parameters: {'hidden_dim': 103, 'dropout': 0.27283030510898065, 'learning_rate': 0.0029879047382652337, 'batch_size': 64, 'weight_decay': 1.9478536155086967e-05}. Best is trial 25 with value: 0.746154607645331.\n",
      "[I 2025-03-20 03:40:20,465] Trial 39 finished with value: 0.657419065899489 and parameters: {'hidden_dim': 60, 'dropout': 0.1642255217338801, 'learning_rate': 0.0011986298808486018, 'batch_size': 64, 'weight_decay': 5.078424653359389e-05}. Best is trial 25 with value: 0.746154607645331.\n",
      "[I 2025-03-20 03:40:29,887] Trial 40 finished with value: 0.6600783755916982 and parameters: {'hidden_dim': 85, 'dropout': 0.2326171615200422, 'learning_rate': 0.0042985625023967, 'batch_size': 32, 'weight_decay': 3.4937421492042685e-05}. Best is trial 25 with value: 0.746154607645331.\n",
      "[I 2025-03-20 03:40:34,420] Trial 41 finished with value: 0.7150811653721209 and parameters: {'hidden_dim': 76, 'dropout': 0.12699324785245938, 'learning_rate': 0.005400996803692855, 'batch_size': 64, 'weight_decay': 1.2062320653433233e-05}. Best is trial 25 with value: 0.746154607645331.\n",
      "[I 2025-03-20 03:40:38,976] Trial 42 finished with value: 0.6666636552769022 and parameters: {'hidden_dim': 47, 'dropout': 0.1443451071033302, 'learning_rate': 0.008015215485919762, 'batch_size': 64, 'weight_decay': 1.5179567014220298e-05}. Best is trial 25 with value: 0.746154607645331.\n",
      "[I 2025-03-20 03:40:46,633] Trial 43 finished with value: 0.7274081627531989 and parameters: {'hidden_dim': 49, 'dropout': 0.10857552312215266, 'learning_rate': 0.0037655908918452757, 'batch_size': 64, 'weight_decay': 2.478155352883063e-05}. Best is trial 25 with value: 0.746154607645331.\n",
      "[I 2025-03-20 03:40:51,255] Trial 44 finished with value: 0.7224122634635716 and parameters: {'hidden_dim': 40, 'dropout': 0.1008124326293435, 'learning_rate': 0.0033534839072605163, 'batch_size': 64, 'weight_decay': 2.410372433796208e-05}. Best is trial 25 with value: 0.746154607645331.\n",
      "[I 2025-03-20 03:40:55,866] Trial 45 finished with value: 0.6727639096580212 and parameters: {'hidden_dim': 39, 'dropout': 0.1835905942918798, 'learning_rate': 0.001970860434739209, 'batch_size': 64, 'weight_decay': 7.04600296560343e-05}. Best is trial 25 with value: 0.746154607645331.\n",
      "[I 2025-03-20 03:41:11,370] Trial 46 finished with value: 0.6412204679553198 and parameters: {'hidden_dim': 57, 'dropout': 0.169840318847602, 'learning_rate': 0.0036433545827432197, 'batch_size': 16, 'weight_decay': 2.038554288613823e-05}. Best is trial 25 with value: 0.746154607645331.\n",
      "[I 2025-03-20 03:41:19,234] Trial 47 finished with value: 0.6775347882316304 and parameters: {'hidden_dim': 47, 'dropout': 0.48092262842940603, 'learning_rate': 0.0029242395956525055, 'batch_size': 64, 'weight_decay': 1.0679590551305342e-05}. Best is trial 25 with value: 0.746154607645331.\n",
      "[I 2025-03-20 03:41:24,012] Trial 48 finished with value: 0.6510420352337274 and parameters: {'hidden_dim': 36, 'dropout': 0.1956057459269193, 'learning_rate': 0.006149831741561262, 'batch_size': 64, 'weight_decay': 3.189670804002458e-05}. Best is trial 25 with value: 0.746154607645331.\n",
      "[I 2025-03-20 03:41:28,588] Trial 49 finished with value: 0.6537730552737726 and parameters: {'hidden_dim': 43, 'dropout': 0.10048374346928095, 'learning_rate': 0.0010797922907203757, 'batch_size': 64, 'weight_decay': 4.20064136302113e-05}. Best is trial 25 with value: 0.746154607645331.\n",
      "[I 2025-03-20 03:41:44,402] Trial 50 finished with value: 0.6405902921450095 and parameters: {'hidden_dim': 63, 'dropout': 0.1230154989361507, 'learning_rate': 0.0003436003925848881, 'batch_size': 16, 'weight_decay': 1.8040710683139765e-05}. Best is trial 25 with value: 0.746154607645331.\n",
      "[I 2025-03-20 03:41:52,144] Trial 51 finished with value: 0.6799157791339877 and parameters: {'hidden_dim': 57, 'dropout': 0.10049041692065543, 'learning_rate': 0.0043908492071159915, 'batch_size': 64, 'weight_decay': 2.5877721275721766e-05}. Best is trial 25 with value: 0.746154607645331.\n",
      "[I 2025-03-20 03:41:56,585] Trial 52 finished with value: 0.6441531313430341 and parameters: {'hidden_dim': 48, 'dropout': 0.15058562195617173, 'learning_rate': 0.008582831866671874, 'batch_size': 64, 'weight_decay': 2.3891350042173506e-05}. Best is trial 25 with value: 0.746154607645331.\n",
      "[I 2025-03-20 03:42:01,080] Trial 53 finished with value: 0.683089090028497 and parameters: {'hidden_dim': 115, 'dropout': 0.11688519920473112, 'learning_rate': 0.0033162467578996225, 'batch_size': 64, 'weight_decay': 1.2758522451501729e-05}. Best is trial 25 with value: 0.746154607645331.\n",
      "[I 2025-03-20 03:42:05,777] Trial 54 finished with value: 0.7060997202412809 and parameters: {'hidden_dim': 72, 'dropout': 0.13869005980902258, 'learning_rate': 0.002555028344808476, 'batch_size': 64, 'weight_decay': 1.0244242630912548e-06}. Best is trial 25 with value: 0.746154607645331.\n",
      "[I 2025-03-20 03:42:10,572] Trial 55 finished with value: 0.6483974777057938 and parameters: {'hidden_dim': 85, 'dropout': 0.4019878829091252, 'learning_rate': 0.005576804543080487, 'batch_size': 64, 'weight_decay': 3.740450273888885e-05}. Best is trial 25 with value: 0.746154607645331.\n",
      "[I 2025-03-20 03:42:19,163] Trial 56 finished with value: 0.7211704898166204 and parameters: {'hidden_dim': 35, 'dropout': 0.2153380680979977, 'learning_rate': 0.0021573682957517263, 'batch_size': 32, 'weight_decay': 2.9155446121881995e-05}. Best is trial 25 with value: 0.746154607645331.\n",
      "[I 2025-03-20 03:42:31,503] Trial 57 finished with value: 0.7480033460899719 and parameters: {'hidden_dim': 34, 'dropout': 0.24595474423178743, 'learning_rate': 0.001808558915813523, 'batch_size': 32, 'weight_decay': 3.117531476616303e-05}. Best is trial 57 with value: 0.7480033460899719.\n",
      "[I 2025-03-20 03:42:39,446] Trial 58 finished with value: 0.6674041482961967 and parameters: {'hidden_dim': 32, 'dropout': 0.2905384850839872, 'learning_rate': 0.00171411832311096, 'batch_size': 32, 'weight_decay': 4.783853088567064e-05}. Best is trial 57 with value: 0.7480033460899719.\n",
      "[I 2025-03-20 03:42:47,721] Trial 59 finished with value: 0.6733493959842751 and parameters: {'hidden_dim': 36, 'dropout': 0.2462834526928987, 'learning_rate': 0.0008918230790586713, 'batch_size': 32, 'weight_decay': 2.9652310078300987e-05}. Best is trial 57 with value: 0.7480033460899719.\n",
      "[I 2025-03-20 03:42:59,046] Trial 60 finished with value: 0.6826799361020873 and parameters: {'hidden_dim': 44, 'dropout': 0.21397109576713447, 'learning_rate': 0.0020547127776135293, 'batch_size': 32, 'weight_decay': 9.791795569296473e-05}. Best is trial 57 with value: 0.7480033460899719.\n",
      "[I 2025-03-20 03:43:07,009] Trial 61 finished with value: 0.7072525597736359 and parameters: {'hidden_dim': 40, 'dropout': 0.2742448402295786, 'learning_rate': 0.0027116341088923067, 'batch_size': 32, 'weight_decay': 2.130886067586293e-05}. Best is trial 57 with value: 0.7480033460899719.\n",
      "[I 2025-03-20 03:43:14,823] Trial 62 finished with value: 0.7288312802796094 and parameters: {'hidden_dim': 35, 'dropout': 0.2303871478163961, 'learning_rate': 0.0022003710977041195, 'batch_size': 32, 'weight_decay': 3.11674262665919e-05}. Best is trial 57 with value: 0.7480033460899719.\n",
      "[I 2025-03-20 03:43:23,075] Trial 63 finished with value: 0.6883349046138995 and parameters: {'hidden_dim': 34, 'dropout': 0.22448602500583845, 'learning_rate': 0.0014691274803449923, 'batch_size': 32, 'weight_decay': 1.7050219215276283e-05}. Best is trial 57 with value: 0.7480033460899719.\n",
      "[I 2025-03-20 03:43:34,516] Trial 64 finished with value: 0.6838601436518809 and parameters: {'hidden_dim': 41, 'dropout': 0.25294011212813877, 'learning_rate': 0.002096035247666507, 'batch_size': 32, 'weight_decay': 6.126921380585538e-05}. Best is trial 57 with value: 0.7480033460899719.\n",
      "[I 2025-03-20 03:43:42,476] Trial 65 finished with value: 0.7178346308462208 and parameters: {'hidden_dim': 36, 'dropout': 0.20361247004431784, 'learning_rate': 0.0023070138136608406, 'batch_size': 32, 'weight_decay': 1.3281304735442391e-05}. Best is trial 57 with value: 0.7480033460899719.\n",
      "[I 2025-03-20 03:43:50,403] Trial 66 finished with value: 0.7107504039463999 and parameters: {'hidden_dim': 49, 'dropout': 0.19106711561940953, 'learning_rate': 0.0017256315973891733, 'batch_size': 32, 'weight_decay': 2.9979833421065835e-05}. Best is trial 57 with value: 0.7480033460899719.\n",
      "[I 2025-03-20 03:43:58,305] Trial 67 finished with value: 0.7262396793370245 and parameters: {'hidden_dim': 35, 'dropout': 0.176176205882667, 'learning_rate': 0.0018812233799263762, 'batch_size': 32, 'weight_decay': 9.433601920404222e-06}. Best is trial 57 with value: 0.7480033460899719.\n",
      "[I 2025-03-20 03:44:09,408] Trial 68 finished with value: 0.7083018972028756 and parameters: {'hidden_dim': 32, 'dropout': 0.1738848054980081, 'learning_rate': 0.003200995228504836, 'batch_size': 32, 'weight_decay': 8.748688259640906e-06}. Best is trial 57 with value: 0.7480033460899719.\n",
      "[I 2025-03-20 03:44:17,375] Trial 69 finished with value: 0.648946703882468 and parameters: {'hidden_dim': 45, 'dropout': 0.15731205619923921, 'learning_rate': 0.001357328402207771, 'batch_size': 32, 'weight_decay': 7.013641638528847e-06}. Best is trial 57 with value: 0.7480033460899719.\n",
      "[I 2025-03-20 03:44:25,257] Trial 70 finished with value: 0.6963466175920034 and parameters: {'hidden_dim': 41, 'dropout': 0.30897685438028083, 'learning_rate': 0.003902939917520293, 'batch_size': 32, 'weight_decay': 9.554618369638984e-06}. Best is trial 57 with value: 0.7480033460899719.\n",
      "[I 2025-03-20 03:44:33,124] Trial 71 finished with value: 0.710230583485254 and parameters: {'hidden_dim': 36, 'dropout': 0.21435707506226134, 'learning_rate': 0.0018426289452099954, 'batch_size': 32, 'weight_decay': 1.878818662128137e-05}. Best is trial 57 with value: 0.7480033460899719.\n",
      "[I 2025-03-20 03:44:44,287] Trial 72 finished with value: 0.7096563714743188 and parameters: {'hidden_dim': 38, 'dropout': 0.23995036176201556, 'learning_rate': 0.002248580111136168, 'batch_size': 32, 'weight_decay': 5.985606113575444e-06}. Best is trial 57 with value: 0.7480033460899719.\n",
      "[I 2025-03-20 03:44:52,153] Trial 73 finished with value: 0.7595339278689538 and parameters: {'hidden_dim': 34, 'dropout': 0.18185558794658085, 'learning_rate': 0.0026771228831630476, 'batch_size': 32, 'weight_decay': 2.2821535811294914e-05}. Best is trial 73 with value: 0.7595339278689538.\n",
      "[I 2025-03-20 03:45:00,079] Trial 74 finished with value: 0.7098793309006569 and parameters: {'hidden_dim': 50, 'dropout': 0.18406490954321297, 'learning_rate': 0.0035915612631417693, 'batch_size': 32, 'weight_decay': 2.32251374360746e-05}. Best is trial 73 with value: 0.7595339278689538.\n",
      "[I 2025-03-20 03:45:18,494] Trial 75 finished with value: 0.7041943448700706 and parameters: {'hidden_dim': 42, 'dropout': 0.11553326040445572, 'learning_rate': 0.002608106772010505, 'batch_size': 16, 'weight_decay': 1.0940870181019865e-05}. Best is trial 73 with value: 0.7595339278689538.\n",
      "[I 2025-03-20 03:45:26,358] Trial 76 finished with value: 0.7370269228676308 and parameters: {'hidden_dim': 45, 'dropout': 0.19975043594890776, 'learning_rate': 0.0030476507743848486, 'batch_size': 32, 'weight_decay': 1.587963619754152e-05}. Best is trial 73 with value: 0.7595339278689538.\n",
      "[I 2025-03-20 03:45:34,223] Trial 77 finished with value: 0.7512291918468877 and parameters: {'hidden_dim': 56, 'dropout': 0.22781246223551804, 'learning_rate': 0.0015162662146863749, 'batch_size': 32, 'weight_decay': 1.9519674121190175e-05}. Best is trial 73 with value: 0.7595339278689538.\n",
      "[I 2025-03-20 03:45:45,393] Trial 78 finished with value: 0.6416886048638067 and parameters: {'hidden_dim': 56, 'dropout': 0.23152607513321727, 'learning_rate': 0.0008974067012984945, 'batch_size': 32, 'weight_decay': 1.5302899774780996e-05}. Best is trial 73 with value: 0.7595339278689538.\n",
      "[I 2025-03-20 03:45:53,374] Trial 79 finished with value: 0.6685112887379278 and parameters: {'hidden_dim': 54, 'dropout': 0.20269398521612517, 'learning_rate': 0.0015668511011156703, 'batch_size': 32, 'weight_decay': 1.7522778138029583e-05}. Best is trial 73 with value: 0.7595339278689538.\n",
      "[I 2025-03-20 03:46:01,246] Trial 80 finished with value: 0.6624283722515424 and parameters: {'hidden_dim': 62, 'dropout': 0.27463034504162814, 'learning_rate': 0.0011341796134114086, 'batch_size': 32, 'weight_decay': 2.015265819687676e-05}. Best is trial 73 with value: 0.7595339278689538.\n",
      "[I 2025-03-20 03:46:09,240] Trial 81 finished with value: 0.6910829182763675 and parameters: {'hidden_dim': 45, 'dropout': 0.17940238518708845, 'learning_rate': 0.0012865927321263765, 'batch_size': 32, 'weight_decay': 1.3885300798817434e-05}. Best is trial 73 with value: 0.7595339278689538.\n",
      "[I 2025-03-20 03:46:20,307] Trial 82 finished with value: 0.7003055638047658 and parameters: {'hidden_dim': 50, 'dropout': 0.19454838398615723, 'learning_rate': 0.0019109171353642199, 'batch_size': 32, 'weight_decay': 2.3896075261561462e-06}. Best is trial 73 with value: 0.7595339278689538.\n",
      "[I 2025-03-20 03:46:28,216] Trial 83 finished with value: 0.7019865176916613 and parameters: {'hidden_dim': 38, 'dropout': 0.22336780636644923, 'learning_rate': 0.0027314219535546865, 'batch_size': 32, 'weight_decay': 1.5956565106805057e-05}. Best is trial 73 with value: 0.7595339278689538.\n",
      "[I 2025-03-20 03:46:36,112] Trial 84 finished with value: 0.6582407794700459 and parameters: {'hidden_dim': 66, 'dropout': 0.17143947824464603, 'learning_rate': 0.005085003474633983, 'batch_size': 32, 'weight_decay': 1.244233678296249e-05}. Best is trial 73 with value: 0.7595339278689538.\n",
      "[I 2025-03-20 03:46:43,951] Trial 85 finished with value: 0.7047164013281009 and parameters: {'hidden_dim': 54, 'dropout': 0.2634464572467713, 'learning_rate': 0.0030461740463364542, 'batch_size': 32, 'weight_decay': 3.8951168083791e-05}. Best is trial 73 with value: 0.7595339278689538.\n",
      "[I 2025-03-20 03:46:55,068] Trial 86 finished with value: 0.6908793599316997 and parameters: {'hidden_dim': 59, 'dropout': 0.24626333865252753, 'learning_rate': 0.001489542806083119, 'batch_size': 32, 'weight_decay': 1.172812095376812e-05}. Best is trial 73 with value: 0.7595339278689538.\n",
      "[I 2025-03-20 03:47:02,931] Trial 87 finished with value: 0.7182190360954647 and parameters: {'hidden_dim': 34, 'dropout': 0.16639439794511163, 'learning_rate': 0.004120395681649588, 'batch_size': 32, 'weight_decay': 2.763661702693802e-05}. Best is trial 73 with value: 0.7595339278689538.\n",
      "[I 2025-03-20 03:47:18,057] Trial 88 finished with value: 0.6360265430852339 and parameters: {'hidden_dim': 46, 'dropout': 0.20221093832313752, 'learning_rate': 0.006380437444484029, 'batch_size': 16, 'weight_decay': 2.233763858846271e-05}. Best is trial 73 with value: 0.7595339278689538.\n",
      "[I 2025-03-20 03:47:29,135] Trial 89 finished with value: 0.745301030977321 and parameters: {'hidden_dim': 50, 'dropout': 0.15086965781006778, 'learning_rate': 0.002398279143645055, 'batch_size': 32, 'weight_decay': 3.376694268475419e-05}. Best is trial 73 with value: 0.7595339278689538.\n",
      "[I 2025-03-20 03:47:37,219] Trial 90 finished with value: 0.7753739552432268 and parameters: {'hidden_dim': 51, 'dropout': 0.14695007074091293, 'learning_rate': 0.0028251714498014244, 'batch_size': 32, 'weight_decay': 3.4654250375245165e-05}. Best is trial 90 with value: 0.7753739552432268.\n",
      "[I 2025-03-20 03:47:45,431] Trial 91 finished with value: 0.7228190978517398 and parameters: {'hidden_dim': 51, 'dropout': 0.1478475879267226, 'learning_rate': 0.0023361865855832283, 'batch_size': 32, 'weight_decay': 3.633743126520466e-05}. Best is trial 90 with value: 0.7753739552432268.\n",
      "[I 2025-03-20 03:47:55,482] Trial 92 finished with value: 0.6803339530179963 and parameters: {'hidden_dim': 55, 'dropout': 0.14169036445104116, 'learning_rate': 0.0028905522822643428, 'batch_size': 32, 'weight_decay': 4.336125706269849e-05}. Best is trial 90 with value: 0.7753739552432268.\n",
      "[I 2025-03-20 03:48:04,501] Trial 93 finished with value: 0.6855819366643553 and parameters: {'hidden_dim': 59, 'dropout': 0.18607011410939944, 'learning_rate': 0.0035892482892395288, 'batch_size': 32, 'weight_decay': 3.48906345468816e-05}. Best is trial 90 with value: 0.7753739552432268.\n",
      "[I 2025-03-20 03:48:17,096] Trial 94 finished with value: 0.717987724732087 and parameters: {'hidden_dim': 48, 'dropout': 0.16319558470129542, 'learning_rate': 0.0024391342283286346, 'batch_size': 32, 'weight_decay': 4.751163775199635e-05}. Best is trial 90 with value: 0.7753739552432268.\n",
      "[I 2025-03-20 03:48:25,807] Trial 95 finished with value: 0.6727773981429058 and parameters: {'hidden_dim': 52, 'dropout': 0.131805676482476, 'learning_rate': 0.003807991214343368, 'batch_size': 32, 'weight_decay': 3.260797212922757e-05}. Best is trial 90 with value: 0.7753739552432268.\n",
      "[I 2025-03-20 03:48:36,521] Trial 96 finished with value: 0.6841108047823395 and parameters: {'hidden_dim': 57, 'dropout': 0.1539357717684214, 'learning_rate': 0.0044600448181629174, 'batch_size': 32, 'weight_decay': 2.5073324848229413e-05}. Best is trial 90 with value: 0.7753739552432268.\n",
      "[I 2025-03-20 03:48:45,631] Trial 97 finished with value: 0.7315972087801804 and parameters: {'hidden_dim': 45, 'dropout': 0.19079485720182185, 'learning_rate': 0.0032044938076080387, 'batch_size': 32, 'weight_decay': 1.9953350434077685e-05}. Best is trial 90 with value: 0.7753739552432268.\n",
      "[I 2025-03-20 03:48:54,834] Trial 98 finished with value: 0.707286175377798 and parameters: {'hidden_dim': 43, 'dropout': 0.21225595081488402, 'learning_rate': 0.003205636853155332, 'batch_size': 32, 'weight_decay': 2.7421536993547065e-05}. Best is trial 90 with value: 0.7753739552432268.\n",
      "[I 2025-03-20 03:49:07,430] Trial 99 finished with value: 0.7031798425998662 and parameters: {'hidden_dim': 45, 'dropout': 0.2248826444895237, 'learning_rate': 0.002739806909891502, 'batch_size': 32, 'weight_decay': 1.877602441131497e-05}. Best is trial 90 with value: 0.7753739552432268.\n",
      "[I 2025-03-20 03:49:07,443] A new study created in memory with name: no-name-cffb0cab-2a75-4d44-8c14-e30f98bf56f4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best LSTM Parameters:\n",
      "  hidden_dim: 51\n",
      "  dropout: 0.14695007074091293\n",
      "  learning_rate: 0.0028251714498014244\n",
      "  batch_size: 32\n",
      "  weight_decay: 3.4654250375245165e-05\n",
      "\n",
      "Optimizing LightGBM for fold 5 using min_max normalization\n",
      "Optimizing LightGBM hyperparameters with CV...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-20 03:49:07,709] Trial 0 finished with value: 0.7364210572039938 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.013661178428178952, 'n_estimators': 456, 'num_leaves': 48, 'max_depth': 6, 'subsample': 0.7552942184455931, 'colsample_bytree': 0.7030385741204636, 'reg_alpha': 1.3087232248047334, 'reg_lambda': 0.6869757398160233, 'min_child_samples': 49}. Best is trial 0 with value: 0.7364210572039938.\n",
      "[I 2025-03-20 03:49:07,830] Trial 1 finished with value: 0.7388272473289514 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.06323892443630524, 'n_estimators': 282, 'num_leaves': 42, 'max_depth': 3, 'subsample': 0.9077831487751247, 'colsample_bytree': 0.6012684467021177, 'reg_alpha': 0.31439409038438626, 'reg_lambda': 1.0912521853098582, 'min_child_samples': 47}. Best is trial 1 with value: 0.7388272473289514.\n",
      "[I 2025-03-20 03:49:07,998] Trial 2 finished with value: 0.7259574938015467 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.019957907467756848, 'n_estimators': 199, 'num_leaves': 37, 'max_depth': 10, 'subsample': 0.7873081624297713, 'colsample_bytree': 0.6493149518105418, 'reg_alpha': 3.6000609130029044, 'reg_lambda': 4.050134848257446, 'min_child_samples': 21}. Best is trial 1 with value: 0.7388272473289514.\n",
      "[I 2025-03-20 03:49:08,115] Trial 3 finished with value: 0.7308021401092974 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.03308671790989007, 'n_estimators': 162, 'num_leaves': 10, 'max_depth': 5, 'subsample': 0.9963593754983149, 'colsample_bytree': 0.805256515122397, 'reg_alpha': 3.0841806167907238, 'reg_lambda': 0.1301677362213169, 'min_child_samples': 21}. Best is trial 1 with value: 0.7388272473289514.\n",
      "[I 2025-03-20 03:49:08,406] Trial 4 finished with value: 0.7653615643668508 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.029437387715603364, 'n_estimators': 405, 'num_leaves': 47, 'max_depth': 6, 'subsample': 0.9716350708762611, 'colsample_bytree': 0.7998448041733087, 'reg_alpha': 2.304933318498776, 'reg_lambda': 3.3362817514757888, 'min_child_samples': 29}. Best is trial 4 with value: 0.7653615643668508.\n",
      "[I 2025-03-20 03:49:08,506] Trial 5 finished with value: 0.7149577081014227 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.07045793365915588, 'n_estimators': 210, 'num_leaves': 23, 'max_depth': 3, 'subsample': 0.8092590874861125, 'colsample_bytree': 0.859403208540551, 'reg_alpha': 3.3760828530802196, 'reg_lambda': 0.15012918259918107, 'min_child_samples': 22}. Best is trial 4 with value: 0.7653615643668508.\n",
      "[I 2025-03-20 03:49:08,780] Trial 6 finished with value: 0.7348558499165627 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.011970252710206382, 'n_estimators': 476, 'num_leaves': 49, 'max_depth': 4, 'subsample': 0.9816084577717837, 'colsample_bytree': 0.7776193095921519, 'reg_alpha': 0.2802529145561249, 'reg_lambda': 1.3744727196612017, 'min_child_samples': 25}. Best is trial 4 with value: 0.7653615643668508.\n",
      "[I 2025-03-20 03:49:08,981] Trial 7 finished with value: 0.7846287256917029 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.0967088301559984, 'n_estimators': 367, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.6725825297010686, 'colsample_bytree': 0.7765487989776441, 'reg_alpha': 1.3901311581414446, 'reg_lambda': 1.2894120399825089, 'min_child_samples': 25}. Best is trial 7 with value: 0.7846287256917029.\n",
      "[I 2025-03-20 03:49:09,193] Trial 8 finished with value: 0.7742625065430856 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.04669085237595252, 'n_estimators': 388, 'num_leaves': 42, 'max_depth': 5, 'subsample': 0.6388242673991037, 'colsample_bytree': 0.9337670455562896, 'reg_alpha': 0.11037032003620384, 'reg_lambda': 0.25448376172072, 'min_child_samples': 45}. Best is trial 7 with value: 0.7846287256917029.\n",
      "[I 2025-03-20 03:49:09,309] Trial 9 finished with value: 0.7427144902695373 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.011232085595448875, 'n_estimators': 177, 'num_leaves': 29, 'max_depth': 4, 'subsample': 0.7436406503252848, 'colsample_bytree': 0.6580654068535353, 'reg_alpha': 0.1699984374960256, 'reg_lambda': 0.1466016632681982, 'min_child_samples': 16}. Best is trial 7 with value: 0.7846287256917029.\n",
      "[I 2025-03-20 03:49:09,576] Trial 10 finished with value: 0.7879643673942818 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.0987558719383339, 'n_estimators': 337, 'num_leaves': 18, 'max_depth': 10, 'subsample': 0.642242017563948, 'colsample_bytree': 0.9614634142305828, 'reg_alpha': 0.7548915517607346, 'reg_lambda': 0.47191940414066896, 'min_child_samples': 37}. Best is trial 10 with value: 0.7879643673942818.\n",
      "[I 2025-03-20 03:49:09,844] Trial 11 finished with value: 0.789410951727108 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.08811492902543544, 'n_estimators': 327, 'num_leaves': 17, 'max_depth': 10, 'subsample': 0.6019793854602531, 'colsample_bytree': 0.993860589036455, 'reg_alpha': 0.7915653922317443, 'reg_lambda': 0.4908802288038389, 'min_child_samples': 38}. Best is trial 11 with value: 0.789410951727108.\n",
      "[I 2025-03-20 03:49:10,101] Trial 12 finished with value: 0.7880605290258984 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.09904613833204629, 'n_estimators': 306, 'num_leaves': 16, 'max_depth': 8, 'subsample': 0.6033581704047635, 'colsample_bytree': 0.9993937583859511, 'reg_alpha': 0.6543087303621062, 'reg_lambda': 0.4491527874295132, 'min_child_samples': 37}. Best is trial 11 with value: 0.789410951727108.\n",
      "[I 2025-03-20 03:49:10,327] Trial 13 finished with value: 0.7733846502675567 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.059150479853954864, 'n_estimators': 263, 'num_leaves': 10, 'max_depth': 8, 'subsample': 0.6035003976897253, 'colsample_bytree': 0.9903471057198379, 'reg_alpha': 0.5497587710479728, 'reg_lambda': 0.36073977073087093, 'min_child_samples': 36}. Best is trial 11 with value: 0.789410951727108.\n",
      "[I 2025-03-20 03:49:10,457] Trial 14 finished with value: 0.7490446295599402 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.04260775628902452, 'n_estimators': 106, 'num_leaves': 19, 'max_depth': 8, 'subsample': 0.601040280387155, 'colsample_bytree': 0.9029095063638374, 'reg_alpha': 0.6670074241508042, 'reg_lambda': 0.26734908270126817, 'min_child_samples': 36}. Best is trial 11 with value: 0.789410951727108.\n",
      "[I 2025-03-20 03:49:10,695] Trial 15 finished with value: 0.7758328270504397 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.08054820064705744, 'n_estimators': 314, 'num_leaves': 16, 'max_depth': 8, 'subsample': 0.7027425747705485, 'colsample_bytree': 0.9991278206705246, 'reg_alpha': 1.271705701760052, 'reg_lambda': 0.6005519835208111, 'min_child_samples': 41}. Best is trial 11 with value: 0.789410951727108.\n",
      "[I 2025-03-20 03:49:10,930] Trial 16 finished with value: 0.7902022686407704 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.049153270642365854, 'n_estimators': 247, 'num_leaves': 27, 'max_depth': 9, 'subsample': 0.8557024840122305, 'colsample_bytree': 0.8865462060766867, 'reg_alpha': 0.3417558966718631, 'reg_lambda': 0.9605461309779892, 'min_child_samples': 33}. Best is trial 16 with value: 0.7902022686407704.\n",
      "[I 2025-03-20 03:49:11,159] Trial 17 finished with value: 0.7868222092171676 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.0465465878014539, 'n_estimators': 242, 'num_leaves': 28, 'max_depth': 9, 'subsample': 0.8800068968445085, 'colsample_bytree': 0.8766707216127839, 'reg_alpha': 0.3840297779966552, 'reg_lambda': 1.9816484674594073, 'min_child_samples': 31}. Best is trial 16 with value: 0.7902022686407704.\n",
      "[I 2025-03-20 03:49:11,549] Trial 18 finished with value: 0.7891401701418367 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.0276669503148614, 'n_estimators': 429, 'num_leaves': 24, 'max_depth': 9, 'subsample': 0.8491865390040959, 'colsample_bytree': 0.9247542413048794, 'reg_alpha': 0.15732636801532773, 'reg_lambda': 0.9134182617267429, 'min_child_samples': 31}. Best is trial 16 with value: 0.7902022686407704.\n",
      "[I 2025-03-20 03:49:12,104] Trial 19 finished with value: 0.8120814759808983 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.055066582050829864, 'n_estimators': 351, 'num_leaves': 37, 'max_depth': 9, 'subsample': 0.9183081737732349, 'colsample_bytree': 0.8416129697716348, 'reg_alpha': 0.42884630132643947, 'reg_lambda': 2.361146160643242, 'min_child_samples': 12}. Best is trial 19 with value: 0.8120814759808983.\n",
      "[I 2025-03-20 03:49:12,442] Trial 20 finished with value: 0.8063997479313741 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.03872168784601257, 'n_estimators': 240, 'num_leaves': 34, 'max_depth': 7, 'subsample': 0.9351507911728097, 'colsample_bytree': 0.8470020073270665, 'reg_alpha': 0.4226531404343252, 'reg_lambda': 2.264708286526748, 'min_child_samples': 12}. Best is trial 19 with value: 0.8120814759808983.\n",
      "[I 2025-03-20 03:49:12,797] Trial 21 finished with value: 0.8072184961811996 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.037562988579447044, 'n_estimators': 239, 'num_leaves': 35, 'max_depth': 7, 'subsample': 0.9284193035856749, 'colsample_bytree': 0.8370506856815749, 'reg_alpha': 0.42478130159875477, 'reg_lambda': 2.348391499173581, 'min_child_samples': 11}. Best is trial 19 with value: 0.8120814759808983.\n",
      "[I 2025-03-20 03:49:13,032] Trial 22 finished with value: 0.7938384840214893 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.036241135685015524, 'n_estimators': 127, 'num_leaves': 34, 'max_depth': 7, 'subsample': 0.9407165929375343, 'colsample_bytree': 0.8366306092515775, 'reg_alpha': 0.4705267745706559, 'reg_lambda': 2.6194968184729914, 'min_child_samples': 11}. Best is trial 19 with value: 0.8120814759808983.\n",
      "[I 2025-03-20 03:49:13,369] Trial 23 finished with value: 0.7895777052780778 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.023436640088171652, 'n_estimators': 227, 'num_leaves': 35, 'max_depth': 7, 'subsample': 0.9394733883321413, 'colsample_bytree': 0.7365058475186161, 'reg_alpha': 0.22066180188581738, 'reg_lambda': 4.923261425328744, 'min_child_samples': 10}. Best is trial 19 with value: 0.8120814759808983.\n",
      "[I 2025-03-20 03:49:13,728] Trial 24 finished with value: 0.7951842957815697 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.03881087601620589, 'n_estimators': 278, 'num_leaves': 39, 'max_depth': 7, 'subsample': 0.9126405882854, 'colsample_bytree': 0.8333961163683786, 'reg_alpha': 0.9800634394236548, 'reg_lambda': 2.0220784228032285, 'min_child_samples': 15}. Best is trial 19 with value: 0.8120814759808983.\n",
      "[I 2025-03-20 03:49:14,155] Trial 25 finished with value: 0.8106794558107178 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.05830176758229365, 'n_estimators': 368, 'num_leaves': 31, 'max_depth': 6, 'subsample': 0.9419478156660014, 'colsample_bytree': 0.8510423074114162, 'reg_alpha': 0.47671373547292656, 'reg_lambda': 1.8568212665665902, 'min_child_samples': 15}. Best is trial 19 with value: 0.8120814759808983.\n",
      "[I 2025-03-20 03:49:14,518] Trial 26 finished with value: 0.8052797097524677 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.05501627697472253, 'n_estimators': 356, 'num_leaves': 32, 'max_depth': 6, 'subsample': 0.8768834975383396, 'colsample_bytree': 0.7429352424988115, 'reg_alpha': 0.23363352585556924, 'reg_lambda': 1.5892077017381276, 'min_child_samples': 16}. Best is trial 19 with value: 0.8120814759808983.\n",
      "[I 2025-03-20 03:49:14,924] Trial 27 finished with value: 0.7909364466425423 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.07393738968783516, 'n_estimators': 428, 'num_leaves': 40, 'max_depth': 5, 'subsample': 0.8237357238093393, 'colsample_bytree': 0.813648102786006, 'reg_alpha': 0.5422871442364616, 'reg_lambda': 3.234838151302246, 'min_child_samples': 14}. Best is trial 19 with value: 0.8120814759808983.\n",
      "[I 2025-03-20 03:49:15,404] Trial 28 finished with value: 0.794618781339877 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.017906647675489138, 'n_estimators': 497, 'num_leaves': 44, 'max_depth': 6, 'subsample': 0.9664184230875238, 'colsample_bytree': 0.9056553782598038, 'reg_alpha': 0.9775536724987547, 'reg_lambda': 1.6597726808936724, 'min_child_samples': 19}. Best is trial 19 with value: 0.8120814759808983.\n",
      "[I 2025-03-20 03:49:15,740] Trial 29 finished with value: 0.7820636710850797 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.05696121062423202, 'n_estimators': 373, 'num_leaves': 31, 'max_depth': 9, 'subsample': 0.8912589981636965, 'colsample_bytree': 0.7454013000430363, 'reg_alpha': 1.6794610652884627, 'reg_lambda': 2.6169609391204047, 'min_child_samples': 18}. Best is trial 19 with value: 0.8120814759808983.\n",
      "[I 2025-03-20 03:49:16,122] Trial 30 finished with value: 0.8073452899077591 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.024928690231990635, 'n_estimators': 344, 'num_leaves': 37, 'max_depth': 6, 'subsample': 0.7697720387073888, 'colsample_bytree': 0.8602966819124603, 'reg_alpha': 0.24093861117361245, 'reg_lambda': 0.8362542918685727, 'min_child_samples': 13}. Best is trial 19 with value: 0.8120814759808983.\n",
      "[I 2025-03-20 03:49:16,507] Trial 31 finished with value: 0.8017663070155724 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.01611401861283965, 'n_estimators': 350, 'num_leaves': 38, 'max_depth': 6, 'subsample': 0.7735182246208606, 'colsample_bytree': 0.8567695210314966, 'reg_alpha': 0.23986694668654535, 'reg_lambda': 0.6848763509999481, 'min_child_samples': 12}. Best is trial 19 with value: 0.8120814759808983.\n",
      "[I 2025-03-20 03:49:16,774] Trial 32 finished with value: 0.7782539388844184 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.02427815334330418, 'n_estimators': 299, 'num_leaves': 35, 'max_depth': 5, 'subsample': 0.7468203055943715, 'colsample_bytree': 0.8756706768833235, 'reg_alpha': 0.18366586210331862, 'reg_lambda': 1.0421894494527788, 'min_child_samples': 14}. Best is trial 19 with value: 0.8120814759808983.\n",
      "[I 2025-03-20 03:49:17,377] Trial 33 finished with value: 0.8093808066983843 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.06840945896644496, 'n_estimators': 401, 'num_leaves': 45, 'max_depth': 7, 'subsample': 0.9139225172912033, 'colsample_bytree': 0.8171757593323491, 'reg_alpha': 0.2928107321000072, 'reg_lambda': 3.2821314681685667, 'min_child_samples': 10}. Best is trial 19 with value: 0.8120814759808983.\n",
      "[I 2025-03-20 03:49:17,648] Trial 34 finished with value: 0.7832461483943223 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.06409905177806453, 'n_estimators': 408, 'num_leaves': 43, 'max_depth': 4, 'subsample': 0.8415987982036366, 'colsample_bytree': 0.7799583238616647, 'reg_alpha': 0.30617844690829804, 'reg_lambda': 3.5006855153519054, 'min_child_samples': 18}. Best is trial 19 with value: 0.8120814759808983.\n",
      "[I 2025-03-20 03:49:18,137] Trial 35 finished with value: 0.8105388212189123 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.07814828509580471, 'n_estimators': 444, 'num_leaves': 46, 'max_depth': 6, 'subsample': 0.9002572476377991, 'colsample_bytree': 0.8248366006206158, 'reg_alpha': 0.12175279296623712, 'reg_lambda': 4.872369392961381, 'min_child_samples': 14}. Best is trial 19 with value: 0.8120814759808983.\n",
      "[I 2025-03-20 03:49:18,475] Trial 36 finished with value: 0.7825790231694942 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.06935973625726662, 'n_estimators': 444, 'num_leaves': 47, 'max_depth': 5, 'subsample': 0.913442517975009, 'colsample_bytree': 0.8223785219127454, 'reg_alpha': 0.10728011541215793, 'reg_lambda': 4.97645564015257, 'min_child_samples': 24}. Best is trial 19 with value: 0.8120814759808983.\n",
      "[I 2025-03-20 03:49:19,072] Trial 37 finished with value: 0.8107145723144497 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.07774398350802954, 'n_estimators': 466, 'num_leaves': 45, 'max_depth': 6, 'subsample': 0.9685091747628699, 'colsample_bytree': 0.7980670947205999, 'reg_alpha': 0.3422514923168429, 'reg_lambda': 3.916065947341201, 'min_child_samples': 10}. Best is trial 19 with value: 0.8120814759808983.\n",
      "[I 2025-03-20 03:49:19,529] Trial 38 finished with value: 0.7939587080221531 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.08128188878862226, 'n_estimators': 482, 'num_leaves': 41, 'max_depth': 6, 'subsample': 0.9626477227974344, 'colsample_bytree': 0.6940755512253752, 'reg_alpha': 0.13186944665761352, 'reg_lambda': 4.247838522484143, 'min_child_samples': 20}. Best is trial 19 with value: 0.8120814759808983.\n",
      "[I 2025-03-20 03:49:19,940] Trial 39 finished with value: 0.7890511575131927 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.051682489649226226, 'n_estimators': 462, 'num_leaves': 46, 'max_depth': 5, 'subsample': 0.9990973296723152, 'colsample_bytree': 0.7891053089749889, 'reg_alpha': 0.544399272619501, 'reg_lambda': 4.035407244833467, 'min_child_samples': 17}. Best is trial 19 with value: 0.8120814759808983.\n",
      "[I 2025-03-20 03:49:20,207] Trial 40 finished with value: 0.7784454816024933 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.08063871713565521, 'n_estimators': 447, 'num_leaves': 50, 'max_depth': 4, 'subsample': 0.9536512395077321, 'colsample_bytree': 0.7965043098013126, 'reg_alpha': 0.13412318266531598, 'reg_lambda': 2.8631100787661756, 'min_child_samples': 22}. Best is trial 19 with value: 0.8120814759808983.\n",
      "[I 2025-03-20 03:49:20,727] Trial 41 finished with value: 0.8070298511273188 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.0681561239252079, 'n_estimators': 406, 'num_leaves': 45, 'max_depth': 7, 'subsample': 0.8938884961379941, 'colsample_bytree': 0.7624357433277728, 'reg_alpha': 0.35667758395559723, 'reg_lambda': 3.633806831130088, 'min_child_samples': 13}. Best is trial 19 with value: 0.8120814759808983.\n",
      "[I 2025-03-20 03:49:21,267] Trial 42 finished with value: 0.8056560385205321 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.061200305733221654, 'n_estimators': 394, 'num_leaves': 48, 'max_depth': 6, 'subsample': 0.9162569208521982, 'colsample_bytree': 0.8158184776319239, 'reg_alpha': 0.31659785796200873, 'reg_lambda': 3.130145636018242, 'min_child_samples': 10}. Best is trial 19 with value: 0.8120814759808983.\n",
      "[I 2025-03-20 03:49:21,668] Trial 43 finished with value: 0.8040543437284882 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.08806949402604582, 'n_estimators': 378, 'num_leaves': 43, 'max_depth': 6, 'subsample': 0.9766713220175565, 'colsample_bytree': 0.7081492099411746, 'reg_alpha': 0.28249285491976295, 'reg_lambda': 4.182294804597818, 'min_child_samples': 15}. Best is trial 19 with value: 0.8120814759808983.\n",
      "[I 2025-03-20 03:49:21,800] Trial 44 finished with value: 0.7338476105726555 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.0735442288073853, 'n_estimators': 426, 'num_leaves': 45, 'max_depth': 5, 'subsample': 0.8673443098069199, 'colsample_bytree': 0.7673242275305895, 'reg_alpha': 4.673879544484267, 'reg_lambda': 1.3143546200889957, 'min_child_samples': 10}. Best is trial 19 with value: 0.8120814759808983.\n",
      "[I 2025-03-20 03:49:22,444] Trial 45 finished with value: 0.8143019501180027 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.06367627205801778, 'n_estimators': 459, 'num_leaves': 41, 'max_depth': 8, 'subsample': 0.9833383982660242, 'colsample_bytree': 0.8100447468483679, 'reg_alpha': 0.18811685031532163, 'reg_lambda': 1.8015455256003534, 'min_child_samples': 13}. Best is trial 45 with value: 0.8143019501180027.\n",
      "[I 2025-03-20 03:49:22,938] Trial 46 finished with value: 0.8023369230316396 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.05481155853265411, 'n_estimators': 471, 'num_leaves': 41, 'max_depth': 8, 'subsample': 0.9860106281585118, 'colsample_bytree': 0.8607196283693526, 'reg_alpha': 0.1843503846810907, 'reg_lambda': 1.822231796264286, 'min_child_samples': 22}. Best is trial 45 with value: 0.8143019501180027.\n",
      "[I 2025-03-20 03:49:23,542] Trial 47 finished with value: 0.8109583722652556 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.04405493602589264, 'n_estimators': 481, 'num_leaves': 39, 'max_depth': 10, 'subsample': 0.9848155385791836, 'colsample_bytree': 0.7978354876444381, 'reg_alpha': 0.13341912414925802, 'reg_lambda': 1.5240043218689825, 'min_child_samples': 17}. Best is trial 45 with value: 0.8143019501180027.\n",
      "[I 2025-03-20 03:49:24,016] Trial 48 finished with value: 0.7908652985699001 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.04293933771336138, 'n_estimators': 488, 'num_leaves': 37, 'max_depth': 10, 'subsample': 0.9537680755706943, 'colsample_bytree': 0.8020333326359474, 'reg_alpha': 0.15432056844759592, 'reg_lambda': 1.2002828971394874, 'min_child_samples': 27}. Best is trial 45 with value: 0.8143019501180027.\n",
      "[I 2025-03-20 03:49:24,602] Trial 49 finished with value: 0.8083551607309157 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.03256689275559443, 'n_estimators': 465, 'num_leaves': 32, 'max_depth': 9, 'subsample': 0.9995795311331219, 'colsample_bytree': 0.728627344398406, 'reg_alpha': 0.20618982200969013, 'reg_lambda': 1.630622274483227, 'min_child_samples': 17}. Best is trial 45 with value: 0.8143019501180027.\n",
      "[I 2025-03-20 03:49:24,789] A new study created in memory with name: no-name-e0e0d457-90c4-4f6d-9454-8e832b59afaf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best LightGBM Parameters:\n",
      "  boosting_type: gbdt\n",
      "  learning_rate: 0.06367627205801778\n",
      "  n_estimators: 459\n",
      "  num_leaves: 41\n",
      "  max_depth: 8\n",
      "  subsample: 0.9833383982660242\n",
      "  colsample_bytree: 0.8100447468483679\n",
      "  reg_alpha: 0.18811685031532163\n",
      "  reg_lambda: 1.8015455256003534\n",
      "  min_child_samples: 13\n",
      "\n",
      "Optimizing LSTM for fold 5 using min_max normalization\n",
      "Created LSTM sequences with lookback=10: 763 train, 145 test\n",
      "Optimizing LSTM hyperparameters with CV...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-20 03:49:49,092] Trial 0 finished with value: 0.6114246758366315 and parameters: {'hidden_dim': 45, 'dropout': 0.4551406810921512, 'learning_rate': 0.007331811314274292, 'batch_size': 16, 'weight_decay': 2.064121088592392e-05}. Best is trial 0 with value: 0.6114246758366315.\n",
      "[I 2025-03-20 03:49:59,766] Trial 1 finished with value: 0.6079155594174203 and parameters: {'hidden_dim': 79, 'dropout': 0.48569536770002286, 'learning_rate': 0.003999161563860724, 'batch_size': 32, 'weight_decay': 3.45872269711161e-05}. Best is trial 0 with value: 0.6114246758366315.\n",
      "[I 2025-03-20 03:50:23,668] Trial 2 finished with value: 0.7191934635268123 and parameters: {'hidden_dim': 32, 'dropout': 0.21712375681979076, 'learning_rate': 0.0016665895921660098, 'batch_size': 16, 'weight_decay': 2.1517123363927774e-05}. Best is trial 2 with value: 0.7191934635268123.\n",
      "[I 2025-03-20 03:50:34,062] Trial 3 finished with value: 0.6351126967355288 and parameters: {'hidden_dim': 127, 'dropout': 0.2873081624297713, 'learning_rate': 0.00017643094449433023, 'batch_size': 32, 'weight_decay': 1.0947309020486406e-05}. Best is trial 2 with value: 0.7191934635268123.\n",
      "[I 2025-03-20 03:50:57,286] Trial 4 finished with value: 0.6366211837233285 and parameters: {'hidden_dim': 47, 'dropout': 0.10585094112968818, 'learning_rate': 0.0004451295365396247, 'batch_size': 16, 'weight_decay': 1.3639281514957935e-06}. Best is trial 2 with value: 0.7191934635268123.\n",
      "[I 2025-03-20 03:51:02,895] Trial 5 finished with value: 0.7385002678155838 and parameters: {'hidden_dim': 59, 'dropout': 0.2875597071705984, 'learning_rate': 0.0033384615669657483, 'batch_size': 64, 'weight_decay': 9.98214837316597e-06}. Best is trial 5 with value: 0.7385002678155838.\n",
      "[I 2025-03-20 03:51:25,888] Trial 6 finished with value: 0.6946212287574208 and parameters: {'hidden_dim': 109, 'dropout': 0.4586320455614753, 'learning_rate': 0.0009209968619749436, 'batch_size': 16, 'weight_decay': 1.6223673683559225e-06}. Best is trial 5 with value: 0.7385002678155838.\n",
      "[I 2025-03-20 03:51:35,892] Trial 7 finished with value: 0.6195919253984422 and parameters: {'hidden_dim': 82, 'dropout': 0.3594032085405511, 'learning_rate': 0.006298297451196278, 'batch_size': 32, 'weight_decay': 7.511737052942637e-05}. Best is trial 5 with value: 0.7385002678155838.\n",
      "[I 2025-03-20 03:51:41,340] Trial 8 finished with value: 0.6453581079444253 and parameters: {'hidden_dim': 125, 'dropout': 0.17649687394806254, 'learning_rate': 0.00809174687672524, 'batch_size': 64, 'weight_decay': 5.656354626844694e-06}. Best is trial 5 with value: 0.7385002678155838.\n",
      "[I 2025-03-20 03:52:04,069] Trial 9 finished with value: 0.5553118279569892 and parameters: {'hidden_dim': 127, 'dropout': 0.3668293205677101, 'learning_rate': 0.009614679235250567, 'batch_size': 16, 'weight_decay': 2.2160868002868673e-05}. Best is trial 5 with value: 0.7385002678155838.\n",
      "[I 2025-03-20 03:52:09,427] Trial 10 finished with value: 0.6962140803945763 and parameters: {'hidden_dim': 68, 'dropout': 0.2783115442415032, 'learning_rate': 0.0020861108338934425, 'batch_size': 64, 'weight_decay': 4.712885048357283e-06}. Best is trial 5 with value: 0.7385002678155838.\n",
      "[I 2025-03-20 03:52:14,825] Trial 11 finished with value: 0.6647543314176549 and parameters: {'hidden_dim': 35, 'dropout': 0.24072164619222963, 'learning_rate': 0.0019833844976595914, 'batch_size': 64, 'weight_decay': 9.224741756397346e-06}. Best is trial 5 with value: 0.7385002678155838.\n",
      "[I 2025-03-20 03:52:23,444] Trial 12 finished with value: 0.6507397298613812 and parameters: {'hidden_dim': 63, 'dropout': 0.17837446011975083, 'learning_rate': 0.0019288337275017535, 'batch_size': 64, 'weight_decay': 5.744275252155949e-05}. Best is trial 5 with value: 0.7385002678155838.\n",
      "[I 2025-03-20 03:52:42,445] Trial 13 finished with value: 0.7084483473123955 and parameters: {'hidden_dim': 34, 'dropout': 0.21834495115854657, 'learning_rate': 0.0008030291804136277, 'batch_size': 16, 'weight_decay': 2.829556495359069e-06}. Best is trial 5 with value: 0.7385002678155838.\n",
      "[I 2025-03-20 03:52:47,664] Trial 14 finished with value: 0.6955354582233771 and parameters: {'hidden_dim': 57, 'dropout': 0.3482143327364933, 'learning_rate': 0.0033529860098850885, 'batch_size': 64, 'weight_decay': 1.4105979051770502e-05}. Best is trial 5 with value: 0.7385002678155838.\n",
      "[I 2025-03-20 03:53:09,611] Trial 15 finished with value: 0.64710655012369 and parameters: {'hidden_dim': 91, 'dropout': 0.1544285378372467, 'learning_rate': 0.0004423310024578753, 'batch_size': 16, 'weight_decay': 3.7504371664630406e-05}. Best is trial 5 with value: 0.7385002678155838.\n",
      "[I 2025-03-20 03:53:14,743] Trial 16 finished with value: 0.6764267593577838 and parameters: {'hidden_dim': 49, 'dropout': 0.24180338110933164, 'learning_rate': 0.0013925482326161299, 'batch_size': 64, 'weight_decay': 4.66462015927367e-06}. Best is trial 5 with value: 0.7385002678155838.\n",
      "[I 2025-03-20 03:53:36,931] Trial 17 finished with value: 0.7127931037556237 and parameters: {'hidden_dim': 32, 'dropout': 0.3224116386088087, 'learning_rate': 0.003773343719635534, 'batch_size': 16, 'weight_decay': 8.27031567043145e-06}. Best is trial 5 with value: 0.7385002678155838.\n",
      "[I 2025-03-20 03:53:42,062] Trial 18 finished with value: 0.6406082518574046 and parameters: {'hidden_dim': 71, 'dropout': 0.4075641304380402, 'learning_rate': 0.0006275250989672774, 'batch_size': 64, 'weight_decay': 1.9163009873146733e-05}. Best is trial 5 with value: 0.7385002678155838.\n",
      "[I 2025-03-20 03:53:51,748] Trial 19 finished with value: 0.6349707514276991 and parameters: {'hidden_dim': 55, 'dropout': 0.10201541627891061, 'learning_rate': 0.00011600174401008022, 'batch_size': 32, 'weight_decay': 3.4943749770536856e-05}. Best is trial 5 with value: 0.7385002678155838.\n",
      "[I 2025-03-20 03:53:56,968] Trial 20 finished with value: 0.6640676846196694 and parameters: {'hidden_dim': 41, 'dropout': 0.2142926399266967, 'learning_rate': 0.0012884392917203468, 'batch_size': 64, 'weight_decay': 3.3653015577044966e-06}. Best is trial 5 with value: 0.7385002678155838.\n",
      "[I 2025-03-20 03:54:19,028] Trial 21 finished with value: 0.7130793365127707 and parameters: {'hidden_dim': 33, 'dropout': 0.32064637068950136, 'learning_rate': 0.003822789416194326, 'batch_size': 16, 'weight_decay': 8.027066873752158e-06}. Best is trial 5 with value: 0.7385002678155838.\n",
      "[I 2025-03-20 03:54:40,991] Trial 22 finished with value: 0.7213884294053879 and parameters: {'hidden_dim': 56, 'dropout': 0.3067794815972964, 'learning_rate': 0.0028901184465335602, 'batch_size': 16, 'weight_decay': 7.096807012090739e-06}. Best is trial 5 with value: 0.7385002678155838.\n",
      "[I 2025-03-20 03:54:59,702] Trial 23 finished with value: 0.7191328785012557 and parameters: {'hidden_dim': 57, 'dropout': 0.26554047308398837, 'learning_rate': 0.002611413203080844, 'batch_size': 16, 'weight_decay': 1.5176372869313308e-05}. Best is trial 5 with value: 0.7385002678155838.\n",
      "[I 2025-03-20 03:55:21,959] Trial 24 finished with value: 0.6850171277209754 and parameters: {'hidden_dim': 90, 'dropout': 0.30870981051565677, 'learning_rate': 0.005328777761498961, 'batch_size': 16, 'weight_decay': 2.401923815744054e-06}. Best is trial 5 with value: 0.7385002678155838.\n",
      "[I 2025-03-20 03:55:43,588] Trial 25 finished with value: 0.6865303524584477 and parameters: {'hidden_dim': 71, 'dropout': 0.4126165761512621, 'learning_rate': 0.0013727600766172698, 'batch_size': 16, 'weight_decay': 6.323791362555009e-06}. Best is trial 5 with value: 0.7385002678155838.\n",
      "[I 2025-03-20 03:56:02,328] Trial 26 finished with value: 0.7092358991553601 and parameters: {'hidden_dim': 52, 'dropout': 0.25012124148770903, 'learning_rate': 0.002540089703719838, 'batch_size': 16, 'weight_decay': 1.2232777178580025e-05}. Best is trial 5 with value: 0.7385002678155838.\n",
      "[I 2025-03-20 03:56:24,339] Trial 27 finished with value: 0.6464628270564804 and parameters: {'hidden_dim': 42, 'dropout': 0.21749608546038396, 'learning_rate': 0.005126993999715966, 'batch_size': 16, 'weight_decay': 2.8500925764536114e-05}. Best is trial 5 with value: 0.7385002678155838.\n",
      "[I 2025-03-20 03:56:34,149] Trial 28 finished with value: 0.6764155798787165 and parameters: {'hidden_dim': 62, 'dropout': 0.39146690940442874, 'learning_rate': 0.002835266273490696, 'batch_size': 32, 'weight_decay': 5.160114850889316e-05}. Best is trial 5 with value: 0.7385002678155838.\n",
      "[I 2025-03-20 03:56:39,270] Trial 29 finished with value: 0.6662185058218125 and parameters: {'hidden_dim': 79, 'dropout': 0.1509627736392178, 'learning_rate': 0.001681113226962786, 'batch_size': 64, 'weight_decay': 1.9296711100531923e-05}. Best is trial 5 with value: 0.7385002678155838.\n",
      "[I 2025-03-20 03:57:01,281] Trial 30 finished with value: 0.667762343877626 and parameters: {'hidden_dim': 41, 'dropout': 0.29993559673268944, 'learning_rate': 0.0011571247130258643, 'batch_size': 16, 'weight_decay': 9.887381126724087e-05}. Best is trial 5 with value: 0.7385002678155838.\n",
      "[I 2025-03-20 03:57:23,187] Trial 31 finished with value: 0.7069876309731619 and parameters: {'hidden_dim': 61, 'dropout': 0.270060249892945, 'learning_rate': 0.0027302843075738136, 'batch_size': 16, 'weight_decay': 1.6166760426684973e-05}. Best is trial 5 with value: 0.7385002678155838.\n",
      "[I 2025-03-20 03:57:42,207] Trial 32 finished with value: 0.6430057968161703 and parameters: {'hidden_dim': 52, 'dropout': 0.3370783356127718, 'learning_rate': 0.004398077847931767, 'batch_size': 16, 'weight_decay': 2.516145097712921e-05}. Best is trial 5 with value: 0.7385002678155838.\n",
      "[I 2025-03-20 03:58:03,980] Trial 33 finished with value: 0.7448257325559733 and parameters: {'hidden_dim': 46, 'dropout': 0.26619651590250715, 'learning_rate': 0.002356176952477017, 'batch_size': 16, 'weight_decay': 1.2664252719296403e-05}. Best is trial 33 with value: 0.7448257325559733.\n",
      "[I 2025-03-20 03:58:25,833] Trial 34 finished with value: 0.6742934856870985 and parameters: {'hidden_dim': 45, 'dropout': 0.1927494843112335, 'learning_rate': 0.000694685291467271, 'batch_size': 16, 'weight_decay': 1.137771095308731e-05}. Best is trial 33 with value: 0.7448257325559733.\n",
      "[I 2025-03-20 03:58:35,637] Trial 35 finished with value: 0.6419948192047645 and parameters: {'hidden_dim': 39, 'dropout': 0.2908563211348557, 'learning_rate': 0.006932667442689095, 'batch_size': 32, 'weight_decay': 6.649839079472505e-06}. Best is trial 33 with value: 0.7448257325559733.\n",
      "[I 2025-03-20 03:58:54,483] Trial 36 finished with value: 0.6658607851441379 and parameters: {'hidden_dim': 47, 'dropout': 0.26321588076952074, 'learning_rate': 0.00030635383176865627, 'batch_size': 16, 'weight_decay': 1.0472876337196781e-05}. Best is trial 33 with value: 0.7448257325559733.\n",
      "[I 2025-03-20 03:59:16,436] Trial 37 finished with value: 0.703659684541064 and parameters: {'hidden_dim': 66, 'dropout': 0.23243699616060456, 'learning_rate': 0.0016557290899884228, 'batch_size': 16, 'weight_decay': 7.898477313831212e-06}. Best is trial 33 with value: 0.7448257325559733.\n",
      "[I 2025-03-20 03:59:26,150] Trial 38 finished with value: 0.6846326148971378 and parameters: {'hidden_dim': 75, 'dropout': 0.3745804471651348, 'learning_rate': 0.003053362741345916, 'batch_size': 32, 'weight_decay': 4.066776133012872e-06}. Best is trial 33 with value: 0.7448257325559733.\n",
      "[I 2025-03-20 03:59:48,094] Trial 39 finished with value: 0.7014773104498575 and parameters: {'hidden_dim': 103, 'dropout': 0.19880896626915862, 'learning_rate': 0.0010187591800824365, 'batch_size': 16, 'weight_decay': 1.8008746898242691e-06}. Best is trial 33 with value: 0.7448257325559733.\n",
      "[I 2025-03-20 03:59:53,273] Trial 40 finished with value: 0.7327017011072616 and parameters: {'hidden_dim': 49, 'dropout': 0.12856029038037647, 'learning_rate': 0.004936196595996659, 'batch_size': 64, 'weight_decay': 1.4182479561704586e-05}. Best is trial 33 with value: 0.7448257325559733.\n",
      "[I 2025-03-20 03:59:58,463] Trial 41 finished with value: 0.7029911871830832 and parameters: {'hidden_dim': 50, 'dropout': 0.1501569731449584, 'learning_rate': 0.005166153476494984, 'batch_size': 64, 'weight_decay': 1.6801541446230588e-05}. Best is trial 33 with value: 0.7448257325559733.\n",
      "[I 2025-03-20 04:00:06,673] Trial 42 finished with value: 0.6883707794400739 and parameters: {'hidden_dim': 39, 'dropout': 0.11883181709715401, 'learning_rate': 0.002277068009565857, 'batch_size': 64, 'weight_decay': 1.1813725172010772e-05}. Best is trial 33 with value: 0.7448257325559733.\n",
      "[I 2025-03-20 04:00:12,020] Trial 43 finished with value: 0.6938490204723236 and parameters: {'hidden_dim': 45, 'dropout': 0.127580927656702, 'learning_rate': 0.00832771482641986, 'batch_size': 64, 'weight_decay': 2.719608125697228e-05}. Best is trial 33 with value: 0.7448257325559733.\n",
      "[I 2025-03-20 04:00:17,297] Trial 44 finished with value: 0.6866719200908772 and parameters: {'hidden_dim': 57, 'dropout': 0.2860569920227418, 'learning_rate': 0.005981956482151496, 'batch_size': 64, 'weight_decay': 1.3213689287107854e-05}. Best is trial 33 with value: 0.7448257325559733.\n",
      "[I 2025-03-20 04:00:22,441] Trial 45 finished with value: 0.7050095887348916 and parameters: {'hidden_dim': 37, 'dropout': 0.33641838617104325, 'learning_rate': 0.004152163325510906, 'batch_size': 64, 'weight_decay': 5.499551444908522e-06}. Best is trial 33 with value: 0.7448257325559733.\n",
      "[I 2025-03-20 04:00:27,602] Trial 46 finished with value: 0.6689599113349495 and parameters: {'hidden_dim': 45, 'dropout': 0.25208882904370605, 'learning_rate': 0.0016934428358521853, 'batch_size': 64, 'weight_decay': 2.3416339876190804e-05}. Best is trial 33 with value: 0.7448257325559733.\n",
      "[I 2025-03-20 04:00:49,520] Trial 47 finished with value: 0.7025099334629349 and parameters: {'hidden_dim': 84, 'dropout': 0.48092262842940603, 'learning_rate': 0.002217867398247831, 'batch_size': 16, 'weight_decay': 9.241948901948097e-06}. Best is trial 33 with value: 0.7448257325559733.\n",
      "[I 2025-03-20 04:00:54,677] Trial 48 finished with value: 0.7232487339307654 and parameters: {'hidden_dim': 60, 'dropout': 0.31142028449492776, 'learning_rate': 0.0031945024125802895, 'batch_size': 64, 'weight_decay': 6.8066747084836555e-06}. Best is trial 33 with value: 0.7448257325559733.\n",
      "[I 2025-03-20 04:00:59,891] Trial 49 finished with value: 0.6639165987100215 and parameters: {'hidden_dim': 60, 'dropout': 0.3163552720530267, 'learning_rate': 0.009999511468230528, 'batch_size': 64, 'weight_decay': 7.187792568301656e-06}. Best is trial 33 with value: 0.7448257325559733.\n",
      "[I 2025-03-20 04:01:05,037] Trial 50 finished with value: 0.6854807868182117 and parameters: {'hidden_dim': 66, 'dropout': 0.4291704101354078, 'learning_rate': 0.003566835376574814, 'batch_size': 64, 'weight_decay': 3.845934941787749e-06}. Best is trial 33 with value: 0.7448257325559733.\n",
      "[I 2025-03-20 04:01:13,260] Trial 51 finished with value: 0.6892648084692565 and parameters: {'hidden_dim': 54, 'dropout': 0.2951736215902913, 'learning_rate': 0.00481902898069088, 'batch_size': 64, 'weight_decay': 9.587981638033876e-06}. Best is trial 33 with value: 0.7448257325559733.\n",
      "[I 2025-03-20 04:01:18,506] Trial 52 finished with value: 0.6747565905025432 and parameters: {'hidden_dim': 48, 'dropout': 0.2755832556483275, 'learning_rate': 0.0032542293188146916, 'batch_size': 64, 'weight_decay': 5.3887866829018704e-06}. Best is trial 33 with value: 0.7448257325559733.\n",
      "[I 2025-03-20 04:01:23,689] Trial 53 finished with value: 0.6974037064074764 and parameters: {'hidden_dim': 70, 'dropout': 0.3594085641964283, 'learning_rate': 0.0019264535811114323, 'batch_size': 64, 'weight_decay': 2.0914698548624588e-05}. Best is trial 33 with value: 0.7448257325559733.\n",
      "[I 2025-03-20 04:01:33,345] Trial 54 finished with value: 0.7377360061677617 and parameters: {'hidden_dim': 121, 'dropout': 0.3357132646540616, 'learning_rate': 0.002353170320547073, 'batch_size': 32, 'weight_decay': 1.0244242630912548e-06}. Best is trial 33 with value: 0.7448257325559733.\n",
      "[I 2025-03-20 04:01:46,107] Trial 55 finished with value: 0.6430875565889792 and parameters: {'hidden_dim': 115, 'dropout': 0.335688362683769, 'learning_rate': 0.006992136618059809, 'batch_size': 32, 'weight_decay': 1.5490607250200595e-06}. Best is trial 33 with value: 0.7448257325559733.\n",
      "[I 2025-03-20 04:01:55,843] Trial 56 finished with value: 0.6715925821721348 and parameters: {'hidden_dim': 122, 'dropout': 0.3751810677065176, 'learning_rate': 0.003734216235094955, 'batch_size': 32, 'weight_decay': 2.218874699875635e-06}. Best is trial 33 with value: 0.7448257325559733.\n",
      "[I 2025-03-20 04:02:05,422] Trial 57 finished with value: 0.6957438167235243 and parameters: {'hidden_dim': 104, 'dropout': 0.34803995669959686, 'learning_rate': 0.002272452319938561, 'batch_size': 32, 'weight_decay': 1.710829066154596e-05}. Best is trial 33 with value: 0.7448257325559733.\n",
      "[I 2025-03-20 04:02:18,243] Trial 58 finished with value: 0.6482850707010687 and parameters: {'hidden_dim': 74, 'dropout': 0.31076175804527634, 'learning_rate': 0.005975167284294761, 'batch_size': 32, 'weight_decay': 1.3310703771626956e-06}. Best is trial 33 with value: 0.7448257325559733.\n",
      "[I 2025-03-20 04:02:23,399] Trial 59 finished with value: 0.6890644905753881 and parameters: {'hidden_dim': 94, 'dropout': 0.38930495828252143, 'learning_rate': 0.0031915040877334173, 'batch_size': 64, 'weight_decay': 1.0491724284018534e-06}. Best is trial 33 with value: 0.7448257325559733.\n",
      "[I 2025-03-20 04:02:33,081] Trial 60 finished with value: 0.6593735793221085 and parameters: {'hidden_dim': 58, 'dropout': 0.3250684044421034, 'learning_rate': 0.004609767496157644, 'batch_size': 32, 'weight_decay': 3.064866688954396e-06}. Best is trial 33 with value: 0.7448257325559733.\n",
      "[I 2025-03-20 04:02:54,950] Trial 61 finished with value: 0.7329468967510206 and parameters: {'hidden_dim': 52, 'dropout': 0.23215774306661038, 'learning_rate': 0.0018579717806790116, 'batch_size': 16, 'weight_decay': 4.1195437407234274e-05}. Best is trial 33 with value: 0.7448257325559733.\n",
      "[I 2025-03-20 04:03:13,545] Trial 62 finished with value: 0.708619888367584 and parameters: {'hidden_dim': 53, 'dropout': 0.23013055122683057, 'learning_rate': 0.002463936585393066, 'batch_size': 16, 'weight_decay': 5.7944478269381834e-05}. Best is trial 33 with value: 0.7448257325559733.\n",
      "[I 2025-03-20 04:03:35,494] Trial 63 finished with value: 0.7133828969033084 and parameters: {'hidden_dim': 51, 'dropout': 0.306407081553551, 'learning_rate': 0.0018936635651860846, 'batch_size': 16, 'weight_decay': 4.637079209013274e-06}. Best is trial 33 with value: 0.7448257325559733.\n",
      "[I 2025-03-20 04:03:40,626] Trial 64 finished with value: 0.7038618236950566 and parameters: {'hidden_dim': 64, 'dropout': 0.28324769871609123, 'learning_rate': 0.0030103765703978053, 'batch_size': 64, 'weight_decay': 3.145780461309445e-05}. Best is trial 33 with value: 0.7448257325559733.\n",
      "[I 2025-03-20 04:04:02,493] Trial 65 finished with value: 0.7365055958250912 and parameters: {'hidden_dim': 59, 'dropout': 0.1743690145411675, 'learning_rate': 0.0014217701579833637, 'batch_size': 16, 'weight_decay': 1.4235799550294479e-05}. Best is trial 33 with value: 0.7448257325559733.\n",
      "[I 2025-03-20 04:04:21,193] Trial 66 finished with value: 0.7369770072979468 and parameters: {'hidden_dim': 59, 'dropout': 0.1637949440467366, 'learning_rate': 0.001486415057837023, 'batch_size': 16, 'weight_decay': 1.3827262761098238e-05}. Best is trial 33 with value: 0.7448257325559733.\n",
      "[I 2025-03-20 04:04:42,908] Trial 67 finished with value: 0.7026690632702112 and parameters: {'hidden_dim': 64, 'dropout': 0.1852165588425348, 'learning_rate': 0.0014545667005184987, 'batch_size': 16, 'weight_decay': 4.0034449241140486e-05}. Best is trial 33 with value: 0.7448257325559733.\n",
      "[I 2025-03-20 04:04:42,920] A new study created in memory with name: no-name-cc7b546c-51da-46a9-ac04-6b938b279a01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best LSTM Parameters:\n",
      "  hidden_dim: 46\n",
      "  dropout: 0.26619651590250715\n",
      "  learning_rate: 0.002356176952477017\n",
      "  batch_size: 16\n",
      "  weight_decay: 1.2664252719296403e-05\n",
      "\n",
      "Optimizing LightGBM for fold 6 using min_max normalization\n",
      "Optimizing LightGBM hyperparameters with CV...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-20 04:04:43,218] Trial 0 finished with value: 0.7511545797092299 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.013661178428178952, 'n_estimators': 456, 'num_leaves': 48, 'max_depth': 6, 'subsample': 0.7552942184455931, 'colsample_bytree': 0.7030385741204636, 'reg_alpha': 1.3087232248047334, 'reg_lambda': 0.6869757398160233, 'min_child_samples': 49}. Best is trial 0 with value: 0.7511545797092299.\n",
      "[I 2025-03-20 04:04:43,330] Trial 1 finished with value: 0.7449732035371762 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.06323892443630524, 'n_estimators': 282, 'num_leaves': 42, 'max_depth': 3, 'subsample': 0.9077831487751247, 'colsample_bytree': 0.6012684467021177, 'reg_alpha': 0.31439409038438626, 'reg_lambda': 1.0912521853098582, 'min_child_samples': 47}. Best is trial 0 with value: 0.7511545797092299.\n",
      "[I 2025-03-20 04:04:43,532] Trial 2 finished with value: 0.7419445107689251 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.019957907467756848, 'n_estimators': 199, 'num_leaves': 37, 'max_depth': 10, 'subsample': 0.7873081624297713, 'colsample_bytree': 0.6493149518105418, 'reg_alpha': 3.6000609130029044, 'reg_lambda': 4.050134848257446, 'min_child_samples': 21}. Best is trial 0 with value: 0.7511545797092299.\n",
      "[I 2025-03-20 04:04:43,655] Trial 3 finished with value: 0.7440663628611521 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.03308671790989007, 'n_estimators': 162, 'num_leaves': 10, 'max_depth': 5, 'subsample': 0.9963593754983149, 'colsample_bytree': 0.805256515122397, 'reg_alpha': 3.0841806167907238, 'reg_lambda': 0.1301677362213169, 'min_child_samples': 21}. Best is trial 0 with value: 0.7511545797092299.\n",
      "[I 2025-03-20 04:04:43,988] Trial 4 finished with value: 0.7817936108021544 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.029437387715603364, 'n_estimators': 405, 'num_leaves': 47, 'max_depth': 6, 'subsample': 0.9716350708762611, 'colsample_bytree': 0.7998448041733087, 'reg_alpha': 2.304933318498776, 'reg_lambda': 3.3362817514757888, 'min_child_samples': 29}. Best is trial 4 with value: 0.7817936108021544.\n",
      "[I 2025-03-20 04:04:44,096] Trial 5 finished with value: 0.7420994619167531 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.07045793365915588, 'n_estimators': 210, 'num_leaves': 23, 'max_depth': 3, 'subsample': 0.8092590874861125, 'colsample_bytree': 0.859403208540551, 'reg_alpha': 3.3760828530802196, 'reg_lambda': 0.15012918259918107, 'min_child_samples': 22}. Best is trial 4 with value: 0.7817936108021544.\n",
      "[I 2025-03-20 04:04:44,353] Trial 6 finished with value: 0.7385677463492516 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.011970252710206382, 'n_estimators': 476, 'num_leaves': 49, 'max_depth': 4, 'subsample': 0.9816084577717837, 'colsample_bytree': 0.7776193095921519, 'reg_alpha': 0.2802529145561249, 'reg_lambda': 1.3744727196612017, 'min_child_samples': 25}. Best is trial 4 with value: 0.7817936108021544.\n",
      "[I 2025-03-20 04:04:44,580] Trial 7 finished with value: 0.8004477587256889 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.0967088301559984, 'n_estimators': 367, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.6725825297010686, 'colsample_bytree': 0.7765487989776441, 'reg_alpha': 1.3901311581414446, 'reg_lambda': 1.2894120399825089, 'min_child_samples': 25}. Best is trial 7 with value: 0.8004477587256889.\n",
      "[I 2025-03-20 04:04:44,810] Trial 8 finished with value: 0.7749560570736701 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.04669085237595252, 'n_estimators': 388, 'num_leaves': 42, 'max_depth': 5, 'subsample': 0.6388242673991037, 'colsample_bytree': 0.9337670455562896, 'reg_alpha': 0.11037032003620384, 'reg_lambda': 0.25448376172072, 'min_child_samples': 45}. Best is trial 7 with value: 0.8004477587256889.\n",
      "[I 2025-03-20 04:04:44,934] Trial 9 finished with value: 0.7206464637126528 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.011232085595448875, 'n_estimators': 177, 'num_leaves': 29, 'max_depth': 4, 'subsample': 0.7436406503252848, 'colsample_bytree': 0.6580654068535353, 'reg_alpha': 0.1699984374960256, 'reg_lambda': 0.1466016632681982, 'min_child_samples': 16}. Best is trial 7 with value: 0.8004477587256889.\n",
      "[I 2025-03-20 04:04:45,217] Trial 10 finished with value: 0.7958707122398161 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.0987558719383339, 'n_estimators': 337, 'num_leaves': 18, 'max_depth': 10, 'subsample': 0.642242017563948, 'colsample_bytree': 0.9614634142305828, 'reg_alpha': 0.7548915517607346, 'reg_lambda': 0.47191940414066896, 'min_child_samples': 37}. Best is trial 7 with value: 0.8004477587256889.\n",
      "[I 2025-03-20 04:04:45,527] Trial 11 finished with value: 0.8002804535108865 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.08811492902543544, 'n_estimators': 327, 'num_leaves': 17, 'max_depth': 10, 'subsample': 0.6019793854602531, 'colsample_bytree': 0.993860589036455, 'reg_alpha': 0.7915653922317443, 'reg_lambda': 0.4908802288038389, 'min_child_samples': 38}. Best is trial 7 with value: 0.8004477587256889.\n",
      "[I 2025-03-20 04:04:45,747] Trial 12 finished with value: 0.7873556274767145 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.0990179709954607, 'n_estimators': 280, 'num_leaves': 10, 'max_depth': 8, 'subsample': 0.6033581704047635, 'colsample_bytree': 0.8896098816778567, 'reg_alpha': 0.907421645328279, 'reg_lambda': 1.8653713281408886, 'min_child_samples': 37}. Best is trial 7 with value: 0.8004477587256889.\n",
      "[I 2025-03-20 04:04:46,101] Trial 13 finished with value: 0.8148943144823496 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.059391142739541755, 'n_estimators': 337, 'num_leaves': 31, 'max_depth': 8, 'subsample': 0.6877372513421857, 'colsample_bytree': 0.7437973057303883, 'reg_alpha': 1.3765039473276297, 'reg_lambda': 0.36073977073087093, 'min_child_samples': 10}. Best is trial 13 with value: 0.8148943144823496.\n",
      "[I 2025-03-20 04:04:46,306] Trial 14 finished with value: 0.8031937435438896 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.054107603519745036, 'n_estimators': 106, 'num_leaves': 32, 'max_depth': 8, 'subsample': 0.7003420127694024, 'colsample_bytree': 0.7199502625390595, 'reg_alpha': 1.6169271278054258, 'reg_lambda': 0.26799625954839545, 'min_child_samples': 10}. Best is trial 13 with value: 0.8148943144823496.\n",
      "[I 2025-03-20 04:04:46,508] Trial 15 finished with value: 0.7962258601626165 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.04670365687217438, 'n_estimators': 115, 'num_leaves': 31, 'max_depth': 8, 'subsample': 0.7027425747705485, 'colsample_bytree': 0.717860014948173, 'reg_alpha': 1.7435571783177828, 'reg_lambda': 0.28040525124394855, 'min_child_samples': 13}. Best is trial 13 with value: 0.8148943144823496.\n",
      "[I 2025-03-20 04:04:46,944] Trial 16 finished with value: 0.8147541077876459 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.04823331757311557, 'n_estimators': 256, 'num_leaves': 31, 'max_depth': 8, 'subsample': 0.8460344390937014, 'colsample_bytree': 0.7232415113894823, 'reg_alpha': 0.4073972467226906, 'reg_lambda': 0.3034322223278426, 'min_child_samples': 10}. Best is trial 13 with value: 0.8148943144823496.\n",
      "[I 2025-03-20 04:04:47,269] Trial 17 finished with value: 0.800839550048285 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.034386681006939306, 'n_estimators': 249, 'num_leaves': 26, 'max_depth': 7, 'subsample': 0.872602340863694, 'colsample_bytree': 0.8426234594206805, 'reg_alpha': 0.4404659741129002, 'reg_lambda': 0.41278270344394874, 'min_child_samples': 15}. Best is trial 13 with value: 0.8148943144823496.\n",
      "[I 2025-03-20 04:04:47,742] Trial 18 finished with value: 0.8174070159567914 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.04037113334939175, 'n_estimators': 247, 'num_leaves': 36, 'max_depth': 9, 'subsample': 0.8556167667539123, 'colsample_bytree': 0.751186464217004, 'reg_alpha': 0.4896385006801378, 'reg_lambda': 0.20715193852734332, 'min_child_samples': 10}. Best is trial 18 with value: 0.8174070159567914.\n",
      "[I 2025-03-20 04:04:48,352] Trial 19 finished with value: 0.8094746362549163 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.024791026100968453, 'n_estimators': 431, 'num_leaves': 36, 'max_depth': 9, 'subsample': 0.9183081737732349, 'colsample_bytree': 0.7559894786501817, 'reg_alpha': 0.5745039717503271, 'reg_lambda': 0.7299829691014335, 'min_child_samples': 17}. Best is trial 18 with value: 0.8174070159567914.\n",
      "[I 2025-03-20 04:04:48,528] Trial 20 finished with value: 0.7480217639857113 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.03857475845661008, 'n_estimators': 319, 'num_leaves': 37, 'max_depth': 9, 'subsample': 0.8291331333239146, 'colsample_bytree': 0.6654826646650247, 'reg_alpha': 4.8265941957688465, 'reg_lambda': 0.10341899854233196, 'min_child_samples': 31}. Best is trial 18 with value: 0.8174070159567914.\n",
      "[I 2025-03-20 04:04:48,889] Trial 21 finished with value: 0.8147444551366606 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.060386383916593636, 'n_estimators': 226, 'num_leaves': 34, 'max_depth': 7, 'subsample': 0.8543899581921216, 'colsample_bytree': 0.7472105296614974, 'reg_alpha': 0.4056350079628855, 'reg_lambda': 0.24244765642762803, 'min_child_samples': 10}. Best is trial 18 with value: 0.8174070159567914.\n",
      "[I 2025-03-20 04:04:49,338] Trial 22 finished with value: 0.8181434170965269 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.04315689498618648, 'n_estimators': 260, 'num_leaves': 41, 'max_depth': 9, 'subsample': 0.8933674286447779, 'colsample_bytree': 0.6965675656011887, 'reg_alpha': 0.21243610457924963, 'reg_lambda': 0.19040617544064492, 'min_child_samples': 12}. Best is trial 22 with value: 0.8181434170965269.\n",
      "[I 2025-03-20 04:04:49,861] Trial 23 finished with value: 0.8220027473980789 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.07394712128394551, 'n_estimators': 352, 'num_leaves': 42, 'max_depth': 9, 'subsample': 0.9034998290341414, 'colsample_bytree': 0.6806294635356269, 'reg_alpha': 0.19030637771004824, 'reg_lambda': 0.20567182360508235, 'min_child_samples': 14}. Best is trial 23 with value: 0.8220027473980789.\n",
      "[I 2025-03-20 04:04:50,289] Trial 24 finished with value: 0.8104700566083555 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.07587861718067437, 'n_estimators': 301, 'num_leaves': 42, 'max_depth': 9, 'subsample': 0.9331362822937641, 'colsample_bytree': 0.6084149606736535, 'reg_alpha': 0.18558021780480935, 'reg_lambda': 0.20348444917281516, 'min_child_samples': 17}. Best is trial 23 with value: 0.8220027473980789.\n",
      "[I 2025-03-20 04:04:50,675] Trial 25 finished with value: 0.8109397768232617 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.03984410542896492, 'n_estimators': 242, 'num_leaves': 45, 'max_depth': 9, 'subsample': 0.8939244529121643, 'colsample_bytree': 0.682179205892748, 'reg_alpha': 0.19802982613010353, 'reg_lambda': 0.1811002234008311, 'min_child_samples': 14}. Best is trial 23 with value: 0.8220027473980789.\n",
      "[I 2025-03-20 04:04:51,133] Trial 26 finished with value: 0.8060485429172471 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.026049865142707348, 'n_estimators': 361, 'num_leaves': 39, 'max_depth': 9, 'subsample': 0.8924963835797676, 'colsample_bytree': 0.6371001672618852, 'reg_alpha': 0.11636916534637037, 'reg_lambda': 0.10435965829319574, 'min_child_samples': 19}. Best is trial 23 with value: 0.8220027473980789.\n",
      "[I 2025-03-20 04:04:51,356] Trial 27 finished with value: 0.7902253857834125 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.019660805193910936, 'n_estimators': 149, 'num_leaves': 40, 'max_depth': 7, 'subsample': 0.9479512162417502, 'colsample_bytree': 0.6898488322627078, 'reg_alpha': 0.23971657188878198, 'reg_lambda': 0.19119473378566054, 'min_child_samples': 13}. Best is trial 23 with value: 0.8220027473980789.\n",
      "[I 2025-03-20 04:04:51,831] Trial 28 finished with value: 0.8117406694248904 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.04088205242173285, 'n_estimators': 298, 'num_leaves': 45, 'max_depth': 9, 'subsample': 0.9495828470431862, 'colsample_bytree': 0.6373031029412917, 'reg_alpha': 0.138948556956941, 'reg_lambda': 0.6943083184547654, 'min_child_samples': 13}. Best is trial 23 with value: 0.8220027473980789.\n",
      "[I 2025-03-20 04:04:52,093] Trial 29 finished with value: 0.7776199131098842 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.01928114185011675, 'n_estimators': 272, 'num_leaves': 45, 'max_depth': 6, 'subsample': 0.7686508974017465, 'colsample_bytree': 0.6982178376442258, 'reg_alpha': 0.5187926766503834, 'reg_lambda': 0.5796678510334619, 'min_child_samples': 24}. Best is trial 23 with value: 0.8220027473980789.\n",
      "[I 2025-03-20 04:04:52,355] Trial 30 finished with value: 0.8026248841335214 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.07797009627363691, 'n_estimators': 216, 'num_leaves': 40, 'max_depth': 10, 'subsample': 0.8717152509416043, 'colsample_bytree': 0.8270854491828434, 'reg_alpha': 0.31202568183755985, 'reg_lambda': 0.3661595260833827, 'min_child_samples': 29}. Best is trial 23 with value: 0.8220027473980789.\n",
      "[I 2025-03-20 04:04:52,777] Trial 31 finished with value: 0.8153155944139225 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.056140721195727224, 'n_estimators': 343, 'num_leaves': 28, 'max_depth': 8, 'subsample': 0.8278774689609323, 'colsample_bytree': 0.7442880562328045, 'reg_alpha': 1.017065612108205, 'reg_lambda': 0.33904498065144156, 'min_child_samples': 10}. Best is trial 23 with value: 0.8220027473980789.\n",
      "[I 2025-03-20 04:04:53,184] Trial 32 finished with value: 0.8119799377782415 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.052825912474219285, 'n_estimators': 362, 'num_leaves': 25, 'max_depth': 8, 'subsample': 0.8177514278000666, 'colsample_bytree': 0.7683542709385813, 'reg_alpha': 1.0232466542615895, 'reg_lambda': 0.20393894765974246, 'min_child_samples': 12}. Best is trial 23 with value: 0.8220027473980789.\n",
      "[I 2025-03-20 04:04:53,685] Trial 33 finished with value: 0.8161928182720066 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.06776338837197465, 'n_estimators': 431, 'num_leaves': 34, 'max_depth': 9, 'subsample': 0.8474275528035018, 'colsample_bytree': 0.7285732886661106, 'reg_alpha': 0.2540536101336187, 'reg_lambda': 0.15547949919185924, 'min_child_samples': 18}. Best is trial 23 with value: 0.8220027473980789.\n",
      "[I 2025-03-20 04:04:54,242] Trial 34 finished with value: 0.814033394013865 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.0696485764084737, 'n_estimators': 436, 'num_leaves': 34, 'max_depth': 9, 'subsample': 0.7841620126650067, 'colsample_bytree': 0.6799374779056455, 'reg_alpha': 0.14951163210886212, 'reg_lambda': 0.127026643596883, 'min_child_samples': 19}. Best is trial 23 with value: 0.8220027473980789.\n",
      "[I 2025-03-20 04:04:54,689] Trial 35 finished with value: 0.8149019186739601 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.0827441840354009, 'n_estimators': 474, 'num_leaves': 35, 'max_depth': 10, 'subsample': 0.8880288147163136, 'colsample_bytree': 0.799045560006496, 'reg_alpha': 0.23608031894587922, 'reg_lambda': 0.16632217412919192, 'min_child_samples': 18}. Best is trial 23 with value: 0.8220027473980789.\n",
      "[I 2025-03-20 04:04:55,164] Trial 36 finished with value: 0.8129428320397519 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.0685878013000199, 'n_estimators': 401, 'num_leaves': 39, 'max_depth': 9, 'subsample': 0.9164348082033408, 'colsample_bytree': 0.7153073730516051, 'reg_alpha': 0.23418549537303282, 'reg_lambda': 0.12331619385818826, 'min_child_samples': 22}. Best is trial 23 with value: 0.8220027473980789.\n",
      "[I 2025-03-20 04:04:55,414] Trial 37 finished with value: 0.79729503680863 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.02997312573856037, 'n_estimators': 189, 'num_leaves': 43, 'max_depth': 7, 'subsample': 0.8514733264606966, 'colsample_bytree': 0.6187611163008523, 'reg_alpha': 0.3014299378137501, 'reg_lambda': 0.22836667721212675, 'min_child_samples': 15}. Best is trial 23 with value: 0.8220027473980789.\n",
      "[I 2025-03-20 04:04:56,034] Trial 38 finished with value: 0.8137319645323497 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.03533020955458412, 'n_estimators': 443, 'num_leaves': 47, 'max_depth': 10, 'subsample': 0.8008164124800301, 'colsample_bytree': 0.6661790014516227, 'reg_alpha': 0.3471901286748965, 'reg_lambda': 0.15181811861780442, 'min_child_samples': 19}. Best is trial 23 with value: 0.8220027473980789.\n",
      "[I 2025-03-20 04:04:56,522] Trial 39 finished with value: 0.815459658951804 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.06513554874867261, 'n_estimators': 418, 'num_leaves': 37, 'max_depth': 9, 'subsample': 0.7448223905826693, 'colsample_bytree': 0.7989469758408123, 'reg_alpha': 0.6084947093043901, 'reg_lambda': 0.8103115558725432, 'min_child_samples': 20}. Best is trial 23 with value: 0.8220027473980789.\n",
      "[I 2025-03-20 04:04:57,051] Trial 40 finished with value: 0.818405582177529 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.04266947263952321, 'n_estimators': 306, 'num_leaves': 33, 'max_depth': 10, 'subsample': 0.9646987800667466, 'colsample_bytree': 0.7275424766269574, 'reg_alpha': 0.13591306747292956, 'reg_lambda': 0.1346558083156494, 'min_child_samples': 12}. Best is trial 23 with value: 0.8220027473980789.\n",
      "[I 2025-03-20 04:04:57,603] Trial 41 finished with value: 0.8208513947333751 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.04525089139644413, 'n_estimators': 310, 'num_leaves': 33, 'max_depth': 10, 'subsample': 0.96866734423287, 'colsample_bytree': 0.7055254395896328, 'reg_alpha': 0.13625278890456188, 'reg_lambda': 0.13374220841802684, 'min_child_samples': 12}. Best is trial 23 with value: 0.8220027473980789.\n",
      "[I 2025-03-20 04:04:58,159] Trial 42 finished with value: 0.8188139749197536 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.04366024984355491, 'n_estimators': 309, 'num_leaves': 37, 'max_depth': 10, 'subsample': 0.9979302132243069, 'colsample_bytree': 0.6981149410257523, 'reg_alpha': 0.10194757962199777, 'reg_lambda': 0.12594505813411525, 'min_child_samples': 13}. Best is trial 23 with value: 0.8220027473980789.\n",
      "[I 2025-03-20 04:04:58,723] Trial 43 finished with value: 0.819788417222766 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.04588075295712109, 'n_estimators': 306, 'num_leaves': 39, 'max_depth': 10, 'subsample': 0.9863799133682687, 'colsample_bytree': 0.7006088634766418, 'reg_alpha': 0.1005374304151547, 'reg_lambda': 0.12861456665708124, 'min_child_samples': 12}. Best is trial 23 with value: 0.8220027473980789.\n",
      "[I 2025-03-20 04:04:59,200] Trial 44 finished with value: 0.8138201132499459 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.04965647731621057, 'n_estimators': 302, 'num_leaves': 38, 'max_depth': 10, 'subsample': 0.9932687826035383, 'colsample_bytree': 0.6475589601648065, 'reg_alpha': 0.10087579108937547, 'reg_lambda': 0.1173498609688949, 'min_child_samples': 15}. Best is trial 23 with value: 0.8220027473980789.\n",
      "[I 2025-03-20 04:05:02,988] Trial 45 finished with value: 0.8098405566116034 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.015329423109695761, 'n_estimators': 376, 'num_leaves': 28, 'max_depth': 10, 'subsample': 0.9711040346703336, 'colsample_bytree': 0.6742368044945469, 'reg_alpha': 0.12841707944590658, 'reg_lambda': 0.1000691044528342, 'min_child_samples': 12}. Best is trial 23 with value: 0.8220027473980789.\n",
      "[I 2025-03-20 04:05:03,237] Trial 46 finished with value: 0.7758034816752442 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.027042161548465577, 'n_estimators': 319, 'num_leaves': 33, 'max_depth': 10, 'subsample': 0.9684959796476403, 'colsample_bytree': 0.7091557397947391, 'reg_alpha': 0.15639651534617832, 'reg_lambda': 0.133731638053175, 'min_child_samples': 48}. Best is trial 23 with value: 0.8220027473980789.\n",
      "[I 2025-03-20 04:05:03,646] Trial 47 finished with value: 0.8046500067838164 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.03257749088226862, 'n_estimators': 288, 'num_leaves': 38, 'max_depth': 10, 'subsample': 0.9935941930121892, 'colsample_bytree': 0.7813569944874968, 'reg_alpha': 0.12146105640237952, 'reg_lambda': 2.3291425071952907, 'min_child_samples': 22}. Best is trial 23 with value: 0.8220027473980789.\n",
      "[I 2025-03-20 04:05:04,042] Trial 48 finished with value: 0.8005051962473964 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.04479587308487226, 'n_estimators': 317, 'num_leaves': 21, 'max_depth': 10, 'subsample': 0.9502227253329183, 'colsample_bytree': 0.6223049917779252, 'reg_alpha': 0.10148534053365393, 'reg_lambda': 0.13809283638499723, 'min_child_samples': 16}. Best is trial 23 with value: 0.8220027473980789.\n",
      "[I 2025-03-20 04:05:04,390] Trial 49 finished with value: 0.7912509293028253 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.022586475149204338, 'n_estimators': 347, 'num_leaves': 43, 'max_depth': 10, 'subsample': 0.9995807257793925, 'colsample_bytree': 0.7304785272301153, 'reg_alpha': 0.16976029053216982, 'reg_lambda': 0.16105317694552418, 'min_child_samples': 33}. Best is trial 23 with value: 0.8220027473980789.\n",
      "[I 2025-03-20 04:05:04,531] A new study created in memory with name: no-name-c6ec760b-3e69-4d8a-8a12-4cb80a82b8db\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best LightGBM Parameters:\n",
      "  boosting_type: gbdt\n",
      "  learning_rate: 0.07394712128394551\n",
      "  n_estimators: 352\n",
      "  num_leaves: 42\n",
      "  max_depth: 9\n",
      "  subsample: 0.9034998290341414\n",
      "  colsample_bytree: 0.6806294635356269\n",
      "  reg_alpha: 0.19030637771004824\n",
      "  reg_lambda: 0.20567182360508235\n",
      "  min_child_samples: 14\n",
      "\n",
      "Optimizing LSTM for fold 6 using min_max normalization\n",
      "Created LSTM sequences with lookback=10: 918 train, 145 test\n",
      "Optimizing LSTM hyperparameters with CV...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-20 04:05:27,355] Trial 0 finished with value: 0.5652208737813809 and parameters: {'hidden_dim': 45, 'dropout': 0.4551406810921512, 'learning_rate': 0.007331811314274292, 'batch_size': 16, 'weight_decay': 2.064121088592392e-05}. Best is trial 0 with value: 0.5652208737813809.\n",
      "[I 2025-03-20 04:05:42,856] Trial 1 finished with value: 0.5955478246464325 and parameters: {'hidden_dim': 79, 'dropout': 0.48569536770002286, 'learning_rate': 0.003999161563860724, 'batch_size': 32, 'weight_decay': 3.45872269711161e-05}. Best is trial 1 with value: 0.5955478246464325.\n",
      "[I 2025-03-20 04:06:07,042] Trial 2 finished with value: 0.6840856260346255 and parameters: {'hidden_dim': 32, 'dropout': 0.21712375681979076, 'learning_rate': 0.0016665895921660098, 'batch_size': 16, 'weight_decay': 2.1517123363927774e-05}. Best is trial 2 with value: 0.6840856260346255.\n",
      "[I 2025-03-20 04:06:21,191] Trial 3 finished with value: 0.6205913711752276 and parameters: {'hidden_dim': 127, 'dropout': 0.2873081624297713, 'learning_rate': 0.00017643094449433023, 'batch_size': 32, 'weight_decay': 1.0947309020486406e-05}. Best is trial 2 with value: 0.6840856260346255.\n",
      "[I 2025-03-20 04:06:47,293] Trial 4 finished with value: 0.6550513553159812 and parameters: {'hidden_dim': 47, 'dropout': 0.10585094112968818, 'learning_rate': 0.0004451295365396247, 'batch_size': 16, 'weight_decay': 1.3639281514957935e-06}. Best is trial 2 with value: 0.6840856260346255.\n",
      "[I 2025-03-20 04:06:53,711] Trial 5 finished with value: 0.668777604845222 and parameters: {'hidden_dim': 59, 'dropout': 0.2875597071705984, 'learning_rate': 0.0033384615669657483, 'batch_size': 64, 'weight_decay': 9.98214837316597e-06}. Best is trial 2 with value: 0.6840856260346255.\n",
      "[I 2025-03-20 04:07:19,640] Trial 6 finished with value: 0.6954046089759855 and parameters: {'hidden_dim': 109, 'dropout': 0.4586320455614753, 'learning_rate': 0.0009209968619749436, 'batch_size': 16, 'weight_decay': 1.6223673683559225e-06}. Best is trial 6 with value: 0.6954046089759855.\n",
      "[I 2025-03-20 04:07:31,798] Trial 7 finished with value: 0.552162942857051 and parameters: {'hidden_dim': 82, 'dropout': 0.3594032085405511, 'learning_rate': 0.006298297451196278, 'batch_size': 32, 'weight_decay': 7.511737052942637e-05}. Best is trial 6 with value: 0.6954046089759855.\n",
      "[I 2025-03-20 04:07:38,146] Trial 8 finished with value: 0.6253439980706726 and parameters: {'hidden_dim': 125, 'dropout': 0.17649687394806254, 'learning_rate': 0.00809174687672524, 'batch_size': 64, 'weight_decay': 5.656354626844694e-06}. Best is trial 6 with value: 0.6954046089759855.\n",
      "[I 2025-03-20 04:08:04,023] Trial 9 finished with value: 0.5492865075683177 and parameters: {'hidden_dim': 127, 'dropout': 0.3668293205677101, 'learning_rate': 0.009614679235250567, 'batch_size': 16, 'weight_decay': 2.2160868002868673e-05}. Best is trial 6 with value: 0.6954046089759855.\n",
      "[I 2025-03-20 04:08:29,987] Trial 10 finished with value: 0.6527524120919131 and parameters: {'hidden_dim': 99, 'dropout': 0.41017227293204855, 'learning_rate': 0.0005511984661188443, 'batch_size': 16, 'weight_decay': 1.6263352971939932e-06}. Best is trial 6 with value: 0.6954046089759855.\n",
      "[I 2025-03-20 04:08:56,001] Trial 11 finished with value: 0.6814418145376927 and parameters: {'hidden_dim': 99, 'dropout': 0.19459188561104168, 'learning_rate': 0.0015094052682318305, 'batch_size': 16, 'weight_decay': 2.566822645775391e-06}. Best is trial 6 with value: 0.6954046089759855.\n",
      "[I 2025-03-20 04:09:18,973] Trial 12 finished with value: 0.6914809991334044 and parameters: {'hidden_dim': 34, 'dropout': 0.2271619166468864, 'learning_rate': 0.0015088018581849542, 'batch_size': 16, 'weight_decay': 3.81642764484911e-06}. Best is trial 6 with value: 0.6954046089759855.\n",
      "[I 2025-03-20 04:09:44,994] Trial 13 finished with value: 0.6455181173037787 and parameters: {'hidden_dim': 99, 'dropout': 0.2527357263363795, 'learning_rate': 0.0007285120693189867, 'batch_size': 16, 'weight_decay': 3.6106328048010977e-06}. Best is trial 6 with value: 0.6954046089759855.\n",
      "[I 2025-03-20 04:10:11,116] Trial 14 finished with value: 0.6391086285673301 and parameters: {'hidden_dim': 71, 'dropout': 0.34670692255989854, 'learning_rate': 0.00023270185959897602, 'batch_size': 16, 'weight_decay': 3.219692901527042e-06}. Best is trial 6 with value: 0.6954046089759855.\n",
      "[I 2025-03-20 04:10:17,491] Trial 15 finished with value: 0.6677244348178207 and parameters: {'hidden_dim': 115, 'dropout': 0.13657894280905486, 'learning_rate': 0.0013153893239156074, 'batch_size': 64, 'weight_decay': 1.052366589170443e-06}. Best is trial 6 with value: 0.6954046089759855.\n",
      "[I 2025-03-20 04:10:43,416] Trial 16 finished with value: 0.6393656386069267 and parameters: {'hidden_dim': 108, 'dropout': 0.4333994251181329, 'learning_rate': 0.0024684247055058992, 'batch_size': 16, 'weight_decay': 6.021316775675363e-06}. Best is trial 6 with value: 0.6954046089759855.\n",
      "[I 2025-03-20 04:11:09,279] Trial 17 finished with value: 0.6190113125136609 and parameters: {'hidden_dim': 84, 'dropout': 0.251683850684237, 'learning_rate': 0.00031918273409101724, 'batch_size': 16, 'weight_decay': 2.022397676963285e-06}. Best is trial 6 with value: 0.6954046089759855.\n",
      "[I 2025-03-20 04:11:21,550] Trial 18 finished with value: 0.6452431670853501 and parameters: {'hidden_dim': 63, 'dropout': 0.4955787938949916, 'learning_rate': 0.0010311848692327347, 'batch_size': 32, 'weight_decay': 5.048398298311657e-06}. Best is trial 6 with value: 0.6954046089759855.\n",
      "[I 2025-03-20 04:11:27,909] Trial 19 finished with value: 0.5529372080969691 and parameters: {'hidden_dim': 33, 'dropout': 0.323315007918974, 'learning_rate': 0.00011600174401008022, 'batch_size': 64, 'weight_decay': 9.771452615200965e-06}. Best is trial 6 with value: 0.6954046089759855.\n",
      "[I 2025-03-20 04:11:53,659] Trial 20 finished with value: 0.6942036251167035 and parameters: {'hidden_dim': 113, 'dropout': 0.4004790357866204, 'learning_rate': 0.0007747395894669975, 'batch_size': 16, 'weight_decay': 1.0286884838098626e-06}. Best is trial 6 with value: 0.6954046089759855.\n",
      "[I 2025-03-20 04:12:19,576] Trial 21 finished with value: 0.644274584118293 and parameters: {'hidden_dim': 112, 'dropout': 0.3904290136968126, 'learning_rate': 0.000874570402517725, 'batch_size': 16, 'weight_decay': 1.2045473680060215e-06}. Best is trial 6 with value: 0.6954046089759855.\n",
      "[I 2025-03-20 04:12:42,480] Trial 22 finished with value: 0.6926580422372096 and parameters: {'hidden_dim': 92, 'dropout': 0.4548290617385883, 'learning_rate': 0.0020576632196204923, 'batch_size': 16, 'weight_decay': 2.087361891918906e-06}. Best is trial 6 with value: 0.6954046089759855.\n",
      "[I 2025-03-20 04:13:08,477] Trial 23 finished with value: 0.6742929167533628 and parameters: {'hidden_dim': 92, 'dropout': 0.4388477612253276, 'learning_rate': 0.0005779927304074329, 'batch_size': 16, 'weight_decay': 1.8873177649009544e-06}. Best is trial 6 with value: 0.6954046089759855.\n",
      "[I 2025-03-20 04:13:34,208] Trial 24 finished with value: 0.6756879150790837 and parameters: {'hidden_dim': 118, 'dropout': 0.468446353010687, 'learning_rate': 0.002217715535478628, 'batch_size': 16, 'weight_decay': 1.067748231638639e-06}. Best is trial 6 with value: 0.6954046089759855.\n",
      "[I 2025-03-20 04:13:59,964] Trial 25 finished with value: 0.6315059318551522 and parameters: {'hidden_dim': 105, 'dropout': 0.41236404232602014, 'learning_rate': 0.00035624939736980416, 'batch_size': 16, 'weight_decay': 2.0048553565664362e-06}. Best is trial 6 with value: 0.6954046089759855.\n",
      "[I 2025-03-20 04:14:25,986] Trial 26 finished with value: 0.6885005156331315 and parameters: {'hidden_dim': 91, 'dropout': 0.4042318695124487, 'learning_rate': 0.0010631315936960874, 'batch_size': 16, 'weight_decay': 2.435497326420217e-06}. Best is trial 6 with value: 0.6954046089759855.\n",
      "[I 2025-03-20 04:14:48,697] Trial 27 finished with value: 0.6192528183504064 and parameters: {'hidden_dim': 118, 'dropout': 0.45851567441807345, 'learning_rate': 0.004140959859029998, 'batch_size': 16, 'weight_decay': 1.5604388170071829e-06}. Best is trial 6 with value: 0.6954046089759855.\n",
      "[I 2025-03-20 04:14:55,040] Trial 28 finished with value: 0.6901054721883874 and parameters: {'hidden_dim': 90, 'dropout': 0.3734873663935882, 'learning_rate': 0.002233658332989968, 'batch_size': 64, 'weight_decay': 2.7913900926456307e-06}. Best is trial 6 with value: 0.6954046089759855.\n",
      "[I 2025-03-20 04:15:10,284] Trial 29 finished with value: 0.6498429063969723 and parameters: {'hidden_dim': 104, 'dropout': 0.4387084115817733, 'learning_rate': 0.00069935916096648, 'batch_size': 32, 'weight_decay': 1.0192959164227854e-06}. Best is trial 6 with value: 0.6954046089759855.\n",
      "[I 2025-03-20 04:15:36,061] Trial 30 finished with value: 0.5894733396816129 and parameters: {'hidden_dim': 111, 'dropout': 0.47574130724842734, 'learning_rate': 0.0027443120920818084, 'batch_size': 16, 'weight_decay': 4.390873562754058e-06}. Best is trial 6 with value: 0.6954046089759855.\n",
      "[I 2025-03-20 04:15:58,744] Trial 31 finished with value: 0.6859777550327468 and parameters: {'hidden_dim': 54, 'dropout': 0.310705071213467, 'learning_rate': 0.0017617740873510557, 'batch_size': 16, 'weight_decay': 7.67927225106783e-06}. Best is trial 6 with value: 0.6954046089759855.\n",
      "[I 2025-03-20 04:16:24,837] Trial 32 finished with value: 0.6908874578256108 and parameters: {'hidden_dim': 44, 'dropout': 0.25195577957045123, 'learning_rate': 0.001200142190188782, 'batch_size': 16, 'weight_decay': 3.900592140988151e-06}. Best is trial 6 with value: 0.6954046089759855.\n",
      "[I 2025-03-20 04:16:50,933] Trial 33 finished with value: 0.6193015875210944 and parameters: {'hidden_dim': 73, 'dropout': 0.49902089888596474, 'learning_rate': 0.005033742553961131, 'batch_size': 16, 'weight_decay': 1.57772877391705e-06}. Best is trial 6 with value: 0.6954046089759855.\n",
      "[I 2025-03-20 04:17:16,958] Trial 34 finished with value: 0.6570189301610161 and parameters: {'hidden_dim': 75, 'dropout': 0.4431816295131722, 'learning_rate': 0.0017656246774359501, 'batch_size': 16, 'weight_decay': 2.3633854797112075e-06}. Best is trial 6 with value: 0.6954046089759855.\n",
      "[I 2025-03-20 04:17:28,991] Trial 35 finished with value: 0.6261941583210345 and parameters: {'hidden_dim': 120, 'dropout': 0.2237575426060477, 'learning_rate': 0.000773308741548637, 'batch_size': 32, 'weight_decay': 1.4016289069274806e-06}. Best is trial 6 with value: 0.6954046089759855.\n",
      "[I 2025-03-20 04:17:54,939] Trial 36 finished with value: 0.636521573883182 and parameters: {'hidden_dim': 97, 'dropout': 0.3333961163683786, 'learning_rate': 0.0005513649486066943, 'batch_size': 16, 'weight_decay': 3.2548933413515875e-06}. Best is trial 6 with value: 0.6954046089759855.\n",
      "[I 2025-03-20 04:18:20,808] Trial 37 finished with value: 0.616096586695626 and parameters: {'hidden_dim': 87, 'dropout': 0.4725232934259057, 'learning_rate': 0.0015762865331654732, 'batch_size': 16, 'weight_decay': 9.210093439262961e-05}. Best is trial 6 with value: 0.6954046089759855.\n",
      "[I 2025-03-20 04:18:43,623] Trial 38 finished with value: 0.6378514554149798 and parameters: {'hidden_dim': 65, 'dropout': 0.41940489718722096, 'learning_rate': 0.002969706531539267, 'batch_size': 16, 'weight_decay': 4.026213427303051e-05}. Best is trial 6 with value: 0.6954046089759855.\n",
      "[I 2025-03-20 04:18:58,927] Trial 39 finished with value: 0.6355095323855968 and parameters: {'hidden_dim': 38, 'dropout': 0.38502209582902797, 'learning_rate': 0.00038197059586923853, 'batch_size': 32, 'weight_decay': 1.2775014048213326e-05}. Best is trial 6 with value: 0.6954046089759855.\n",
      "[I 2025-03-20 04:19:05,233] Trial 40 finished with value: 0.6951366782549856 and parameters: {'hidden_dim': 105, 'dropout': 0.2833600913132189, 'learning_rate': 0.0038484305001629565, 'batch_size': 64, 'weight_decay': 1.931439232679121e-06}. Best is trial 6 with value: 0.6954046089759855.\n",
      "[I 2025-03-20 04:19:11,566] Trial 41 finished with value: 0.6807406615409498 and parameters: {'hidden_dim': 104, 'dropout': 0.2819687776929019, 'learning_rate': 0.0039089355016614525, 'batch_size': 64, 'weight_decay': 1.3625649386282352e-06}. Best is trial 6 with value: 0.6954046089759855.\n",
      "[I 2025-03-20 04:19:17,888] Trial 42 finished with value: 0.6440014325098118 and parameters: {'hidden_dim': 96, 'dropout': 0.22338318407937807, 'learning_rate': 0.0018616093093328464, 'batch_size': 64, 'weight_decay': 1.9394831081464384e-06}. Best is trial 6 with value: 0.6954046089759855.\n",
      "[I 2025-03-20 04:19:27,543] Trial 43 finished with value: 0.6652605558270976 and parameters: {'hidden_dim': 121, 'dropout': 0.29216659750918306, 'learning_rate': 0.0012988927160425125, 'batch_size': 64, 'weight_decay': 1.295440538205027e-06}. Best is trial 6 with value: 0.6954046089759855.\n",
      "[I 2025-03-20 04:19:34,033] Trial 44 finished with value: 0.6898753419886917 and parameters: {'hidden_dim': 109, 'dropout': 0.1626932075937906, 'learning_rate': 0.005981956482151496, 'batch_size': 64, 'weight_decay': 2.8115027735824443e-06}. Best is trial 6 with value: 0.6954046089759855.\n",
      "[I 2025-03-20 04:19:40,296] Trial 45 finished with value: 0.6845873687009946 and parameters: {'hidden_dim': 79, 'dropout': 0.19996234498647109, 'learning_rate': 0.0034144161508730436, 'batch_size': 64, 'weight_decay': 1.7915467546887279e-06}. Best is trial 6 with value: 0.6954046089759855.\n",
      "[I 2025-03-20 04:20:05,924] Trial 46 finished with value: 0.6758077498358075 and parameters: {'hidden_dim': 124, 'dropout': 0.2599469245541447, 'learning_rate': 0.0009360505489522162, 'batch_size': 16, 'weight_decay': 2.3387126384908967e-06}. Best is trial 6 with value: 0.6954046089759855.\n",
      "[I 2025-03-20 04:20:05,933] A new study created in memory with name: no-name-eca0ee1e-d66d-497d-9379-841af6517050\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best LSTM Parameters:\n",
      "  hidden_dim: 109\n",
      "  dropout: 0.4586320455614753\n",
      "  learning_rate: 0.0009209968619749436\n",
      "  batch_size: 16\n",
      "  weight_decay: 1.6223673683559225e-06\n",
      "\n",
      "Optimizing LightGBM for fold 7 using min_max normalization\n",
      "Optimizing LightGBM hyperparameters with CV...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-20 04:20:06,247] Trial 0 finished with value: 0.7582452088856926 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.013661178428178952, 'n_estimators': 456, 'num_leaves': 48, 'max_depth': 6, 'subsample': 0.7552942184455931, 'colsample_bytree': 0.7030385741204636, 'reg_alpha': 1.3087232248047334, 'reg_lambda': 0.6869757398160233, 'min_child_samples': 49}. Best is trial 0 with value: 0.7582452088856926.\n",
      "[I 2025-03-20 04:20:06,381] Trial 1 finished with value: 0.7447474511758461 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.06323892443630524, 'n_estimators': 282, 'num_leaves': 42, 'max_depth': 3, 'subsample': 0.9077831487751247, 'colsample_bytree': 0.6012684467021177, 'reg_alpha': 0.31439409038438626, 'reg_lambda': 1.0912521853098582, 'min_child_samples': 47}. Best is trial 0 with value: 0.7582452088856926.\n",
      "[I 2025-03-20 04:20:06,615] Trial 2 finished with value: 0.7467652768449934 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.019957907467756848, 'n_estimators': 199, 'num_leaves': 37, 'max_depth': 10, 'subsample': 0.7873081624297713, 'colsample_bytree': 0.6493149518105418, 'reg_alpha': 3.6000609130029044, 'reg_lambda': 4.050134848257446, 'min_child_samples': 21}. Best is trial 0 with value: 0.7582452088856926.\n",
      "[I 2025-03-20 04:20:06,739] Trial 3 finished with value: 0.7388181569399705 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.03308671790989007, 'n_estimators': 162, 'num_leaves': 10, 'max_depth': 5, 'subsample': 0.9963593754983149, 'colsample_bytree': 0.805256515122397, 'reg_alpha': 3.0841806167907238, 'reg_lambda': 0.1301677362213169, 'min_child_samples': 21}. Best is trial 0 with value: 0.7582452088856926.\n",
      "[I 2025-03-20 04:20:07,101] Trial 4 finished with value: 0.7651151920131216 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.029437387715603364, 'n_estimators': 405, 'num_leaves': 47, 'max_depth': 6, 'subsample': 0.9716350708762611, 'colsample_bytree': 0.7998448041733087, 'reg_alpha': 2.304933318498776, 'reg_lambda': 3.3362817514757888, 'min_child_samples': 29}. Best is trial 4 with value: 0.7651151920131216.\n",
      "[I 2025-03-20 04:20:07,211] Trial 5 finished with value: 0.7401398557402963 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.07045793365915588, 'n_estimators': 210, 'num_leaves': 23, 'max_depth': 3, 'subsample': 0.8092590874861125, 'colsample_bytree': 0.859403208540551, 'reg_alpha': 3.3760828530802196, 'reg_lambda': 0.15012918259918107, 'min_child_samples': 22}. Best is trial 4 with value: 0.7651151920131216.\n",
      "[I 2025-03-20 04:20:07,476] Trial 6 finished with value: 0.7352839412191328 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.011970252710206382, 'n_estimators': 476, 'num_leaves': 49, 'max_depth': 4, 'subsample': 0.9816084577717837, 'colsample_bytree': 0.7776193095921519, 'reg_alpha': 0.2802529145561249, 'reg_lambda': 1.3744727196612017, 'min_child_samples': 25}. Best is trial 4 with value: 0.7651151920131216.\n",
      "[I 2025-03-20 04:20:07,757] Trial 7 finished with value: 0.7884809835511006 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.0967088301559984, 'n_estimators': 367, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.6725825297010686, 'colsample_bytree': 0.7765487989776441, 'reg_alpha': 1.3901311581414446, 'reg_lambda': 1.2894120399825089, 'min_child_samples': 25}. Best is trial 7 with value: 0.7884809835511006.\n",
      "[I 2025-03-20 04:20:08,006] Trial 8 finished with value: 0.7745081096334708 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.04669085237595252, 'n_estimators': 388, 'num_leaves': 42, 'max_depth': 5, 'subsample': 0.6388242673991037, 'colsample_bytree': 0.9337670455562896, 'reg_alpha': 0.11037032003620384, 'reg_lambda': 0.25448376172072, 'min_child_samples': 45}. Best is trial 7 with value: 0.7884809835511006.\n",
      "[I 2025-03-20 04:20:08,126] Trial 9 finished with value: 0.7168515194413795 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.011232085595448875, 'n_estimators': 177, 'num_leaves': 29, 'max_depth': 4, 'subsample': 0.7436406503252848, 'colsample_bytree': 0.6580654068535353, 'reg_alpha': 0.1699984374960256, 'reg_lambda': 0.1466016632681982, 'min_child_samples': 16}. Best is trial 7 with value: 0.7884809835511006.\n",
      "[I 2025-03-20 04:20:08,479] Trial 10 finished with value: 0.7904198859914888 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.0987558719383339, 'n_estimators': 337, 'num_leaves': 18, 'max_depth': 10, 'subsample': 0.642242017563948, 'colsample_bytree': 0.9614634142305828, 'reg_alpha': 0.7548915517607346, 'reg_lambda': 0.47191940414066896, 'min_child_samples': 37}. Best is trial 10 with value: 0.7904198859914888.\n",
      "[I 2025-03-20 04:20:08,827] Trial 11 finished with value: 0.7883581056215518 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.08811492902543544, 'n_estimators': 327, 'num_leaves': 17, 'max_depth': 10, 'subsample': 0.6019793854602531, 'colsample_bytree': 0.993860589036455, 'reg_alpha': 0.7915653922317443, 'reg_lambda': 0.4908802288038389, 'min_child_samples': 38}. Best is trial 10 with value: 0.7904198859914888.\n",
      "[I 2025-03-20 04:20:09,145] Trial 12 finished with value: 0.7881120184953959 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.09822003027572318, 'n_estimators': 307, 'num_leaves': 30, 'max_depth': 8, 'subsample': 0.6801173039155465, 'colsample_bytree': 0.893626879385864, 'reg_alpha': 0.8750718436454238, 'reg_lambda': 1.8653713281408886, 'min_child_samples': 37}. Best is trial 10 with value: 0.7904198859914888.\n",
      "[I 2025-03-20 04:20:09,564] Trial 13 finished with value: 0.789983657176508 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.05345803972760133, 'n_estimators': 371, 'num_leaves': 19, 'max_depth': 8, 'subsample': 0.6866546830080261, 'colsample_bytree': 0.739487019699413, 'reg_alpha': 1.3765039473276297, 'reg_lambda': 0.36073977073087093, 'min_child_samples': 10}. Best is trial 10 with value: 0.7904198859914888.\n",
      "[I 2025-03-20 04:20:09,902] Trial 14 finished with value: 0.7904038884558882 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.05100525278048549, 'n_estimators': 257, 'num_leaves': 16, 'max_depth': 8, 'subsample': 0.7213915181789433, 'colsample_bytree': 0.9955930766794112, 'reg_alpha': 0.4759657006669087, 'reg_lambda': 0.3531473318787954, 'min_child_samples': 10}. Best is trial 10 with value: 0.7904198859914888.\n",
      "[I 2025-03-20 04:20:10,024] Trial 15 finished with value: 0.7357105614590964 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.03723884525074748, 'n_estimators': 115, 'num_leaves': 11, 'max_depth': 8, 'subsample': 0.8344537276585535, 'colsample_bytree': 0.999116402099236, 'reg_alpha': 0.40048967827900994, 'reg_lambda': 0.2704985533025318, 'min_child_samples': 36}. Best is trial 10 with value: 0.7904198859914888.\n",
      "[I 2025-03-20 04:20:10,458] Trial 16 finished with value: 0.7898152762466221 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.0228912073270293, 'n_estimators': 256, 'num_leaves': 24, 'max_depth': 9, 'subsample': 0.7262029280996849, 'colsample_bytree': 0.9411892299151416, 'reg_alpha': 0.4703040391963052, 'reg_lambda': 0.6707769629629746, 'min_child_samples': 10}. Best is trial 10 with value: 0.7904198859914888.\n",
      "[I 2025-03-20 04:20:10,735] Trial 17 finished with value: 0.7815723070036105 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.046365348006120466, 'n_estimators': 250, 'num_leaves': 16, 'max_depth': 9, 'subsample': 0.6095214934622076, 'colsample_bytree': 0.942734695918559, 'reg_alpha': 0.5934813805363774, 'reg_lambda': 0.41278270344394874, 'min_child_samples': 32}. Best is trial 10 with value: 0.7904198859914888.\n",
      "[I 2025-03-20 04:20:11,031] Trial 18 finished with value: 0.7889055372634296 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.0714205745729074, 'n_estimators': 341, 'num_leaves': 24, 'max_depth': 7, 'subsample': 0.8787755180290456, 'colsample_bytree': 0.8663135595810827, 'reg_alpha': 0.1872680649745959, 'reg_lambda': 0.22698624013506324, 'min_child_samples': 42}. Best is trial 10 with value: 0.7904198859914888.\n",
      "[I 2025-03-20 04:20:11,548] Trial 19 finished with value: 0.7941451087904382 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.058366600940812155, 'n_estimators': 431, 'num_leaves': 15, 'max_depth': 9, 'subsample': 0.707396038383983, 'colsample_bytree': 0.9639568377968977, 'reg_alpha': 0.6401077786992869, 'reg_lambda': 0.8606728509972232, 'min_child_samples': 16}. Best is trial 19 with value: 0.7941451087904382.\n",
      "[I 2025-03-20 04:20:12,056] Trial 20 finished with value: 0.7900091485876775 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.07558110092538005, 'n_estimators': 433, 'num_leaves': 20, 'max_depth': 9, 'subsample': 0.6609638240373592, 'colsample_bytree': 0.90163331778984, 'reg_alpha': 0.940943171208533, 'reg_lambda': 2.1296237943504677, 'min_child_samples': 16}. Best is trial 19 with value: 0.7941451087904382.\n",
      "[I 2025-03-20 04:20:12,370] Trial 21 finished with value: 0.7832719405435976 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.052048895800756605, 'n_estimators': 274, 'num_leaves': 14, 'max_depth': 9, 'subsample': 0.7126570267571599, 'colsample_bytree': 0.9708619156892152, 'reg_alpha': 0.5817850552523328, 'reg_lambda': 0.8863319353880528, 'min_child_samples': 16}. Best is trial 19 with value: 0.7941451087904382.\n",
      "[I 2025-03-20 04:20:12,817] Trial 22 finished with value: 0.7895470514356975 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.04112985552652503, 'n_estimators': 424, 'num_leaves': 14, 'max_depth': 7, 'subsample': 0.7664880772068221, 'colsample_bytree': 0.9661552963794725, 'reg_alpha': 0.38190367782032547, 'reg_lambda': 0.5437420189122654, 'min_child_samples': 13}. Best is trial 19 with value: 0.7941451087904382.\n",
      "[I 2025-03-20 04:20:13,356] Trial 23 finished with value: 0.7927214686541574 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.057686385373887594, 'n_estimators': 493, 'num_leaves': 21, 'max_depth': 8, 'subsample': 0.7091774875884672, 'colsample_bytree': 0.9069842609656802, 'reg_alpha': 0.22112237155233916, 'reg_lambda': 0.3538623252171034, 'min_child_samples': 31}. Best is trial 19 with value: 0.7941451087904382.\n",
      "[I 2025-03-20 04:20:13,939] Trial 24 finished with value: 0.7917863979171138 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.060611660414675535, 'n_estimators': 493, 'num_leaves': 27, 'max_depth': 10, 'subsample': 0.6378350594111826, 'colsample_bytree': 0.9077240762118297, 'reg_alpha': 0.25884478241560555, 'reg_lambda': 0.7717984754361071, 'min_child_samples': 32}. Best is trial 19 with value: 0.7941451087904382.\n",
      "[I 2025-03-20 04:20:14,526] Trial 25 finished with value: 0.7962341460076455 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.05830176758229365, 'n_estimators': 498, 'num_leaves': 27, 'max_depth': 9, 'subsample': 0.6998326202060511, 'colsample_bytree': 0.9041632550187783, 'reg_alpha': 0.22351524545390877, 'reg_lambda': 0.9118324701901641, 'min_child_samples': 31}. Best is trial 25 with value: 0.7962341460076455.\n",
      "[I 2025-03-20 04:20:14,987] Trial 26 finished with value: 0.7784623331610699 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.026049865142707348, 'n_estimators': 453, 'num_leaves': 34, 'max_depth': 7, 'subsample': 0.7020742688677728, 'colsample_bytree': 0.8489580045710458, 'reg_alpha': 0.11636916534637037, 'reg_lambda': 2.1115595379116696, 'min_child_samples': 28}. Best is trial 25 with value: 0.7962341460076455.\n",
      "[I 2025-03-20 04:20:15,513] Trial 27 finished with value: 0.7902055353655226 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.03778153972706135, 'n_estimators': 500, 'num_leaves': 26, 'max_depth': 9, 'subsample': 0.8370870583887345, 'colsample_bytree': 0.8322656966941289, 'reg_alpha': 0.20229406167476213, 'reg_lambda': 1.0431373961113595, 'min_child_samples': 33}. Best is trial 25 with value: 0.7962341460076455.\n",
      "[I 2025-03-20 04:20:16,080] Trial 28 finished with value: 0.7989059316276692 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.07798680548479898, 'n_estimators': 475, 'num_leaves': 22, 'max_depth': 8, 'subsample': 0.7842981360740441, 'colsample_bytree': 0.8803555227766457, 'reg_alpha': 0.15180982743816535, 'reg_lambda': 0.18855148635300387, 'min_child_samples': 26}. Best is trial 28 with value: 0.7989059316276692.\n",
      "[I 2025-03-20 04:20:16,542] Trial 29 finished with value: 0.7949145090329068 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.07823719643141308, 'n_estimators': 456, 'num_leaves': 32, 'max_depth': 6, 'subsample': 0.7770537681372724, 'colsample_bytree': 0.8777362633928484, 'reg_alpha': 0.1414682570253124, 'reg_lambda': 0.6440961910927886, 'min_child_samples': 24}. Best is trial 28 with value: 0.7989059316276692.\n",
      "[I 2025-03-20 04:20:16,990] Trial 30 finished with value: 0.7905171609265527 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.08127912541145364, 'n_estimators': 458, 'num_leaves': 33, 'max_depth': 6, 'subsample': 0.7697720387073888, 'colsample_bytree': 0.8833175025056103, 'reg_alpha': 0.14289075870846413, 'reg_lambda': 0.6107847928088047, 'min_child_samples': 26}. Best is trial 28 with value: 0.7989059316276692.\n",
      "[I 2025-03-20 04:20:17,487] Trial 31 finished with value: 0.7928654836966982 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.0637802430286984, 'n_estimators': 452, 'num_leaves': 32, 'max_depth': 6, 'subsample': 0.7493689789266408, 'colsample_bytree': 0.9258126153098183, 'reg_alpha': 0.1362858248036764, 'reg_lambda': 0.10038723230950491, 'min_child_samples': 19}. Best is trial 28 with value: 0.7989059316276692.\n",
      "[I 2025-03-20 04:20:17,938] Trial 32 finished with value: 0.7828729288044849 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.015856563559195746, 'n_estimators': 421, 'num_leaves': 36, 'max_depth': 7, 'subsample': 0.8049181244263212, 'colsample_bytree': 0.834417957095398, 'reg_alpha': 0.10097838166501152, 'reg_lambda': 1.6195518149297832, 'min_child_samples': 23}. Best is trial 28 with value: 0.7989059316276692.\n",
      "[I 2025-03-20 04:20:18,669] Trial 33 finished with value: 0.8055830918319142 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.06503768629638887, 'n_estimators': 468, 'num_leaves': 27, 'max_depth': 9, 'subsample': 0.8375975002101579, 'colsample_bytree': 0.8706994842996025, 'reg_alpha': 0.15042867782848357, 'reg_lambda': 0.9630839359018448, 'min_child_samples': 19}. Best is trial 33 with value: 0.8055830918319142.\n",
      "[I 2025-03-20 04:20:19,083] Trial 34 finished with value: 0.7965349571889447 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.08156702018381681, 'n_estimators': 472, 'num_leaves': 39, 'max_depth': 5, 'subsample': 0.8668042850188088, 'colsample_bytree': 0.8684851594759402, 'reg_alpha': 0.1497573874706667, 'reg_lambda': 0.19245040381020687, 'min_child_samples': 19}. Best is trial 33 with value: 0.8055830918319142.\n",
      "[I 2025-03-20 04:20:19,498] Trial 35 finished with value: 0.794650001880407 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.06670086070877458, 'n_estimators': 476, 'num_leaves': 40, 'max_depth': 5, 'subsample': 0.8853579570751645, 'colsample_bytree': 0.8204207445919348, 'reg_alpha': 0.23749354446247498, 'reg_lambda': 0.20327618778110193, 'min_child_samples': 19}. Best is trial 33 with value: 0.8055830918319142.\n",
      "[I 2025-03-20 04:20:19,829] Trial 36 finished with value: 0.7862810861968823 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.08609292133202916, 'n_estimators': 401, 'num_leaves': 27, 'max_depth': 5, 'subsample': 0.9390348773586282, 'colsample_bytree': 0.846641324019938, 'reg_alpha': 0.33221822930953265, 'reg_lambda': 0.18096239637976475, 'min_child_samples': 28}. Best is trial 33 with value: 0.8055830918319142.\n",
      "[I 2025-03-20 04:20:20,508] Trial 37 finished with value: 0.802396667208334 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.06873274358942731, 'n_estimators': 476, 'num_leaves': 39, 'max_depth': 8, 'subsample': 0.8482410105592609, 'colsample_bytree': 0.7959139761888102, 'reg_alpha': 0.17264197964683448, 'reg_lambda': 3.015117285803386, 'min_child_samples': 19}. Best is trial 33 with value: 0.8055830918319142.\n",
      "[I 2025-03-20 04:20:20,834] Trial 38 finished with value: 0.7838326457703468 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.08560970931494435, 'n_estimators': 470, 'num_leaves': 46, 'max_depth': 4, 'subsample': 0.8346263326740773, 'colsample_bytree': 0.7791332044326358, 'reg_alpha': 0.16074291239263971, 'reg_lambda': 4.551139252548467, 'min_child_samples': 19}. Best is trial 33 with value: 0.8055830918319142.\n",
      "[I 2025-03-20 04:20:21,040] Trial 39 finished with value: 0.7549582662552227 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.06743574339036783, 'n_estimators': 403, 'num_leaves': 38, 'max_depth': 3, 'subsample': 0.8645672602217614, 'colsample_bytree': 0.7467476141616457, 'reg_alpha': 0.3134821067676956, 'reg_lambda': 3.3865845597492075, 'min_child_samples': 21}. Best is trial 33 with value: 0.8055830918319142.\n",
      "[I 2025-03-20 04:20:21,697] Trial 40 finished with value: 0.804479708831983 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.07310204735347338, 'n_estimators': 375, 'num_leaves': 45, 'max_depth': 8, 'subsample': 0.919385041459303, 'colsample_bytree': 0.8147441276458119, 'reg_alpha': 0.12503228147826803, 'reg_lambda': 3.0050775150481313, 'min_child_samples': 13}. Best is trial 33 with value: 0.8055830918319142.\n",
      "[I 2025-03-20 04:20:22,370] Trial 41 finished with value: 0.8041772097865622 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.07470234990035088, 'n_estimators': 382, 'num_leaves': 42, 'max_depth': 8, 'subsample': 0.9263533665941375, 'colsample_bytree': 0.8019943151751634, 'reg_alpha': 0.1227353811160812, 'reg_lambda': 2.8448629179162217, 'min_child_samples': 13}. Best is trial 33 with value: 0.8055830918319142.\n",
      "[I 2025-03-20 04:20:23,007] Trial 42 finished with value: 0.8046381660785242 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.07152657658971978, 'n_estimators': 374, 'num_leaves': 45, 'max_depth': 8, 'subsample': 0.9285780417131189, 'colsample_bytree': 0.8012696950608881, 'reg_alpha': 0.11868571967558846, 'reg_lambda': 2.7986530815658575, 'min_child_samples': 14}. Best is trial 33 with value: 0.8055830918319142.\n",
      "[I 2025-03-20 04:20:23,642] Trial 43 finished with value: 0.8027307781724776 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.04588075295712109, 'n_estimators': 362, 'num_leaves': 44, 'max_depth': 8, 'subsample': 0.9334010187814712, 'colsample_bytree': 0.8002339872890225, 'reg_alpha': 0.12297151769250812, 'reg_lambda': 2.7205775759581927, 'min_child_samples': 13}. Best is trial 33 with value: 0.8055830918319142.\n",
      "[I 2025-03-20 04:20:23,899] Trial 44 finished with value: 0.7656257398745628 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.04487928249128377, 'n_estimators': 366, 'num_leaves': 45, 'max_depth': 7, 'subsample': 0.9183208918763891, 'colsample_bytree': 0.7315538848088445, 'reg_alpha': 4.673879544484267, 'reg_lambda': 3.106887101989842, 'min_child_samples': 13}. Best is trial 33 with value: 0.8055830918319142.\n",
      "[I 2025-03-20 04:20:24,530] Trial 45 finished with value: 0.8046305274869402 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.05230322931380171, 'n_estimators': 354, 'num_leaves': 42, 'max_depth': 8, 'subsample': 0.9550614624827906, 'colsample_bytree': 0.7608521197544003, 'reg_alpha': 0.12021751917361469, 'reg_lambda': 2.609836398312474, 'min_child_samples': 13}. Best is trial 33 with value: 0.8055830918319142.\n",
      "[I 2025-03-20 04:20:25,035] Trial 46 finished with value: 0.7821160176699892 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.032726854374566475, 'n_estimators': 312, 'num_leaves': 48, 'max_depth': 8, 'subsample': 0.9536482092713444, 'colsample_bytree': 0.6992505656462282, 'reg_alpha': 2.0753259051896107, 'reg_lambda': 3.872839974414542, 'min_child_samples': 14}. Best is trial 33 with value: 0.8055830918319142.\n",
      "[I 2025-03-20 04:20:25,607] Trial 47 finished with value: 0.802742209286297 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.05288043616188556, 'n_estimators': 352, 'num_leaves': 42, 'max_depth': 7, 'subsample': 0.9801569160396391, 'colsample_bytree': 0.7579970761124949, 'reg_alpha': 0.11554432434400021, 'reg_lambda': 4.909696151862137, 'min_child_samples': 12}. Best is trial 33 with value: 0.8055830918319142.\n",
      "[I 2025-03-20 04:20:26,307] Trial 48 finished with value: 0.8094538698725436 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.09111794593591382, 'n_estimators': 384, 'num_leaves': 43, 'max_depth': 10, 'subsample': 0.9019492906020363, 'colsample_bytree': 0.7120447174163372, 'reg_alpha': 0.10128201296407296, 'reg_lambda': 1.3798455934921647, 'min_child_samples': 15}. Best is trial 48 with value: 0.8094538698725436.\n",
      "[I 2025-03-20 04:20:28,117] Trial 49 finished with value: 0.805225221617014 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.09089646037243178, 'n_estimators': 318, 'num_leaves': 44, 'max_depth': 10, 'subsample': 0.9011531115659, 'colsample_bytree': 0.6949957146763862, 'reg_alpha': 0.19196370912564964, 'reg_lambda': 1.2758045602330672, 'min_child_samples': 15}. Best is trial 48 with value: 0.8094538698725436.\n",
      "[I 2025-03-20 04:20:30,249] A new study created in memory with name: no-name-4203c4be-65a3-48ad-8c7a-a691d156e79b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best LightGBM Parameters:\n",
      "  boosting_type: gbdt\n",
      "  learning_rate: 0.09111794593591382\n",
      "  n_estimators: 384\n",
      "  num_leaves: 43\n",
      "  max_depth: 10\n",
      "  subsample: 0.9019492906020363\n",
      "  colsample_bytree: 0.7120447174163372\n",
      "  reg_alpha: 0.10128201296407296\n",
      "  reg_lambda: 1.3798455934921647\n",
      "  min_child_samples: 15\n",
      "\n",
      "Optimizing LSTM for fold 7 using min_max normalization\n",
      "Created LSTM sequences with lookback=10: 1073 train, 145 test\n",
      "Optimizing LSTM hyperparameters with CV...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-20 04:20:56,859] Trial 0 finished with value: 0.5313189275919252 and parameters: {'hidden_dim': 45, 'dropout': 0.4551406810921512, 'learning_rate': 0.007331811314274292, 'batch_size': 16, 'weight_decay': 2.064121088592392e-05}. Best is trial 0 with value: 0.5313189275919252.\n",
      "[I 2025-03-20 04:21:14,194] Trial 1 finished with value: 0.603730601106366 and parameters: {'hidden_dim': 79, 'dropout': 0.48569536770002286, 'learning_rate': 0.003999161563860724, 'batch_size': 32, 'weight_decay': 3.45872269711161e-05}. Best is trial 1 with value: 0.603730601106366.\n",
      "[I 2025-03-20 04:21:44,232] Trial 2 finished with value: 0.7009412593425122 and parameters: {'hidden_dim': 32, 'dropout': 0.21712375681979076, 'learning_rate': 0.0016665895921660098, 'batch_size': 16, 'weight_decay': 2.1517123363927774e-05}. Best is trial 2 with value: 0.7009412593425122.\n",
      "[I 2025-03-20 04:21:58,168] Trial 3 finished with value: 0.6331588654389368 and parameters: {'hidden_dim': 127, 'dropout': 0.2873081624297713, 'learning_rate': 0.00017643094449433023, 'batch_size': 32, 'weight_decay': 1.0947309020486406e-05}. Best is trial 2 with value: 0.7009412593425122.\n",
      "[I 2025-03-20 04:22:27,549] Trial 4 finished with value: 0.6466377873568451 and parameters: {'hidden_dim': 47, 'dropout': 0.10585094112968818, 'learning_rate': 0.0004451295365396247, 'batch_size': 16, 'weight_decay': 1.3639281514957935e-06}. Best is trial 2 with value: 0.7009412593425122.\n",
      "[I 2025-03-20 04:22:35,274] Trial 5 finished with value: 0.6707070306790114 and parameters: {'hidden_dim': 59, 'dropout': 0.2875597071705984, 'learning_rate': 0.0033384615669657483, 'batch_size': 64, 'weight_decay': 9.98214837316597e-06}. Best is trial 2 with value: 0.7009412593425122.\n",
      "[I 2025-03-20 04:23:04,807] Trial 6 finished with value: 0.691454868553904 and parameters: {'hidden_dim': 109, 'dropout': 0.4586320455614753, 'learning_rate': 0.0009209968619749436, 'batch_size': 16, 'weight_decay': 1.6223673683559225e-06}. Best is trial 2 with value: 0.7009412593425122.\n",
      "[I 2025-03-20 04:23:22,123] Trial 7 finished with value: 0.5616444046790319 and parameters: {'hidden_dim': 82, 'dropout': 0.3594032085405511, 'learning_rate': 0.006298297451196278, 'batch_size': 32, 'weight_decay': 7.511737052942637e-05}. Best is trial 2 with value: 0.7009412593425122.\n",
      "[I 2025-03-20 04:23:29,818] Trial 8 finished with value: 0.6128454213890401 and parameters: {'hidden_dim': 125, 'dropout': 0.17649687394806254, 'learning_rate': 0.00809174687672524, 'batch_size': 64, 'weight_decay': 5.656354626844694e-06}. Best is trial 2 with value: 0.7009412593425122.\n",
      "[I 2025-03-20 04:23:59,230] Trial 9 finished with value: 0.5436308968299647 and parameters: {'hidden_dim': 127, 'dropout': 0.3668293205677101, 'learning_rate': 0.009614679235250567, 'batch_size': 16, 'weight_decay': 2.2160868002868673e-05}. Best is trial 2 with value: 0.7009412593425122.\n",
      "[I 2025-03-20 04:24:28,860] Trial 10 finished with value: 0.6620334236298225 and parameters: {'hidden_dim': 32, 'dropout': 0.198627869896562, 'learning_rate': 0.0015689723478599755, 'batch_size': 16, 'weight_decay': 8.469738945067809e-05}. Best is trial 2 with value: 0.7009412593425122.\n",
      "[I 2025-03-20 04:24:58,478] Trial 11 finished with value: 0.6792611564089509 and parameters: {'hidden_dim': 99, 'dropout': 0.19459188561104168, 'learning_rate': 0.0008208508072052221, 'batch_size': 16, 'weight_decay': 1.2356535789799862e-06}. Best is trial 2 with value: 0.7009412593425122.\n",
      "[I 2025-03-20 04:25:25,006] Trial 12 finished with value: 0.6801595013536957 and parameters: {'hidden_dim': 102, 'dropout': 0.39121170409630657, 'learning_rate': 0.0015088018581849542, 'batch_size': 16, 'weight_decay': 3.0637026571262712e-06}. Best is trial 2 with value: 0.7009412593425122.\n",
      "[I 2025-03-20 04:25:54,426] Trial 13 finished with value: 0.6926516105122692 and parameters: {'hidden_dim': 105, 'dropout': 0.24296708365322092, 'learning_rate': 0.0006765029601394963, 'batch_size': 16, 'weight_decay': 3.841393445073376e-06}. Best is trial 2 with value: 0.7009412593425122.\n",
      "[I 2025-03-20 04:26:24,008] Trial 14 finished with value: 0.6528793882930392 and parameters: {'hidden_dim': 79, 'dropout': 0.23755223498704398, 'learning_rate': 0.00035408449626257027, 'batch_size': 16, 'weight_decay': 3.777851311856535e-06}. Best is trial 2 with value: 0.7009412593425122.\n",
      "[I 2025-03-20 04:26:34,881] Trial 15 finished with value: 0.6906811501882424 and parameters: {'hidden_dim': 67, 'dropout': 0.14322510503536331, 'learning_rate': 0.0021582167694204684, 'batch_size': 64, 'weight_decay': 8.73103087669017e-06}. Best is trial 2 with value: 0.7009412593425122.\n",
      "[I 2025-03-20 04:27:01,625] Trial 16 finished with value: 0.6602456908926815 and parameters: {'hidden_dim': 96, 'dropout': 0.2531146568668383, 'learning_rate': 0.00046120972793413676, 'batch_size': 16, 'weight_decay': 3.607028329864146e-05}. Best is trial 2 with value: 0.7009412593425122.\n",
      "[I 2025-03-20 04:27:31,034] Trial 17 finished with value: 0.6254604333866522 and parameters: {'hidden_dim': 114, 'dropout': 0.3170523748258723, 'learning_rate': 0.00010728531826263386, 'batch_size': 16, 'weight_decay': 2.3487371390342356e-06}. Best is trial 2 with value: 0.7009412593425122.\n",
      "[I 2025-03-20 04:27:48,247] Trial 18 finished with value: 0.6372572740591426 and parameters: {'hidden_dim': 87, 'dropout': 0.23953327682962694, 'learning_rate': 0.0006275250989672774, 'batch_size': 32, 'weight_decay': 6.542799411237608e-06}. Best is trial 2 with value: 0.7009412593425122.\n",
      "[I 2025-03-20 04:27:55,979] Trial 19 finished with value: 0.6428106962743171 and parameters: {'hidden_dim': 68, 'dropout': 0.15100282581222765, 'learning_rate': 0.0003062866640340381, 'batch_size': 64, 'weight_decay': 1.4240140043185105e-05}. Best is trial 2 with value: 0.7009412593425122.\n",
      "[I 2025-03-20 04:28:25,635] Trial 20 finished with value: 0.6835021141598568 and parameters: {'hidden_dim': 33, 'dropout': 0.32523067423385355, 'learning_rate': 0.0014922903054061507, 'batch_size': 16, 'weight_decay': 4.534851314379002e-06}. Best is trial 2 with value: 0.7009412593425122.\n",
      "[I 2025-03-20 04:28:54,924] Trial 21 finished with value: 0.7036231731893468 and parameters: {'hidden_dim': 112, 'dropout': 0.42636546121294133, 'learning_rate': 0.0009293239847581082, 'batch_size': 16, 'weight_decay': 2.0713612975876557e-06}. Best is trial 21 with value: 0.7036231731893468.\n",
      "[I 2025-03-20 04:29:24,094] Trial 22 finished with value: 0.6286919069581222 and parameters: {'hidden_dim': 113, 'dropout': 0.42705867313937407, 'learning_rate': 0.002318999954988156, 'batch_size': 16, 'weight_decay': 2.2085681115651907e-06}. Best is trial 21 with value: 0.7036231731893468.\n",
      "[I 2025-03-20 04:29:53,508] Trial 23 finished with value: 0.6835614061501333 and parameters: {'hidden_dim': 92, 'dropout': 0.2600546439746263, 'learning_rate': 0.0006856707178971015, 'batch_size': 16, 'weight_decay': 2.8407366639036087e-06}. Best is trial 21 with value: 0.7036231731893468.\n",
      "[I 2025-03-20 04:30:19,705] Trial 24 finished with value: 0.6840850736332892 and parameters: {'hidden_dim': 106, 'dropout': 0.21616437549879228, 'learning_rate': 0.0011909319333426823, 'batch_size': 16, 'weight_decay': 1.644387391646328e-06}. Best is trial 21 with value: 0.7036231731893468.\n",
      "[I 2025-03-20 04:30:48,920] Trial 25 finished with value: 0.6440313933029626 and parameters: {'hidden_dim': 120, 'dropout': 0.4093158340474059, 'learning_rate': 0.0002357086282372379, 'batch_size': 16, 'weight_decay': 3.997156981690294e-05}. Best is trial 21 with value: 0.7036231731893468.\n",
      "[I 2025-03-20 04:31:18,247] Trial 26 finished with value: 0.6361257856611046 and parameters: {'hidden_dim': 116, 'dropout': 0.35066510746147644, 'learning_rate': 0.002540089703719838, 'batch_size': 16, 'weight_decay': 6.105997553781917e-06}. Best is trial 21 with value: 0.7036231731893468.\n",
      "[I 2025-03-20 04:31:47,940] Trial 27 finished with value: 0.7097626920249914 and parameters: {'hidden_dim': 70, 'dropout': 0.27810745810353776, 'learning_rate': 0.0010846565209408274, 'batch_size': 16, 'weight_decay': 1.815205741555055e-05}. Best is trial 27 with value: 0.7097626920249914.\n",
      "[I 2025-03-20 04:31:55,653] Trial 28 finished with value: 0.6592141446073355 and parameters: {'hidden_dim': 48, 'dropout': 0.2837256128301313, 'learning_rate': 0.0011279178916552347, 'batch_size': 64, 'weight_decay': 1.6774508051082706e-05}. Best is trial 27 with value: 0.7097626920249914.\n",
      "[I 2025-03-20 04:32:12,785] Trial 29 finished with value: 0.6689437341348837 and parameters: {'hidden_dim': 59, 'dropout': 0.32530710383277694, 'learning_rate': 0.0036614800399770962, 'batch_size': 32, 'weight_decay': 2.1781434666909898e-05}. Best is trial 27 with value: 0.7097626920249914.\n",
      "[I 2025-03-20 04:32:42,334] Trial 30 finished with value: 0.5717005448381759 and parameters: {'hidden_dim': 41, 'dropout': 0.43050364373417105, 'learning_rate': 0.005420395273435931, 'batch_size': 16, 'weight_decay': 2.7334823881702583e-05}. Best is trial 27 with value: 0.7097626920249914.\n",
      "[I 2025-03-20 04:33:11,885] Trial 31 finished with value: 0.6541086725056147 and parameters: {'hidden_dim': 72, 'dropout': 0.260650226135498, 'learning_rate': 0.0006423970457475085, 'batch_size': 16, 'weight_decay': 1.6166760426684973e-05}. Best is trial 27 with value: 0.7097626920249914.\n",
      "[I 2025-03-20 04:33:38,148] Trial 32 finished with value: 0.6826922942376856 and parameters: {'hidden_dim': 59, 'dropout': 0.17050956966427586, 'learning_rate': 0.001845100458148681, 'batch_size': 16, 'weight_decay': 4.6881429114397445e-05}. Best is trial 27 with value: 0.7097626920249914.\n",
      "[I 2025-03-20 04:34:07,692] Trial 33 finished with value: 0.6850702380200646 and parameters: {'hidden_dim': 106, 'dropout': 0.49902089888596474, 'learning_rate': 0.0010199621906399384, 'batch_size': 16, 'weight_decay': 8.254543162385282e-06}. Best is trial 27 with value: 0.7097626920249914.\n",
      "[I 2025-03-20 04:34:37,426] Trial 34 finished with value: 0.6684258846700871 and parameters: {'hidden_dim': 89, 'dropout': 0.22447637087977707, 'learning_rate': 0.0005592324996866906, 'batch_size': 16, 'weight_decay': 1.274940967292353e-05}. Best is trial 27 with value: 0.7097626920249914.\n",
      "[I 2025-03-20 04:34:54,630] Trial 35 finished with value: 0.6625919107517939 and parameters: {'hidden_dim': 53, 'dropout': 0.3002647552259041, 'learning_rate': 0.0008526806071590007, 'batch_size': 32, 'weight_decay': 1.0422772359755192e-06}. Best is trial 27 with value: 0.7097626920249914.\n",
      "[I 2025-03-20 04:35:24,140] Trial 36 finished with value: 0.6939164303029588 and parameters: {'hidden_dim': 39, 'dropout': 0.1084149606736535, 'learning_rate': 0.001309998308314132, 'batch_size': 16, 'weight_decay': 5.774241800420202e-05}. Best is trial 27 with value: 0.7097626920249914.\n",
      "[I 2025-03-20 04:35:50,458] Trial 37 finished with value: 0.696590003682782 and parameters: {'hidden_dim': 39, 'dropout': 0.46058345986340965, 'learning_rate': 0.002803158142568536, 'batch_size': 16, 'weight_decay': 5.70992434425577e-05}. Best is trial 27 with value: 0.7097626920249914.\n",
      "[I 2025-03-20 04:35:50,466] A new study created in memory with name: no-name-0a4def89-5f22-448d-bc89-ec9001190312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best LSTM Parameters:\n",
      "  hidden_dim: 70\n",
      "  dropout: 0.27810745810353776\n",
      "  learning_rate: 0.0010846565209408274\n",
      "  batch_size: 16\n",
      "  weight_decay: 1.815205741555055e-05\n",
      "\n",
      "Optimizing LightGBM for fold 8 using min_max normalization\n",
      "Optimizing LightGBM hyperparameters with CV...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-20 04:35:50,816] Trial 0 finished with value: 0.7453541568482962 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.013661178428178952, 'n_estimators': 456, 'num_leaves': 48, 'max_depth': 6, 'subsample': 0.7552942184455931, 'colsample_bytree': 0.7030385741204636, 'reg_alpha': 1.3087232248047334, 'reg_lambda': 0.6869757398160233, 'min_child_samples': 49}. Best is trial 0 with value: 0.7453541568482962.\n",
      "[I 2025-03-20 04:35:50,944] Trial 1 finished with value: 0.7208806596404523 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.06323892443630524, 'n_estimators': 282, 'num_leaves': 42, 'max_depth': 3, 'subsample': 0.9077831487751247, 'colsample_bytree': 0.6012684467021177, 'reg_alpha': 0.31439409038438626, 'reg_lambda': 1.0912521853098582, 'min_child_samples': 47}. Best is trial 0 with value: 0.7453541568482962.\n",
      "[I 2025-03-20 04:35:51,206] Trial 2 finished with value: 0.7498669356426416 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.019957907467756848, 'n_estimators': 199, 'num_leaves': 37, 'max_depth': 10, 'subsample': 0.7873081624297713, 'colsample_bytree': 0.6493149518105418, 'reg_alpha': 3.6000609130029044, 'reg_lambda': 4.050134848257446, 'min_child_samples': 21}. Best is trial 2 with value: 0.7498669356426416.\n",
      "[I 2025-03-20 04:35:51,338] Trial 3 finished with value: 0.726858396671875 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.03308671790989007, 'n_estimators': 162, 'num_leaves': 10, 'max_depth': 5, 'subsample': 0.9963593754983149, 'colsample_bytree': 0.805256515122397, 'reg_alpha': 3.0841806167907238, 'reg_lambda': 0.1301677362213169, 'min_child_samples': 21}. Best is trial 2 with value: 0.7498669356426416.\n",
      "[I 2025-03-20 04:35:51,748] Trial 4 finished with value: 0.7680818150411975 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.029437387715603364, 'n_estimators': 405, 'num_leaves': 47, 'max_depth': 6, 'subsample': 0.9716350708762611, 'colsample_bytree': 0.7998448041733087, 'reg_alpha': 2.304933318498776, 'reg_lambda': 3.3362817514757888, 'min_child_samples': 29}. Best is trial 4 with value: 0.7680818150411975.\n",
      "[I 2025-03-20 04:35:51,877] Trial 5 finished with value: 0.7320217097121491 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.07045793365915588, 'n_estimators': 210, 'num_leaves': 23, 'max_depth': 3, 'subsample': 0.8092590874861125, 'colsample_bytree': 0.859403208540551, 'reg_alpha': 3.3760828530802196, 'reg_lambda': 0.15012918259918107, 'min_child_samples': 22}. Best is trial 4 with value: 0.7680818150411975.\n",
      "[I 2025-03-20 04:35:52,194] Trial 6 finished with value: 0.7266691759977191 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.011970252710206382, 'n_estimators': 476, 'num_leaves': 49, 'max_depth': 4, 'subsample': 0.9816084577717837, 'colsample_bytree': 0.7776193095921519, 'reg_alpha': 0.2802529145561249, 'reg_lambda': 1.3744727196612017, 'min_child_samples': 25}. Best is trial 4 with value: 0.7680818150411975.\n",
      "[I 2025-03-20 04:35:52,511] Trial 7 finished with value: 0.7857618793924219 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.0967088301559984, 'n_estimators': 367, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.6725825297010686, 'colsample_bytree': 0.7765487989776441, 'reg_alpha': 1.3901311581414446, 'reg_lambda': 1.2894120399825089, 'min_child_samples': 25}. Best is trial 7 with value: 0.7857618793924219.\n",
      "[I 2025-03-20 04:35:52,779] Trial 8 finished with value: 0.7659071121641039 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.04669085237595252, 'n_estimators': 388, 'num_leaves': 42, 'max_depth': 5, 'subsample': 0.6388242673991037, 'colsample_bytree': 0.9337670455562896, 'reg_alpha': 0.11037032003620384, 'reg_lambda': 0.25448376172072, 'min_child_samples': 45}. Best is trial 7 with value: 0.7857618793924219.\n",
      "[I 2025-03-20 04:35:52,910] Trial 9 finished with value: 0.710974368735978 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.011232085595448875, 'n_estimators': 177, 'num_leaves': 29, 'max_depth': 4, 'subsample': 0.7436406503252848, 'colsample_bytree': 0.6580654068535353, 'reg_alpha': 0.1699984374960256, 'reg_lambda': 0.1466016632681982, 'min_child_samples': 16}. Best is trial 7 with value: 0.7857618793924219.\n",
      "[I 2025-03-20 04:35:54,502] Trial 10 finished with value: 0.7827519921939936 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.0987558719383339, 'n_estimators': 337, 'num_leaves': 18, 'max_depth': 10, 'subsample': 0.642242017563948, 'colsample_bytree': 0.9614634142305828, 'reg_alpha': 0.7548915517607346, 'reg_lambda': 0.47191940414066896, 'min_child_samples': 37}. Best is trial 7 with value: 0.7857618793924219.\n",
      "[I 2025-03-20 04:35:56,836] Trial 11 finished with value: 0.7790367334294448 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.08811492902543544, 'n_estimators': 327, 'num_leaves': 17, 'max_depth': 10, 'subsample': 0.6019793854602531, 'colsample_bytree': 0.993860589036455, 'reg_alpha': 0.7915653922317443, 'reg_lambda': 0.4908802288038389, 'min_child_samples': 38}. Best is trial 7 with value: 0.7857618793924219.\n",
      "[I 2025-03-20 04:35:57,191] Trial 12 finished with value: 0.7792970763253102 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.09822003027572318, 'n_estimators': 307, 'num_leaves': 30, 'max_depth': 8, 'subsample': 0.6801173039155465, 'colsample_bytree': 0.893626879385864, 'reg_alpha': 0.8750718436454238, 'reg_lambda': 1.8653713281408886, 'min_child_samples': 37}. Best is trial 7 with value: 0.7857618793924219.\n",
      "[I 2025-03-20 04:35:57,669] Trial 13 finished with value: 0.7884526644848261 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.05345803972760133, 'n_estimators': 371, 'num_leaves': 19, 'max_depth': 8, 'subsample': 0.6866546830080261, 'colsample_bytree': 0.739487019699413, 'reg_alpha': 1.3765039473276297, 'reg_lambda': 0.36073977073087093, 'min_child_samples': 10}. Best is trial 13 with value: 0.7884526644848261.\n",
      "[I 2025-03-20 04:35:58,115] Trial 14 finished with value: 0.7907328977924897 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.0514136988240323, 'n_estimators': 399, 'num_leaves': 24, 'max_depth': 8, 'subsample': 0.7003547686087039, 'colsample_bytree': 0.7199502625390595, 'reg_alpha': 1.6169271278054258, 'reg_lambda': 0.26799625954839545, 'min_child_samples': 10}. Best is trial 14 with value: 0.7907328977924897.\n",
      "[I 2025-03-20 04:35:58,623] Trial 15 finished with value: 0.7925586601470531 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.043288657420412956, 'n_estimators': 428, 'num_leaves': 23, 'max_depth': 8, 'subsample': 0.7162209016787783, 'colsample_bytree': 0.717860014948173, 'reg_alpha': 1.7435571783177828, 'reg_lambda': 0.28040525124394855, 'min_child_samples': 13}. Best is trial 15 with value: 0.7925586601470531.\n",
      "[I 2025-03-20 04:35:58,908] Trial 16 finished with value: 0.7671787808888085 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.04109638618124266, 'n_estimators': 431, 'num_leaves': 25, 'max_depth': 8, 'subsample': 0.8460344390937014, 'colsample_bytree': 0.7060158413192544, 'reg_alpha': 4.9707495188682715, 'reg_lambda': 0.21780141322905835, 'min_child_samples': 10}. Best is trial 15 with value: 0.7925586601470531.\n",
      "[I 2025-03-20 04:35:59,676] Trial 17 finished with value: 0.7863845019070487 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.024514901988786787, 'n_estimators': 497, 'num_leaves': 35, 'max_depth': 7, 'subsample': 0.7296307043536723, 'colsample_bytree': 0.7264341586544525, 'reg_alpha': 1.9529401268872983, 'reg_lambda': 0.2595048901693072, 'min_child_samples': 15}. Best is trial 15 with value: 0.7925586601470531.\n",
      "[I 2025-03-20 04:35:59,934] Trial 18 finished with value: 0.7785764625528836 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.037144471324082946, 'n_estimators': 258, 'num_leaves': 12, 'max_depth': 9, 'subsample': 0.7137351539393999, 'colsample_bytree': 0.8468277336455567, 'reg_alpha': 0.45729733448074894, 'reg_lambda': 0.10867773802521877, 'min_child_samples': 15}. Best is trial 15 with value: 0.7925586601470531.\n",
      "[I 2025-03-20 04:36:00,522] Trial 19 finished with value: 0.7940902872750475 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.055146041120499804, 'n_estimators': 433, 'num_leaves': 25, 'max_depth': 7, 'subsample': 0.7941895058442429, 'colsample_bytree': 0.6718644712235572, 'reg_alpha': 0.4816921037070958, 'reg_lambda': 0.7118591133015433, 'min_child_samples': 17}. Best is trial 19 with value: 0.7940902872750475.\n",
      "[I 2025-03-20 04:36:00,703] Trial 20 finished with value: 0.7782402129703803 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.06841355883445985, 'n_estimators': 119, 'num_leaves': 35, 'max_depth': 7, 'subsample': 0.8562428892392476, 'colsample_bytree': 0.6540433629141039, 'reg_alpha': 0.4645863481645727, 'reg_lambda': 0.8357842924827359, 'min_child_samples': 17}. Best is trial 19 with value: 0.7940902872750475.\n",
      "[I 2025-03-20 04:36:01,380] Trial 21 finished with value: 0.8016179503816051 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.05146725416609422, 'n_estimators': 434, 'num_leaves': 24, 'max_depth': 9, 'subsample': 0.7782673129517497, 'colsample_bytree': 0.6865157079494899, 'reg_alpha': 0.47030520300856754, 'reg_lambda': 0.4013493756205192, 'min_child_samples': 12}. Best is trial 21 with value: 0.8016179503816051.\n",
      "[I 2025-03-20 04:36:02,088] Trial 22 finished with value: 0.7975322603773616 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.05734172211168016, 'n_estimators': 439, 'num_leaves': 28, 'max_depth': 9, 'subsample': 0.7845396551547295, 'colsample_bytree': 0.6100731451373813, 'reg_alpha': 0.494743958755481, 'reg_lambda': 0.5437420189122654, 'min_child_samples': 13}. Best is trial 21 with value: 0.8016179503816051.\n",
      "[I 2025-03-20 04:36:02,761] Trial 23 finished with value: 0.7950713970295784 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.05801951618776068, 'n_estimators': 451, 'num_leaves': 28, 'max_depth': 9, 'subsample': 0.8282268833081798, 'colsample_bytree': 0.6113656305071066, 'reg_alpha': 0.457258697678428, 'reg_lambda': 0.6514696069961735, 'min_child_samples': 19}. Best is trial 21 with value: 0.8016179503816051.\n",
      "[I 2025-03-20 04:36:03,411] Trial 24 finished with value: 0.7945052424041779 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.07709152582540008, 'n_estimators': 499, 'num_leaves': 28, 'max_depth': 9, 'subsample': 0.8504609308778457, 'colsample_bytree': 0.6054882595098037, 'reg_alpha': 0.2798175987792169, 'reg_lambda': 0.46860273035314454, 'min_child_samples': 20}. Best is trial 21 with value: 0.8016179503816051.\n",
      "[I 2025-03-20 04:36:04,092] Trial 25 finished with value: 0.7999163689971376 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.05956558541390768, 'n_estimators': 465, 'num_leaves': 32, 'max_depth': 9, 'subsample': 0.924368532259745, 'colsample_bytree': 0.6225105012919172, 'reg_alpha': 0.5686426653018474, 'reg_lambda': 0.5700725575412722, 'min_child_samples': 13}. Best is trial 21 with value: 0.8016179503816051.\n",
      "[I 2025-03-20 04:36:04,862] Trial 26 finished with value: 0.8034911089182734 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.02850815149388724, 'n_estimators': 466, 'num_leaves': 33, 'max_depth': 9, 'subsample': 0.9066303872175514, 'colsample_bytree': 0.6296457333415331, 'reg_alpha': 0.20533957510556644, 'reg_lambda': 0.367384306452101, 'min_child_samples': 13}. Best is trial 26 with value: 0.8034911089182734.\n",
      "[I 2025-03-20 04:36:05,386] Trial 27 finished with value: 0.7793364438229384 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.0177667762727948, 'n_estimators': 473, 'num_leaves': 33, 'max_depth': 9, 'subsample': 0.9184117009064229, 'colsample_bytree': 0.6433637388419149, 'reg_alpha': 0.19890570018563852, 'reg_lambda': 0.3653687670341498, 'min_child_samples': 32}. Best is trial 26 with value: 0.8034911089182734.\n",
      "[I 2025-03-20 04:36:05,855] Trial 28 finished with value: 0.7913822638441692 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.02431915261192662, 'n_estimators': 349, 'num_leaves': 40, 'max_depth': 9, 'subsample': 0.9160173025190899, 'colsample_bytree': 0.6830055207511323, 'reg_alpha': 0.10413499328271592, 'reg_lambda': 0.18306482534409932, 'min_child_samples': 25}. Best is trial 26 with value: 0.8034911089182734.\n",
      "[I 2025-03-20 04:36:06,375] Trial 29 finished with value: 0.7921260716575185 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.03117987255582556, 'n_estimators': 468, 'num_leaves': 33, 'max_depth': 6, 'subsample': 0.8872440314182884, 'colsample_bytree': 0.6362211597277405, 'reg_alpha': 0.19831217680921615, 'reg_lambda': 0.8868588432747507, 'min_child_samples': 12}. Best is trial 26 with value: 0.8034911089182734.\n",
      "[I 2025-03-20 04:36:06,896] Trial 30 finished with value: 0.7877349134521335 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.025900396055231294, 'n_estimators': 413, 'num_leaves': 39, 'max_depth': 10, 'subsample': 0.9531228763192888, 'colsample_bytree': 0.6759270227589871, 'reg_alpha': 1.0208028016225736, 'reg_lambda': 0.3331095880690521, 'min_child_samples': 29}. Best is trial 26 with value: 0.8034911089182734.\n",
      "[I 2025-03-20 04:36:07,680] Trial 31 finished with value: 0.8013700667673497 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.03779508995294448, 'n_estimators': 448, 'num_leaves': 32, 'max_depth': 9, 'subsample': 0.7735182246208606, 'colsample_bytree': 0.628357149397912, 'reg_alpha': 0.6143832119041995, 'reg_lambda': 0.5979214375064372, 'min_child_samples': 13}. Best is trial 26 with value: 0.8034911089182734.\n",
      "[I 2025-03-20 04:36:08,498] Trial 32 finished with value: 0.8029101084805909 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.03720590328434999, 'n_estimators': 468, 'num_leaves': 32, 'max_depth': 9, 'subsample': 0.7591902724909234, 'colsample_bytree': 0.6866036817769872, 'reg_alpha': 0.5770919045143261, 'reg_lambda': 0.6009510154935767, 'min_child_samples': 13}. Best is trial 26 with value: 0.8034911089182734.\n",
      "[I 2025-03-20 04:36:09,243] Trial 33 finished with value: 0.7996576400122121 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.035207774321456255, 'n_estimators': 500, 'num_leaves': 36, 'max_depth': 8, 'subsample': 0.7592117426478897, 'colsample_bytree': 0.6886789117485443, 'reg_alpha': 0.37370716920312713, 'reg_lambda': 0.41804047235907416, 'min_child_samples': 18}. Best is trial 26 with value: 0.8034911089182734.\n",
      "[I 2025-03-20 04:36:09,931] Trial 34 finished with value: 0.7919540967188501 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.018630192943076992, 'n_estimators': 381, 'num_leaves': 32, 'max_depth': 10, 'subsample': 0.7617336974689178, 'colsample_bytree': 0.7473491145497136, 'reg_alpha': 0.6558353079839443, 'reg_lambda': 0.8935711446513438, 'min_child_samples': 14}. Best is trial 26 with value: 0.8034911089182734.\n",
      "[I 2025-03-20 04:36:10,429] Trial 35 finished with value: 0.7862412700074953 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.028271791985759392, 'n_estimators': 416, 'num_leaves': 21, 'max_depth': 9, 'subsample': 0.880131109558902, 'colsample_bytree': 0.6392124406064695, 'reg_alpha': 0.34610400355563914, 'reg_lambda': 1.8328833111637195, 'min_child_samples': 22}. Best is trial 26 with value: 0.8034911089182734.\n",
      "[I 2025-03-20 04:36:11,123] Trial 36 finished with value: 0.8066563263527637 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.03691050535655741, 'n_estimators': 452, 'num_leaves': 38, 'max_depth': 7, 'subsample': 0.7751658238154441, 'colsample_bytree': 0.690995843366836, 'reg_alpha': 0.25005198500272385, 'reg_lambda': 0.6584038046087708, 'min_child_samples': 11}. Best is trial 36 with value: 0.8066563263527637.\n",
      "[I 2025-03-20 04:36:11,496] Trial 37 finished with value: 0.782947423758389 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.01619480329089237, 'n_estimators': 253, 'num_leaves': 39, 'max_depth': 7, 'subsample': 0.8058335050611841, 'colsample_bytree': 0.7643799886132949, 'reg_alpha': 0.1440505854257843, 'reg_lambda': 0.6955853404186726, 'min_child_samples': 11}. Best is trial 36 with value: 0.8066563263527637.\n",
      "[I 2025-03-20 04:36:11,992] Trial 38 finished with value: 0.7866382371007988 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.04456703047166929, 'n_estimators': 480, 'num_leaves': 46, 'max_depth': 6, 'subsample': 0.8270356094780089, 'colsample_bytree': 0.6965449556144093, 'reg_alpha': 0.2541003717527003, 'reg_lambda': 1.1509212196653056, 'min_child_samples': 19}. Best is trial 36 with value: 0.8066563263527637.\n",
      "[I 2025-03-20 04:36:12,351] Trial 39 finished with value: 0.7565975741341994 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.020541687548930217, 'n_estimators': 452, 'num_leaves': 46, 'max_depth': 5, 'subsample': 0.7448223905826693, 'colsample_bytree': 0.8183554456550612, 'reg_alpha': 0.23501197592474618, 'reg_lambda': 1.7267412970601683, 'min_child_samples': 23}. Best is trial 36 with value: 0.8066563263527637.\n",
      "[I 2025-03-20 04:36:12,788] Trial 40 finished with value: 0.7880736284767257 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.048873789068320725, 'n_estimators': 398, 'num_leaves': 44, 'max_depth': 8, 'subsample': 0.8196897052303502, 'colsample_bytree': 0.6653580055097164, 'reg_alpha': 0.36094325359316953, 'reg_lambda': 0.18888021518675868, 'min_child_samples': 32}. Best is trial 36 with value: 0.8066563263527637.\n",
      "[I 2025-03-20 04:36:13,524] Trial 41 finished with value: 0.8006621886089679 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.03857984255693903, 'n_estimators': 449, 'num_leaves': 31, 'max_depth': 9, 'subsample': 0.773388374012465, 'colsample_bytree': 0.6312490995529167, 'reg_alpha': 0.992844356999151, 'reg_lambda': 0.6179715374467909, 'min_child_samples': 15}. Best is trial 36 with value: 0.8066563263527637.\n",
      "[I 2025-03-20 04:36:14,535] Trial 42 finished with value: 0.8065118730927334 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.033137871032767705, 'n_estimators': 481, 'num_leaves': 37, 'max_depth': 10, 'subsample': 0.7787203014829364, 'colsample_bytree': 0.7017017720865915, 'reg_alpha': 0.13655505789553038, 'reg_lambda': 0.43023679828311917, 'min_child_samples': 11}. Best is trial 36 with value: 0.8066563263527637.\n",
      "[I 2025-03-20 04:36:15,458] Trial 43 finished with value: 0.8067707350096047 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.03203784098610669, 'n_estimators': 483, 'num_leaves': 37, 'max_depth': 10, 'subsample': 0.7347511805260317, 'colsample_bytree': 0.7029271125594092, 'reg_alpha': 0.13676339783839198, 'reg_lambda': 0.40674931326493186, 'min_child_samples': 12}. Best is trial 43 with value: 0.8067707350096047.\n",
      "[I 2025-03-20 04:36:16,488] Trial 44 finished with value: 0.8073506984003324 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.03355277961356783, 'n_estimators': 488, 'num_leaves': 37, 'max_depth': 10, 'subsample': 0.7306430421887818, 'colsample_bytree': 0.7559145543493914, 'reg_alpha': 0.12791481100146823, 'reg_lambda': 0.32810819295834215, 'min_child_samples': 10}. Best is trial 44 with value: 0.8073506984003324.\n",
      "[I 2025-03-20 04:36:17,596] Trial 45 finished with value: 0.8083812385613871 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.0319893174405536, 'n_estimators': 489, 'num_leaves': 42, 'max_depth': 10, 'subsample': 0.7335642112794829, 'colsample_bytree': 0.7597013782176442, 'reg_alpha': 0.13765836193788422, 'reg_lambda': 0.3260033748235826, 'min_child_samples': 10}. Best is trial 45 with value: 0.8083812385613871.\n",
      "[I 2025-03-20 04:36:18,689] Trial 46 finished with value: 0.8102284313225739 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.032726854374566475, 'n_estimators': 486, 'num_leaves': 42, 'max_depth': 10, 'subsample': 0.7312870570323871, 'colsample_bytree': 0.7982196486033886, 'reg_alpha': 0.12374388903281718, 'reg_lambda': 0.30156735102022697, 'min_child_samples': 10}. Best is trial 46 with value: 0.8102284313225739.\n",
      "[I 2025-03-20 04:36:19,167] Trial 47 finished with value: 0.7744227600689486 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.022615097919446547, 'n_estimators': 489, 'num_leaves': 42, 'max_depth': 10, 'subsample': 0.7277499908186869, 'colsample_bytree': 0.7995914132204904, 'reg_alpha': 0.13583617536387596, 'reg_lambda': 0.30695151112968483, 'min_child_samples': 46}. Best is trial 46 with value: 0.8102284313225739.\n",
      "[I 2025-03-20 04:36:19,635] Trial 48 finished with value: 0.7837467739154553 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.032314468882410415, 'n_estimators': 489, 'num_leaves': 44, 'max_depth': 10, 'subsample': 0.6527550668262337, 'colsample_bytree': 0.7610279123676795, 'reg_alpha': 0.15888577482337432, 'reg_lambda': 0.21466830256852762, 'min_child_samples': 49}. Best is trial 46 with value: 0.8102284313225739.\n",
      "[I 2025-03-20 04:36:20,524] Trial 49 finished with value: 0.8116601144967543 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.026947265581569554, 'n_estimators': 412, 'num_leaves': 41, 'max_depth': 10, 'subsample': 0.6960144623550353, 'colsample_bytree': 0.7900563958169663, 'reg_alpha': 0.1271686316051481, 'reg_lambda': 0.31506274442114524, 'min_child_samples': 10}. Best is trial 49 with value: 0.8116601144967543.\n",
      "[I 2025-03-20 04:36:20,721] A new study created in memory with name: no-name-f8ab5df1-2f01-4e2e-8ebc-039df88bf8f9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best LightGBM Parameters:\n",
      "  boosting_type: gbdt\n",
      "  learning_rate: 0.026947265581569554\n",
      "  n_estimators: 412\n",
      "  num_leaves: 41\n",
      "  max_depth: 10\n",
      "  subsample: 0.6960144623550353\n",
      "  colsample_bytree: 0.7900563958169663\n",
      "  reg_alpha: 0.1271686316051481\n",
      "  reg_lambda: 0.31506274442114524\n",
      "  min_child_samples: 10\n",
      "\n",
      "Optimizing LSTM for fold 8 using min_max normalization\n",
      "Created LSTM sequences with lookback=10: 1228 train, 145 test\n",
      "Optimizing LSTM hyperparameters with CV...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-20 04:36:54,411] Trial 0 finished with value: 0.5630502835398906 and parameters: {'hidden_dim': 45, 'dropout': 0.4551406810921512, 'learning_rate': 0.007331811314274292, 'batch_size': 16, 'weight_decay': 2.064121088592392e-05}. Best is trial 0 with value: 0.5630502835398906.\n",
      "[I 2025-03-20 04:37:13,405] Trial 1 finished with value: 0.5839463165094807 and parameters: {'hidden_dim': 79, 'dropout': 0.48569536770002286, 'learning_rate': 0.003999161563860724, 'batch_size': 32, 'weight_decay': 3.45872269711161e-05}. Best is trial 1 with value: 0.5839463165094807.\n",
      "[I 2025-03-20 04:37:47,171] Trial 2 finished with value: 0.6699389897244132 and parameters: {'hidden_dim': 32, 'dropout': 0.21712375681979076, 'learning_rate': 0.0016665895921660098, 'batch_size': 16, 'weight_decay': 2.1517123363927774e-05}. Best is trial 2 with value: 0.6699389897244132.\n",
      "[I 2025-03-20 04:38:02,824] Trial 3 finished with value: 0.6015731785963683 and parameters: {'hidden_dim': 127, 'dropout': 0.2873081624297713, 'learning_rate': 0.00017643094449433023, 'batch_size': 32, 'weight_decay': 1.0947309020486406e-05}. Best is trial 2 with value: 0.6699389897244132.\n",
      "[I 2025-03-20 04:38:36,492] Trial 4 finished with value: 0.6313309167767734 and parameters: {'hidden_dim': 47, 'dropout': 0.10585094112968818, 'learning_rate': 0.0004451295365396247, 'batch_size': 16, 'weight_decay': 1.3639281514957935e-06}. Best is trial 2 with value: 0.6699389897244132.\n",
      "[I 2025-03-20 04:38:48,050] Trial 5 finished with value: 0.6687782930686316 and parameters: {'hidden_dim': 59, 'dropout': 0.2875597071705984, 'learning_rate': 0.0033384615669657483, 'batch_size': 64, 'weight_decay': 9.98214837316597e-06}. Best is trial 2 with value: 0.6699389897244132.\n",
      "[I 2025-03-20 04:39:21,282] Trial 6 finished with value: 0.6341510557312778 and parameters: {'hidden_dim': 109, 'dropout': 0.4586320455614753, 'learning_rate': 0.0009209968619749436, 'batch_size': 16, 'weight_decay': 1.6223673683559225e-06}. Best is trial 2 with value: 0.6699389897244132.\n",
      "[I 2025-03-20 04:39:36,859] Trial 7 finished with value: 0.5616641048240923 and parameters: {'hidden_dim': 82, 'dropout': 0.3594032085405511, 'learning_rate': 0.006298297451196278, 'batch_size': 32, 'weight_decay': 7.511737052942637e-05}. Best is trial 2 with value: 0.6699389897244132.\n",
      "[I 2025-03-20 04:39:48,461] Trial 8 finished with value: 0.5805329510568346 and parameters: {'hidden_dim': 125, 'dropout': 0.17649687394806254, 'learning_rate': 0.00809174687672524, 'batch_size': 64, 'weight_decay': 5.656354626844694e-06}. Best is trial 2 with value: 0.6699389897244132.\n",
      "[I 2025-03-20 04:40:21,577] Trial 9 finished with value: 0.5050199980305604 and parameters: {'hidden_dim': 127, 'dropout': 0.3668293205677101, 'learning_rate': 0.009614679235250567, 'batch_size': 16, 'weight_decay': 2.2160868002868673e-05}. Best is trial 2 with value: 0.6699389897244132.\n",
      "[I 2025-03-20 04:40:55,353] Trial 10 finished with value: 0.6434146386263636 and parameters: {'hidden_dim': 32, 'dropout': 0.198627869896562, 'learning_rate': 0.0015689723478599755, 'batch_size': 16, 'weight_decay': 8.469738945067809e-05}. Best is trial 2 with value: 0.6699389897244132.\n",
      "[I 2025-03-20 04:41:03,806] Trial 11 finished with value: 0.6784201209022921 and parameters: {'hidden_dim': 64, 'dropout': 0.25668451047832225, 'learning_rate': 0.0020832659212191686, 'batch_size': 64, 'weight_decay': 4.899133576690419e-06}. Best is trial 11 with value: 0.6784201209022921.\n",
      "[I 2025-03-20 04:41:12,135] Trial 12 finished with value: 0.632182827706323 and parameters: {'hidden_dim': 72, 'dropout': 0.21598500798518633, 'learning_rate': 0.0015088018581849542, 'batch_size': 64, 'weight_decay': 3.460656555538206e-06}. Best is trial 11 with value: 0.6784201209022921.\n",
      "[I 2025-03-20 04:41:20,314] Trial 13 finished with value: 0.6060484705133193 and parameters: {'hidden_dim': 95, 'dropout': 0.24296708365322092, 'learning_rate': 0.0007285120693189867, 'batch_size': 64, 'weight_decay': 4.459010219894359e-06}. Best is trial 11 with value: 0.6784201209022921.\n",
      "[I 2025-03-20 04:41:31,798] Trial 14 finished with value: 0.6313519816598105 and parameters: {'hidden_dim': 33, 'dropout': 0.11485150758934834, 'learning_rate': 0.0017038860393305435, 'batch_size': 64, 'weight_decay': 1.2545792342299691e-05}. Best is trial 11 with value: 0.6784201209022921.\n",
      "[I 2025-03-20 04:42:05,571] Trial 15 finished with value: 0.587946008101323 and parameters: {'hidden_dim': 58, 'dropout': 0.3402754772779238, 'learning_rate': 0.0003539798922574453, 'batch_size': 16, 'weight_decay': 2.5886593912338396e-06}. Best is trial 11 with value: 0.6784201209022921.\n",
      "[I 2025-03-20 04:42:13,924] Trial 16 finished with value: 0.6184866305103384 and parameters: {'hidden_dim': 61, 'dropout': 0.26430609192606264, 'learning_rate': 0.0024684247055058992, 'batch_size': 64, 'weight_decay': 4.4383979493096764e-05}. Best is trial 11 with value: 0.6784201209022921.\n",
      "[I 2025-03-20 04:42:47,842] Trial 17 finished with value: 0.6106475307274636 and parameters: {'hidden_dim': 90, 'dropout': 0.1572378497520306, 'learning_rate': 0.00010728531826263386, 'batch_size': 16, 'weight_decay': 5.847918834978513e-06}. Best is trial 11 with value: 0.6784201209022921.\n",
      "[I 2025-03-20 04:42:56,183] Trial 18 finished with value: 0.5919544664390067 and parameters: {'hidden_dim': 43, 'dropout': 0.32294830382545214, 'learning_rate': 0.0006275250989672774, 'batch_size': 64, 'weight_decay': 1.7445159426190412e-05}. Best is trial 11 with value: 0.6784201209022921.\n",
      "[I 2025-03-20 04:43:15,209] Trial 19 finished with value: 0.6289874574278557 and parameters: {'hidden_dim': 70, 'dropout': 0.3982201913987795, 'learning_rate': 0.0025483949776746854, 'batch_size': 32, 'weight_decay': 7.823169758168759e-06}. Best is trial 11 with value: 0.6784201209022921.\n",
      "[I 2025-03-20 04:43:23,599] Trial 20 finished with value: 0.6331200389647055 and parameters: {'hidden_dim': 52, 'dropout': 0.23524611020501152, 'learning_rate': 0.004681922702699792, 'batch_size': 64, 'weight_decay': 3.3438390648003014e-05}. Best is trial 11 with value: 0.6784201209022921.\n",
      "[I 2025-03-20 04:43:31,994] Trial 21 finished with value: 0.5828385016023924 and parameters: {'hidden_dim': 64, 'dropout': 0.2980875063506988, 'learning_rate': 0.003188336393947412, 'batch_size': 64, 'weight_decay': 1.0468189634633399e-05}. Best is trial 11 with value: 0.6784201209022921.\n",
      "[I 2025-03-20 04:43:43,535] Trial 22 finished with value: 0.6398258064703968 and parameters: {'hidden_dim': 38, 'dropout': 0.2653690741445928, 'learning_rate': 0.00132963949040977, 'batch_size': 64, 'weight_decay': 2.648810081202726e-06}. Best is trial 11 with value: 0.6784201209022921.\n",
      "[I 2025-03-20 04:43:51,955] Trial 23 finished with value: 0.6241959742384071 and parameters: {'hidden_dim': 52, 'dropout': 0.16752463312930127, 'learning_rate': 0.0023769399368068736, 'batch_size': 64, 'weight_decay': 6.985098954622796e-06}. Best is trial 11 with value: 0.6784201209022921.\n",
      "[I 2025-03-20 04:44:00,250] Trial 24 finished with value: 0.6215716506257131 and parameters: {'hidden_dim': 70, 'dropout': 0.27013767407553946, 'learning_rate': 0.004566638771153086, 'batch_size': 64, 'weight_decay': 1.3986612110065837e-05}. Best is trial 11 with value: 0.6784201209022921.\n",
      "[I 2025-03-20 04:44:33,921] Trial 25 finished with value: 0.6250406336662109 and parameters: {'hidden_dim': 55, 'dropout': 0.31220979238894414, 'learning_rate': 0.0011582501251596786, 'batch_size': 16, 'weight_decay': 2.8846452399741964e-05}. Best is trial 11 with value: 0.6784201209022921.\n",
      "[I 2025-03-20 04:44:42,230] Trial 26 finished with value: 0.6558792793318531 and parameters: {'hidden_dim': 82, 'dropout': 0.20432547106566096, 'learning_rate': 0.002097495860861346, 'batch_size': 64, 'weight_decay': 9.481380342815729e-06}. Best is trial 11 with value: 0.6784201209022921.\n",
      "[I 2025-03-20 04:44:53,857] Trial 27 finished with value: 0.5982311190953343 and parameters: {'hidden_dim': 65, 'dropout': 0.23653244882934293, 'learning_rate': 0.0034273819685187255, 'batch_size': 64, 'weight_decay': 5.1180842411010416e-05}. Best is trial 11 with value: 0.6784201209022921.\n",
      "[I 2025-03-20 04:45:09,439] Trial 28 finished with value: 0.5423031208019474 and parameters: {'hidden_dim': 102, 'dropout': 0.3999814679239561, 'learning_rate': 0.005727254011682953, 'batch_size': 32, 'weight_decay': 3.777623350600246e-06}. Best is trial 11 with value: 0.6784201209022921.\n",
      "[I 2025-03-20 04:45:43,119] Trial 29 finished with value: 0.651256481417343 and parameters: {'hidden_dim': 47, 'dropout': 0.13734095983271558, 'learning_rate': 0.0010028583557230189, 'batch_size': 16, 'weight_decay': 1.9296711100531923e-05}. Best is trial 11 with value: 0.6784201209022921.\n",
      "[I 2025-03-20 04:46:16,644] Trial 30 finished with value: 0.6468547006822146 and parameters: {'hidden_dim': 41, 'dropout': 0.19108762942054577, 'learning_rate': 0.0019757881151980334, 'batch_size': 16, 'weight_decay': 1.0353633098111883e-06}. Best is trial 11 with value: 0.6784201209022921.\n",
      "[I 2025-03-20 04:46:28,068] Trial 31 finished with value: 0.6484593158917409 and parameters: {'hidden_dim': 87, 'dropout': 0.21304452823225842, 'learning_rate': 0.0020558929841084897, 'batch_size': 64, 'weight_decay': 7.844887758823711e-06}. Best is trial 11 with value: 0.6784201209022921.\n",
      "[I 2025-03-20 04:46:36,392] Trial 32 finished with value: 0.6449592105903733 and parameters: {'hidden_dim': 81, 'dropout': 0.24722854476940734, 'learning_rate': 0.003061024247907061, 'batch_size': 64, 'weight_decay': 1.5616586570717427e-05}. Best is trial 11 with value: 0.6784201209022921.\n",
      "[I 2025-03-20 04:46:44,720] Trial 33 finished with value: 0.5882989357124826 and parameters: {'hidden_dim': 76, 'dropout': 0.21742274679978704, 'learning_rate': 0.0040833115212624855, 'batch_size': 64, 'weight_decay': 9.672092233697107e-06}. Best is trial 11 with value: 0.6784201209022921.\n",
      "[I 2025-03-20 04:46:52,939] Trial 34 finished with value: 0.5957280703131926 and parameters: {'hidden_dim': 75, 'dropout': 0.28110650756383465, 'learning_rate': 0.0007866670669695684, 'batch_size': 64, 'weight_decay': 2.3030395985968945e-05}. Best is trial 11 with value: 0.6784201209022921.\n",
      "[I 2025-03-20 04:47:11,745] Trial 35 finished with value: 0.628308997895814 and parameters: {'hidden_dim': 97, 'dropout': 0.1520450112264312, 'learning_rate': 0.0012904067125210424, 'batch_size': 32, 'weight_decay': 5.0983525622335785e-06}. Best is trial 11 with value: 0.6784201209022921.\n",
      "[I 2025-03-20 04:47:19,933] Trial 36 finished with value: 0.6319582978912941 and parameters: {'hidden_dim': 85, 'dropout': 0.2939631939091616, 'learning_rate': 0.0029255864813841114, 'batch_size': 64, 'weight_decay': 9.622741278513246e-06}. Best is trial 11 with value: 0.6784201209022921.\n",
      "[I 2025-03-20 04:47:53,475] Trial 37 finished with value: 0.6273989525535298 and parameters: {'hidden_dim': 112, 'dropout': 0.18464347508755297, 'learning_rate': 0.0004091684231926461, 'batch_size': 16, 'weight_decay': 2.1075777667799873e-06}. Best is trial 11 with value: 0.6784201209022921.\n",
      "[I 2025-03-20 04:48:12,277] Trial 38 finished with value: 0.6049412465003918 and parameters: {'hidden_dim': 66, 'dropout': 0.2544058461085721, 'learning_rate': 0.0056613177464866086, 'batch_size': 32, 'weight_decay': 1.256523349000352e-05}. Best is trial 11 with value: 0.6784201209022921.\n",
      "[I 2025-03-20 04:48:20,593] Trial 39 finished with value: 0.6527291863516653 and parameters: {'hidden_dim': 51, 'dropout': 0.32904790308583565, 'learning_rate': 0.001954049941303959, 'batch_size': 64, 'weight_decay': 6.522170853183143e-06}. Best is trial 11 with value: 0.6784201209022921.\n",
      "[I 2025-03-20 04:48:53,923] Trial 40 finished with value: 0.5776394582212474 and parameters: {'hidden_dim': 46, 'dropout': 0.20978860194028398, 'learning_rate': 0.007186323415869851, 'batch_size': 16, 'weight_decay': 2.6484189090236794e-05}. Best is trial 11 with value: 0.6784201209022921.\n",
      "[I 2025-03-20 04:49:02,399] Trial 41 finished with value: 0.6550958714263547 and parameters: {'hidden_dim': 37, 'dropout': 0.3530190803751338, 'learning_rate': 0.0019212867428647766, 'batch_size': 64, 'weight_decay': 5.923163469432942e-06}. Best is trial 11 with value: 0.6784201209022921.\n",
      "[I 2025-03-20 04:49:14,097] Trial 42 finished with value: 0.6348420732787284 and parameters: {'hidden_dim': 35, 'dropout': 0.37351202941832495, 'learning_rate': 0.0016442302488187946, 'batch_size': 64, 'weight_decay': 3.8061870058562388e-06}. Best is trial 11 with value: 0.6784201209022921.\n",
      "[I 2025-03-20 04:49:22,551] Trial 43 finished with value: 0.6189614862847754 and parameters: {'hidden_dim': 38, 'dropout': 0.35210003285153624, 'learning_rate': 0.0010264241185937342, 'batch_size': 64, 'weight_decay': 8.201392482360044e-06}. Best is trial 11 with value: 0.6784201209022921.\n",
      "[I 2025-03-20 04:49:30,996] Trial 44 finished with value: 0.6525047445721915 and parameters: {'hidden_dim': 59, 'dropout': 0.4759608459617735, 'learning_rate': 0.0022393545106306565, 'batch_size': 64, 'weight_decay': 5.082533927712535e-06}. Best is trial 11 with value: 0.6784201209022921.\n",
      "[I 2025-03-20 04:49:39,411] Trial 45 finished with value: 0.6290980978414709 and parameters: {'hidden_dim': 41, 'dropout': 0.4122177838123044, 'learning_rate': 0.003971851624406997, 'batch_size': 64, 'weight_decay': 2.78083183122535e-06}. Best is trial 11 with value: 0.6784201209022921.\n",
      "[I 2025-03-20 04:49:50,891] Trial 46 finished with value: 0.6134276129331396 and parameters: {'hidden_dim': 77, 'dropout': 0.4372620447394197, 'learning_rate': 0.0016934428358521853, 'batch_size': 64, 'weight_decay': 1.186625310716546e-05}. Best is trial 11 with value: 0.6784201209022921.\n",
      "[I 2025-03-20 04:50:24,543] Trial 47 finished with value: 0.6269570108978438 and parameters: {'hidden_dim': 36, 'dropout': 0.3126524222867965, 'learning_rate': 0.002757183419364651, 'batch_size': 16, 'weight_decay': 4.6937351401433e-06}. Best is trial 11 with value: 0.6784201209022921.\n",
      "[I 2025-03-20 04:50:32,902] Trial 48 finished with value: 0.6144902084428179 and parameters: {'hidden_dim': 32, 'dropout': 0.22625924840238293, 'learning_rate': 0.000816455159589192, 'batch_size': 64, 'weight_decay': 1.6255324398012737e-05}. Best is trial 11 with value: 0.6784201209022921.\n",
      "[I 2025-03-20 04:50:51,972] Trial 49 finished with value: 0.6016609155724004 and parameters: {'hidden_dim': 49, 'dropout': 0.2796187254000811, 'learning_rate': 0.0005575590481033422, 'batch_size': 32, 'weight_decay': 6.543940786738066e-06}. Best is trial 11 with value: 0.6784201209022921.\n",
      "[I 2025-03-20 04:51:25,605] Trial 50 finished with value: 0.6729236548824707 and parameters: {'hidden_dim': 56, 'dropout': 0.374736777367904, 'learning_rate': 0.0015052531951248495, 'batch_size': 16, 'weight_decay': 3.250826200817201e-06}. Best is trial 11 with value: 0.6784201209022921.\n",
      "[I 2025-03-20 04:51:25,614] A new study created in memory with name: no-name-d2f94f59-6e31-4556-8f1d-5c9abdf74951\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best LSTM Parameters:\n",
      "  hidden_dim: 64\n",
      "  dropout: 0.25668451047832225\n",
      "  learning_rate: 0.0020832659212191686\n",
      "  batch_size: 64\n",
      "  weight_decay: 4.899133576690419e-06\n",
      "\n",
      "Optimizing LightGBM for fold 9 using min_max normalization\n",
      "Optimizing LightGBM hyperparameters with CV...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-20 04:51:26,023] Trial 0 finished with value: 0.709430755091097 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.013661178428178952, 'n_estimators': 456, 'num_leaves': 48, 'max_depth': 6, 'subsample': 0.7552942184455931, 'colsample_bytree': 0.7030385741204636, 'reg_alpha': 1.3087232248047334, 'reg_lambda': 0.6869757398160233, 'min_child_samples': 49}. Best is trial 0 with value: 0.709430755091097.\n",
      "[I 2025-03-20 04:51:26,159] Trial 1 finished with value: 0.6892365650052783 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.06323892443630524, 'n_estimators': 282, 'num_leaves': 42, 'max_depth': 3, 'subsample': 0.9077831487751247, 'colsample_bytree': 0.6012684467021177, 'reg_alpha': 0.31439409038438626, 'reg_lambda': 1.0912521853098582, 'min_child_samples': 47}. Best is trial 0 with value: 0.709430755091097.\n",
      "[I 2025-03-20 04:51:26,460] Trial 2 finished with value: 0.7076291009442716 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.019957907467756848, 'n_estimators': 199, 'num_leaves': 37, 'max_depth': 10, 'subsample': 0.7873081624297713, 'colsample_bytree': 0.6493149518105418, 'reg_alpha': 3.6000609130029044, 'reg_lambda': 4.050134848257446, 'min_child_samples': 21}. Best is trial 0 with value: 0.709430755091097.\n",
      "[I 2025-03-20 04:51:26,594] Trial 3 finished with value: 0.7014674406631052 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.03308671790989007, 'n_estimators': 162, 'num_leaves': 10, 'max_depth': 5, 'subsample': 0.9963593754983149, 'colsample_bytree': 0.805256515122397, 'reg_alpha': 3.0841806167907238, 'reg_lambda': 0.1301677362213169, 'min_child_samples': 21}. Best is trial 0 with value: 0.709430755091097.\n",
      "[I 2025-03-20 04:51:27,031] Trial 4 finished with value: 0.7337697137287804 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.029437387715603364, 'n_estimators': 405, 'num_leaves': 47, 'max_depth': 6, 'subsample': 0.9716350708762611, 'colsample_bytree': 0.7998448041733087, 'reg_alpha': 2.304933318498776, 'reg_lambda': 3.3362817514757888, 'min_child_samples': 29}. Best is trial 4 with value: 0.7337697137287804.\n",
      "[I 2025-03-20 04:51:27,164] Trial 5 finished with value: 0.6941890982056633 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.07045793365915588, 'n_estimators': 210, 'num_leaves': 23, 'max_depth': 3, 'subsample': 0.8092590874861125, 'colsample_bytree': 0.859403208540551, 'reg_alpha': 3.3760828530802196, 'reg_lambda': 0.15012918259918107, 'min_child_samples': 22}. Best is trial 4 with value: 0.7337697137287804.\n",
      "[I 2025-03-20 04:51:27,464] Trial 6 finished with value: 0.6987215429511247 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.011970252710206382, 'n_estimators': 476, 'num_leaves': 49, 'max_depth': 4, 'subsample': 0.9816084577717837, 'colsample_bytree': 0.7776193095921519, 'reg_alpha': 0.2802529145561249, 'reg_lambda': 1.3744727196612017, 'min_child_samples': 25}. Best is trial 4 with value: 0.7337697137287804.\n",
      "[I 2025-03-20 04:51:27,865] Trial 7 finished with value: 0.7588840928963205 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.0967088301559984, 'n_estimators': 367, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.6725825297010686, 'colsample_bytree': 0.7765487989776441, 'reg_alpha': 1.3901311581414446, 'reg_lambda': 1.2894120399825089, 'min_child_samples': 25}. Best is trial 7 with value: 0.7588840928963205.\n",
      "[I 2025-03-20 04:51:28,156] Trial 8 finished with value: 0.7366134379062863 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.04669085237595252, 'n_estimators': 388, 'num_leaves': 42, 'max_depth': 5, 'subsample': 0.6388242673991037, 'colsample_bytree': 0.9337670455562896, 'reg_alpha': 0.11037032003620384, 'reg_lambda': 0.25448376172072, 'min_child_samples': 45}. Best is trial 7 with value: 0.7588840928963205.\n",
      "[I 2025-03-20 04:51:28,292] Trial 9 finished with value: 0.6963043657467972 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.011232085595448875, 'n_estimators': 177, 'num_leaves': 29, 'max_depth': 4, 'subsample': 0.7436406503252848, 'colsample_bytree': 0.6580654068535353, 'reg_alpha': 0.1699984374960256, 'reg_lambda': 0.1466016632681982, 'min_child_samples': 16}. Best is trial 7 with value: 0.7588840928963205.\n",
      "[I 2025-03-20 04:51:28,722] Trial 10 finished with value: 0.7669492632273913 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.0987558719383339, 'n_estimators': 337, 'num_leaves': 18, 'max_depth': 10, 'subsample': 0.642242017563948, 'colsample_bytree': 0.9614634142305828, 'reg_alpha': 0.7548915517607346, 'reg_lambda': 0.47191940414066896, 'min_child_samples': 37}. Best is trial 10 with value: 0.7669492632273913.\n",
      "[I 2025-03-20 04:51:29,133] Trial 11 finished with value: 0.7591431291172606 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.08811492902543544, 'n_estimators': 327, 'num_leaves': 17, 'max_depth': 10, 'subsample': 0.6019793854602531, 'colsample_bytree': 0.993860589036455, 'reg_alpha': 0.7915653922317443, 'reg_lambda': 0.4908802288038389, 'min_child_samples': 38}. Best is trial 10 with value: 0.7669492632273913.\n",
      "[I 2025-03-20 04:51:29,494] Trial 12 finished with value: 0.7636775914106415 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.09904613833204629, 'n_estimators': 306, 'num_leaves': 16, 'max_depth': 8, 'subsample': 0.6033581704047635, 'colsample_bytree': 0.9993937583859511, 'reg_alpha': 0.6543087303621062, 'reg_lambda': 0.4491527874295132, 'min_child_samples': 37}. Best is trial 10 with value: 0.7669492632273913.\n",
      "[I 2025-03-20 04:51:29,827] Trial 13 finished with value: 0.7596995516641869 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.05330893872203613, 'n_estimators': 272, 'num_leaves': 17, 'max_depth': 8, 'subsample': 0.6883516020297582, 'colsample_bytree': 0.9903471057198379, 'reg_alpha': 0.545247645863888, 'reg_lambda': 0.35862632111634024, 'min_child_samples': 36}. Best is trial 10 with value: 0.7669492632273913.\n",
      "[I 2025-03-20 04:51:29,946] Trial 14 finished with value: 0.7250293456727837 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.09902754547617337, 'n_estimators': 106, 'num_leaves': 10, 'max_depth': 8, 'subsample': 0.6019856427436097, 'colsample_bytree': 0.9060493430682394, 'reg_alpha': 0.5882107951041878, 'reg_lambda': 0.2856720849649229, 'min_child_samples': 35}. Best is trial 10 with value: 0.7669492632273913.\n",
      "[I 2025-03-20 04:51:30,327] Trial 15 finished with value: 0.7498222532746613 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.041200994336669815, 'n_estimators': 327, 'num_leaves': 22, 'max_depth': 8, 'subsample': 0.6938019068592701, 'colsample_bytree': 0.9374845040223587, 'reg_alpha': 1.0376247533690395, 'reg_lambda': 0.5809021707795811, 'min_child_samples': 41}. Best is trial 10 with value: 0.7669492632273913.\n",
      "[I 2025-03-20 04:51:30,710] Trial 16 finished with value: 0.7656114642323997 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.06743210976592647, 'n_estimators': 256, 'num_leaves': 29, 'max_depth': 9, 'subsample': 0.8557024840122305, 'colsample_bytree': 0.8687091705040944, 'reg_alpha': 0.32864171604260717, 'reg_lambda': 0.9605461309779892, 'min_child_samples': 32}. Best is trial 10 with value: 0.7669492632273913.\n",
      "[I 2025-03-20 04:51:31,060] Trial 17 finished with value: 0.7681780475686981 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.06715548817290806, 'n_estimators': 249, 'num_leaves': 30, 'max_depth': 9, 'subsample': 0.8800068968445085, 'colsample_bytree': 0.8663473552356292, 'reg_alpha': 0.3728840141886645, 'reg_lambda': 1.9816484674594073, 'min_child_samples': 32}. Best is trial 17 with value: 0.7681780475686981.\n",
      "[I 2025-03-20 04:51:31,348] Trial 18 finished with value: 0.7567763222030989 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.0741819897306124, 'n_estimators': 241, 'num_leaves': 35, 'max_depth': 9, 'subsample': 0.8918850975867088, 'colsample_bytree': 0.8425740823442552, 'reg_alpha': 0.4453087627434717, 'reg_lambda': 2.0700082233542947, 'min_child_samples': 42}. Best is trial 17 with value: 0.7681780475686981.\n",
      "[I 2025-03-20 04:51:32,049] Trial 19 finished with value: 0.7779488938812053 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.024323369819210055, 'n_estimators': 431, 'num_leaves': 23, 'max_depth': 9, 'subsample': 0.8485871963258085, 'colsample_bytree': 0.9099801935870323, 'reg_alpha': 0.18660755150531425, 'reg_lambda': 2.1312192026778476, 'min_child_samples': 12}. Best is trial 19 with value: 0.7779488938812053.\n",
      "[I 2025-03-20 04:51:32,670] Trial 20 finished with value: 0.7706444531948379 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.019681331344982907, 'n_estimators': 441, 'num_leaves': 25, 'max_depth': 7, 'subsample': 0.8459882178374232, 'colsample_bytree': 0.8970207889031838, 'reg_alpha': 0.182704562550891, 'reg_lambda': 2.4224822691368924, 'min_child_samples': 12}. Best is trial 19 with value: 0.7779488938812053.\n",
      "[I 2025-03-20 04:51:33,316] Trial 21 finished with value: 0.7735126640560985 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.020243049615205393, 'n_estimators': 446, 'num_leaves': 25, 'max_depth': 7, 'subsample': 0.8567021503215939, 'colsample_bytree': 0.8923566664933249, 'reg_alpha': 0.19496700020605012, 'reg_lambda': 2.328568773789191, 'min_child_samples': 11}. Best is trial 19 with value: 0.7779488938812053.\n",
      "[I 2025-03-20 04:51:33,938] Trial 22 finished with value: 0.771407438686692 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.019082422752978147, 'n_estimators': 439, 'num_leaves': 24, 'max_depth': 7, 'subsample': 0.8413825793093584, 'colsample_bytree': 0.9154859839685122, 'reg_alpha': 0.1908713982983036, 'reg_lambda': 2.2981171757312486, 'min_child_samples': 11}. Best is trial 19 with value: 0.7779488938812053.\n",
      "[I 2025-03-20 04:51:34,688] Trial 23 finished with value: 0.7643419332603542 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.019777669681433786, 'n_estimators': 493, 'num_leaves': 26, 'max_depth': 7, 'subsample': 0.9359602346271472, 'colsample_bytree': 0.9066710703846703, 'reg_alpha': 0.10476429487387189, 'reg_lambda': 4.920578102508583, 'min_child_samples': 10}. Best is trial 19 with value: 0.7779488938812053.\n",
      "[I 2025-03-20 04:51:35,369] Trial 24 finished with value: 0.7728795555172903 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.026209155883256195, 'n_estimators': 431, 'num_leaves': 34, 'max_depth': 7, 'subsample': 0.8237667186819242, 'colsample_bytree': 0.9484705821497487, 'reg_alpha': 0.19114311600892447, 'reg_lambda': 2.760070359100948, 'min_child_samples': 15}. Best is trial 19 with value: 0.7779488938812053.\n",
      "[I 2025-03-20 04:51:35,880] Trial 25 finished with value: 0.7580618801953429 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.030016220267750415, 'n_estimators': 411, 'num_leaves': 33, 'max_depth': 6, 'subsample': 0.8064316198890865, 'colsample_bytree': 0.9558443648684933, 'reg_alpha': 0.22351524545390877, 'reg_lambda': 3.2113875071946216, 'min_child_samples': 15}. Best is trial 19 with value: 0.7779488938812053.\n",
      "[I 2025-03-20 04:51:36,458] Trial 26 finished with value: 0.7682168584311109 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.02546513026340495, 'n_estimators': 423, 'num_leaves': 39, 'max_depth': 7, 'subsample': 0.7589038201932554, 'colsample_bytree': 0.8255707176448154, 'reg_alpha': 0.14238886678516227, 'reg_lambda': 2.9789355604831824, 'min_child_samples': 16}. Best is trial 19 with value: 0.7779488938812053.\n",
      "[I 2025-03-20 04:51:37,184] Trial 27 finished with value: 0.7677817124140714 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.015417960530175382, 'n_estimators': 368, 'num_leaves': 33, 'max_depth': 9, 'subsample': 0.9194182869334776, 'colsample_bytree': 0.8869068333780097, 'reg_alpha': 0.237762629995904, 'reg_lambda': 1.5874102772597172, 'min_child_samples': 14}. Best is trial 19 with value: 0.7779488938812053.\n",
      "[I 2025-03-20 04:51:37,608] Trial 28 finished with value: 0.7534738149121238 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.02542421108892843, 'n_estimators': 497, 'num_leaves': 28, 'max_depth': 5, 'subsample': 0.9455006471236871, 'colsample_bytree': 0.9634555068700721, 'reg_alpha': 0.13778857298231614, 'reg_lambda': 0.9745135910664157, 'min_child_samples': 19}. Best is trial 19 with value: 0.7779488938812053.\n",
      "[I 2025-03-20 04:51:38,057] Trial 29 finished with value: 0.7488722050209932 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.014462858197225566, 'n_estimators': 467, 'num_leaves': 19, 'max_depth': 6, 'subsample': 0.7775149065426555, 'colsample_bytree': 0.7404538228700832, 'reg_alpha': 0.13924812931797464, 'reg_lambda': 0.8284801564508117, 'min_child_samples': 18}. Best is trial 19 with value: 0.7779488938812053.\n",
      "[I 2025-03-20 04:51:38,745] Trial 30 finished with value: 0.769683417514184 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.024248458984397016, 'n_estimators': 458, 'num_leaves': 21, 'max_depth': 8, 'subsample': 0.8289185581921412, 'colsample_bytree': 0.9326226979803302, 'reg_alpha': 0.43217436593604636, 'reg_lambda': 1.6757956334544808, 'min_child_samples': 13}. Best is trial 19 with value: 0.7779488938812053.\n",
      "[I 2025-03-20 04:51:39,384] Trial 31 finished with value: 0.7681069860486209 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.01686915520494336, 'n_estimators': 428, 'num_leaves': 24, 'max_depth': 7, 'subsample': 0.8621170373931505, 'colsample_bytree': 0.9094126625946186, 'reg_alpha': 0.22816539172446962, 'reg_lambda': 2.580071246365887, 'min_child_samples': 10}. Best is trial 19 with value: 0.7779488938812053.\n",
      "[I 2025-03-20 04:51:39,833] Trial 32 finished with value: 0.7431641057302933 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.022281912823687564, 'n_estimators': 384, 'num_leaves': 14, 'max_depth': 7, 'subsample': 0.8376567577337141, 'colsample_bytree': 0.9272697099945159, 'reg_alpha': 0.18366586210331862, 'reg_lambda': 4.9775718036367085, 'min_child_samples': 10}. Best is trial 19 with value: 0.7779488938812053.\n",
      "[I 2025-03-20 04:51:40,443] Trial 33 finished with value: 0.7702477300747574 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.0342938641117479, 'n_estimators': 445, 'num_leaves': 32, 'max_depth': 6, 'subsample': 0.8857818990309694, 'colsample_bytree': 0.8802778462300657, 'reg_alpha': 0.27445622511545964, 'reg_lambda': 2.1205303596710636, 'min_child_samples': 12}. Best is trial 19 with value: 0.7779488938812053.\n",
      "[I 2025-03-20 04:51:41,060] Trial 34 finished with value: 0.7550691726947971 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.01743619173898589, 'n_estimators': 475, 'num_leaves': 26, 'max_depth': 7, 'subsample': 0.8253122236579854, 'colsample_bytree': 0.8357132646540617, 'reg_alpha': 0.19225429785135234, 'reg_lambda': 3.6621714387254083, 'min_child_samples': 18}. Best is trial 19 with value: 0.7779488938812053.\n",
      "[I 2025-03-20 04:51:41,442] Trial 35 finished with value: 0.7483710014904293 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.022193047915380612, 'n_estimators': 397, 'num_leaves': 20, 'max_depth': 5, 'subsample': 0.7767630769315621, 'colsample_bytree': 0.9751911566598552, 'reg_alpha': 0.12620515251023895, 'reg_lambda': 2.5806258576776235, 'min_child_samples': 14}. Best is trial 19 with value: 0.7779488938812053.\n",
      "[I 2025-03-20 04:51:41,943] Trial 36 finished with value: 0.7671928804405802 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.03691050535655741, 'n_estimators': 360, 'num_leaves': 27, 'max_depth': 8, 'subsample': 0.7342773520548617, 'colsample_bytree': 0.948900290350643, 'reg_alpha': 0.3160154072706494, 'reg_lambda': 1.1960211247530903, 'min_child_samples': 24}. Best is trial 19 with value: 0.7779488938812053.\n",
      "[I 2025-03-20 04:51:42,521] Trial 37 finished with value: 0.746553408928529 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.027159998190224407, 'n_estimators': 435, 'num_leaves': 38, 'max_depth': 6, 'subsample': 0.8104951459000177, 'colsample_bytree': 0.9129570667181108, 'reg_alpha': 2.0061190721556637, 'reg_lambda': 4.000399025770869, 'min_child_samples': 19}. Best is trial 19 with value: 0.7779488938812053.\n",
      "[I 2025-03-20 04:51:43,273] Trial 38 finished with value: 0.7682954557116914 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.012323504117578484, 'n_estimators': 415, 'num_leaves': 31, 'max_depth': 9, 'subsample': 0.8698548082639179, 'colsample_bytree': 0.8482998876331302, 'reg_alpha': 0.16074291239263971, 'reg_lambda': 1.715579882204438, 'min_child_samples': 12}. Best is trial 19 with value: 0.7779488938812053.\n",
      "[I 2025-03-20 04:51:43,729] Trial 39 finished with value: 0.7464102123275947 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.018339983175581036, 'n_estimators': 457, 'num_leaves': 46, 'max_depth': 6, 'subsample': 0.9028022594569031, 'colsample_bytree': 0.60951827827375, 'reg_alpha': 0.2623251942114349, 'reg_lambda': 1.4202018523399722, 'min_child_samples': 21}. Best is trial 19 with value: 0.7779488938812053.\n",
      "[I 2025-03-20 04:51:44,041] Trial 40 finished with value: 0.7379073723960439 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.02200262677251764, 'n_estimators': 483, 'num_leaves': 35, 'max_depth': 4, 'subsample': 0.7859060139453391, 'colsample_bytree': 0.8098712851870157, 'reg_alpha': 0.2058653065749943, 'reg_lambda': 0.7348821593349745, 'min_child_samples': 17}. Best is trial 19 with value: 0.7779488938812053.\n",
      "[I 2025-03-20 04:51:44,672] Trial 41 finished with value: 0.7739800815098231 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.02019635752190426, 'n_estimators': 448, 'num_leaves': 25, 'max_depth': 7, 'subsample': 0.8447308501174919, 'colsample_bytree': 0.8917262477098913, 'reg_alpha': 0.1626047683247871, 'reg_lambda': 2.579272846833345, 'min_child_samples': 12}. Best is trial 19 with value: 0.7779488938812053.\n",
      "[I 2025-03-20 04:51:45,325] Trial 42 finished with value: 0.7706921816413317 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.028911726806094402, 'n_estimators': 449, 'num_leaves': 23, 'max_depth': 7, 'subsample': 0.8158318248304117, 'colsample_bytree': 0.8813109588689342, 'reg_alpha': 0.10275458795965423, 'reg_lambda': 3.0487031887579046, 'min_child_samples': 10}. Best is trial 19 with value: 0.7779488938812053.\n",
      "[I 2025-03-20 04:51:45,735] Trial 43 finished with value: 0.7221912524738132 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.015734282010580438, 'n_estimators': 400, 'num_leaves': 22, 'max_depth': 8, 'subsample': 0.8424620226239956, 'colsample_bytree': 0.9272117704151732, 'reg_alpha': 0.15849230883681203, 'reg_lambda': 2.365372499211063, 'min_child_samples': 49}. Best is trial 19 with value: 0.7779488938812053.\n",
      "[I 2025-03-20 04:51:46,299] Trial 44 finished with value: 0.7216335615052617 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.021572674001825984, 'n_estimators': 374, 'num_leaves': 24, 'max_depth': 7, 'subsample': 0.8613322443064856, 'colsample_bytree': 0.9743955623206707, 'reg_alpha': 4.673879544484267, 'reg_lambda': 3.959186500785523, 'min_child_samples': 15}. Best is trial 19 with value: 0.7779488938812053.\n",
      "[I 2025-03-20 04:51:46,711] Trial 45 finished with value: 0.7451531041810623 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.013657837176621185, 'n_estimators': 349, 'num_leaves': 27, 'max_depth': 6, 'subsample': 0.7977596721716281, 'colsample_bytree': 0.7608521197544003, 'reg_alpha': 0.35283513033411473, 'reg_lambda': 1.9837144267838644, 'min_child_samples': 12}. Best is trial 19 with value: 0.7779488938812053.\n",
      "[I 2025-03-20 04:51:47,222] Trial 46 finished with value: 0.7685909910283482 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.032726854374566475, 'n_estimators': 471, 'num_leaves': 15, 'max_depth': 8, 'subsample': 0.9176944566237223, 'colsample_bytree': 0.7091557397947391, 'reg_alpha': 0.11521815055806141, 'reg_lambda': 2.7833671679135787, 'min_child_samples': 13}. Best is trial 19 with value: 0.7779488938812053.\n",
      "[I 2025-03-20 04:51:47,585] Trial 47 finished with value: 0.7295672965765 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.01845954099153649, 'n_estimators': 418, 'num_leaves': 40, 'max_depth': 5, 'subsample': 0.8753108931746318, 'colsample_bytree': 0.8568532338975555, 'reg_alpha': 0.2617276143560488, 'reg_lambda': 1.5140993897155395, 'min_child_samples': 21}. Best is trial 19 with value: 0.7779488938812053.\n",
      "[I 2025-03-20 04:51:48,067] Trial 48 finished with value: 0.7607780241481379 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.024478166185502692, 'n_estimators': 308, 'num_leaves': 35, 'max_depth': 10, 'subsample': 0.8294945855979649, 'colsample_bytree': 0.944545586666829, 'reg_alpha': 0.4404977028583715, 'reg_lambda': 0.11123155755853965, 'min_child_samples': 28}. Best is trial 19 with value: 0.7779488938812053.\n",
      "[I 2025-03-20 04:51:48,553] Trial 49 finished with value: 0.7702126140229826 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.037718325789504195, 'n_estimators': 385, 'num_leaves': 20, 'max_depth': 7, 'subsample': 0.8479193471199045, 'colsample_bytree': 0.91704016848925, 'reg_alpha': 0.1517617904735651, 'reg_lambda': 3.488931223950321, 'min_child_samples': 16}. Best is trial 19 with value: 0.7779488938812053.\n",
      "[I 2025-03-20 04:51:48,709] A new study created in memory with name: no-name-424ff76d-6484-4a1d-956c-3804602c3863\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best LightGBM Parameters:\n",
      "  boosting_type: gbdt\n",
      "  learning_rate: 0.024323369819210055\n",
      "  n_estimators: 431\n",
      "  num_leaves: 23\n",
      "  max_depth: 9\n",
      "  subsample: 0.8485871963258085\n",
      "  colsample_bytree: 0.9099801935870323\n",
      "  reg_alpha: 0.18660755150531425\n",
      "  reg_lambda: 2.1312192026778476\n",
      "  min_child_samples: 12\n",
      "\n",
      "Optimizing LSTM for fold 9 using min_max normalization\n",
      "Created LSTM sequences with lookback=10: 1383 train, 145 test\n",
      "Optimizing LSTM hyperparameters with CV...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-20 04:52:25,766] Trial 0 finished with value: 0.535804664071591 and parameters: {'hidden_dim': 45, 'dropout': 0.4551406810921512, 'learning_rate': 0.007331811314274292, 'batch_size': 16, 'weight_decay': 2.064121088592392e-05}. Best is trial 0 with value: 0.535804664071591.\n",
      "[I 2025-03-20 04:52:46,500] Trial 1 finished with value: 0.5427117658946311 and parameters: {'hidden_dim': 79, 'dropout': 0.48569536770002286, 'learning_rate': 0.003999161563860724, 'batch_size': 32, 'weight_decay': 3.45872269711161e-05}. Best is trial 1 with value: 0.5427117658946311.\n",
      "[I 2025-03-20 04:53:23,905] Trial 2 finished with value: 0.6711566570551567 and parameters: {'hidden_dim': 32, 'dropout': 0.21712375681979076, 'learning_rate': 0.0016665895921660098, 'batch_size': 16, 'weight_decay': 2.1517123363927774e-05}. Best is trial 2 with value: 0.6711566570551567.\n",
      "[I 2025-03-20 04:53:44,800] Trial 3 finished with value: 0.6083875314223341 and parameters: {'hidden_dim': 127, 'dropout': 0.2873081624297713, 'learning_rate': 0.00017643094449433023, 'batch_size': 32, 'weight_decay': 1.0947309020486406e-05}. Best is trial 2 with value: 0.6711566570551567.\n",
      "[I 2025-03-20 04:54:21,729] Trial 4 finished with value: 0.641756798103414 and parameters: {'hidden_dim': 47, 'dropout': 0.10585094112968818, 'learning_rate': 0.0004451295365396247, 'batch_size': 16, 'weight_decay': 1.3639281514957935e-06}. Best is trial 2 with value: 0.6711566570551567.\n",
      "[I 2025-03-20 04:54:31,435] Trial 5 finished with value: 0.6659151907645694 and parameters: {'hidden_dim': 59, 'dropout': 0.2875597071705984, 'learning_rate': 0.0033384615669657483, 'batch_size': 64, 'weight_decay': 9.98214837316597e-06}. Best is trial 2 with value: 0.6711566570551567.\n",
      "[I 2025-03-20 04:55:08,378] Trial 6 finished with value: 0.6532411071565252 and parameters: {'hidden_dim': 109, 'dropout': 0.4586320455614753, 'learning_rate': 0.0009209968619749436, 'batch_size': 16, 'weight_decay': 1.6223673683559225e-06}. Best is trial 2 with value: 0.6711566570551567.\n",
      "[I 2025-03-20 04:55:29,217] Trial 7 finished with value: 0.5328843140987225 and parameters: {'hidden_dim': 82, 'dropout': 0.3594032085405511, 'learning_rate': 0.006298297451196278, 'batch_size': 32, 'weight_decay': 7.511737052942637e-05}. Best is trial 2 with value: 0.6711566570551567.\n",
      "[I 2025-03-20 04:55:38,753] Trial 8 finished with value: 0.58826366958439 and parameters: {'hidden_dim': 125, 'dropout': 0.17649687394806254, 'learning_rate': 0.00809174687672524, 'batch_size': 64, 'weight_decay': 5.656354626844694e-06}. Best is trial 2 with value: 0.6711566570551567.\n",
      "[I 2025-03-20 04:56:15,649] Trial 9 finished with value: 0.5151964700064666 and parameters: {'hidden_dim': 127, 'dropout': 0.3668293205677101, 'learning_rate': 0.009614679235250567, 'batch_size': 16, 'weight_decay': 2.2160868002868673e-05}. Best is trial 2 with value: 0.6711566570551567.\n",
      "[I 2025-03-20 04:56:56,253] Trial 10 finished with value: 0.6774218507481486 and parameters: {'hidden_dim': 32, 'dropout': 0.198627869896562, 'learning_rate': 0.0015689723478599755, 'batch_size': 16, 'weight_decay': 8.469738945067809e-05}. Best is trial 10 with value: 0.6774218507481486.\n",
      "[I 2025-03-20 04:57:33,774] Trial 11 finished with value: 0.6427782363985002 and parameters: {'hidden_dim': 35, 'dropout': 0.19058312272398745, 'learning_rate': 0.0019833844976595914, 'batch_size': 16, 'weight_decay': 7.238871454280833e-05}. Best is trial 10 with value: 0.6774218507481486.\n",
      "[I 2025-03-20 04:58:11,433] Trial 12 finished with value: 0.6629629946247521 and parameters: {'hidden_dim': 33, 'dropout': 0.2036480525290789, 'learning_rate': 0.0011199998097904127, 'batch_size': 16, 'weight_decay': 9.317576029252809e-05}. Best is trial 10 with value: 0.6774218507481486.\n",
      "[I 2025-03-20 04:58:48,903] Trial 13 finished with value: 0.6388947600492912 and parameters: {'hidden_dim': 65, 'dropout': 0.23752318417795276, 'learning_rate': 0.0007285120693189867, 'batch_size': 16, 'weight_decay': 3.592505975293006e-05}. Best is trial 10 with value: 0.6774218507481486.\n",
      "[I 2025-03-20 04:59:26,253] Trial 14 finished with value: 0.647832728247233 and parameters: {'hidden_dim': 54, 'dropout': 0.11485150758934834, 'learning_rate': 0.0016131525076615407, 'batch_size': 16, 'weight_decay': 3.706997073180021e-06}. Best is trial 10 with value: 0.6774218507481486.\n",
      "[I 2025-03-20 04:59:35,899] Trial 15 finished with value: 0.6095948893954023 and parameters: {'hidden_dim': 75, 'dropout': 0.24012784951072286, 'learning_rate': 0.0003239628263686598, 'batch_size': 64, 'weight_decay': 3.7504371664630406e-05}. Best is trial 10 with value: 0.6774218507481486.\n",
      "[I 2025-03-20 05:00:16,002] Trial 16 finished with value: 0.6098103688551276 and parameters: {'hidden_dim': 99, 'dropout': 0.1583274391610994, 'learning_rate': 0.0024684247055058992, 'batch_size': 16, 'weight_decay': 1.516722557322051e-05}. Best is trial 10 with value: 0.6774218507481486.\n",
      "[I 2025-03-20 05:00:53,337] Trial 17 finished with value: 0.6004032916363543 and parameters: {'hidden_dim': 32, 'dropout': 0.3395696612011294, 'learning_rate': 0.00010728531826263386, 'batch_size': 16, 'weight_decay': 5.258676801828717e-05}. Best is trial 10 with value: 0.6774218507481486.\n",
      "[I 2025-03-20 05:01:11,058] Trial 18 finished with value: 0.628569871347747 and parameters: {'hidden_dim': 45, 'dropout': 0.24087059057602495, 'learning_rate': 0.0006275250989672774, 'batch_size': 32, 'weight_decay': 5.241926450414238e-06}. Best is trial 10 with value: 0.6774218507481486.\n",
      "[I 2025-03-20 05:01:23,758] Trial 19 finished with value: 0.6352183690869442 and parameters: {'hidden_dim': 71, 'dropout': 0.15100282581222765, 'learning_rate': 0.0012669937433152315, 'batch_size': 64, 'weight_decay': 5.0544666877380265e-05}. Best is trial 10 with value: 0.6774218507481486.\n",
      "[I 2025-03-20 05:02:00,819] Trial 20 finished with value: 0.5965701679381571 and parameters: {'hidden_dim': 54, 'dropout': 0.31584956519595825, 'learning_rate': 0.004241511909900162, 'batch_size': 16, 'weight_decay': 2.326452924109024e-05}. Best is trial 10 with value: 0.6774218507481486.\n",
      "[I 2025-03-20 05:02:10,463] Trial 21 finished with value: 0.6391231346766385 and parameters: {'hidden_dim': 61, 'dropout': 0.26795554642726727, 'learning_rate': 0.003188336393947412, 'batch_size': 64, 'weight_decay': 1.0468189634633399e-05}. Best is trial 10 with value: 0.6774218507481486.\n",
      "[I 2025-03-20 05:02:19,955] Trial 22 finished with value: 0.654572416006596 and parameters: {'hidden_dim': 42, 'dropout': 0.21385929384475041, 'learning_rate': 0.0024770677759814283, 'batch_size': 64, 'weight_decay': 4.986691512908768e-06}. Best is trial 10 with value: 0.6774218507481486.\n",
      "[I 2025-03-20 05:02:32,743] Trial 23 finished with value: 0.6487965766345932 and parameters: {'hidden_dim': 90, 'dropout': 0.3968430106379216, 'learning_rate': 0.0014327395004525422, 'batch_size': 64, 'weight_decay': 2.8800150817969444e-06}. Best is trial 10 with value: 0.6774218507481486.\n",
      "[I 2025-03-20 05:02:42,369] Trial 24 finished with value: 0.5910674755318012 and parameters: {'hidden_dim': 55, 'dropout': 0.27382791917192173, 'learning_rate': 0.005328777761498961, 'batch_size': 64, 'weight_decay': 1.3424138367713363e-05}. Best is trial 10 with value: 0.6774218507481486.\n",
      "[I 2025-03-20 05:02:51,921] Trial 25 finished with value: 0.6757903196420116 and parameters: {'hidden_dim': 39, 'dropout': 0.31046138410439933, 'learning_rate': 0.0025956817934301587, 'batch_size': 64, 'weight_decay': 8.368704241544395e-06}. Best is trial 10 with value: 0.6774218507481486.\n",
      "[I 2025-03-20 05:03:30,292] Trial 26 finished with value: 0.6448097113374159 and parameters: {'hidden_dim': 39, 'dropout': 0.3181694865268744, 'learning_rate': 0.002097495860861346, 'batch_size': 16, 'weight_decay': 7.643059214286206e-06}. Best is trial 10 with value: 0.6774218507481486.\n",
      "[I 2025-03-20 05:04:09,452] Trial 27 finished with value: 0.6205759136592378 and parameters: {'hidden_dim': 40, 'dropout': 0.39668519437280986, 'learning_rate': 0.0007832472315257963, 'batch_size': 16, 'weight_decay': 2.5032956355233365e-06}. Best is trial 10 with value: 0.6774218507481486.\n",
      "[I 2025-03-20 05:04:26,822] Trial 28 finished with value: 0.6186616730500744 and parameters: {'hidden_dim': 38, 'dropout': 0.22590849257649542, 'learning_rate': 0.0004997653299421055, 'batch_size': 32, 'weight_decay': 1.775776316480489e-05}. Best is trial 10 with value: 0.6774218507481486.\n",
      "[I 2025-03-20 05:04:39,621] Trial 29 finished with value: 0.6823816972656531 and parameters: {'hidden_dim': 48, 'dropout': 0.13666744458353786, 'learning_rate': 0.0015516261633503558, 'batch_size': 64, 'weight_decay': 2.3806970808760897e-05}. Best is trial 29 with value: 0.6823816972656531.\n",
      "[I 2025-03-20 05:04:49,364] Trial 30 finished with value: 0.6402754327952453 and parameters: {'hidden_dim': 50, 'dropout': 0.13661838231310647, 'learning_rate': 0.0010933955132323735, 'batch_size': 64, 'weight_decay': 2.8958984767286833e-05}. Best is trial 29 with value: 0.6823816972656531.\n",
      "[I 2025-03-20 05:04:58,913] Trial 31 finished with value: 0.6602388046424309 and parameters: {'hidden_dim': 32, 'dropout': 0.16747283186453246, 'learning_rate': 0.001701929244904214, 'batch_size': 64, 'weight_decay': 7.776988541958994e-06}. Best is trial 29 with value: 0.6823816972656531.\n",
      "[I 2025-03-20 05:05:11,651] Trial 32 finished with value: 0.6728596114020086 and parameters: {'hidden_dim': 46, 'dropout': 0.19815183370477216, 'learning_rate': 0.002545251390056808, 'batch_size': 64, 'weight_decay': 4.6881429114397445e-05}. Best is trial 29 with value: 0.6823816972656531.\n",
      "[I 2025-03-20 05:05:21,450] Trial 33 finished with value: 0.6352919782603031 and parameters: {'hidden_dim': 48, 'dropout': 0.13388626944653662, 'learning_rate': 0.0028225362969412846, 'batch_size': 64, 'weight_decay': 5.2782322544014986e-05}. Best is trial 29 with value: 0.6823816972656531.\n",
      "[I 2025-03-20 05:05:30,977] Trial 34 finished with value: 0.5909899734482397 and parameters: {'hidden_dim': 64, 'dropout': 0.2611961875839098, 'learning_rate': 0.00472416893704208, 'batch_size': 64, 'weight_decay': 9.845414779099886e-05}. Best is trial 29 with value: 0.6823816972656531.\n",
      "[I 2025-03-20 05:05:40,664] Trial 35 finished with value: 0.638543614530007 and parameters: {'hidden_dim': 44, 'dropout': 0.18389581186502163, 'learning_rate': 0.003352400471928185, 'batch_size': 64, 'weight_decay': 4.6461258271985586e-05}. Best is trial 29 with value: 0.6823816972656531.\n",
      "[I 2025-03-20 05:05:53,410] Trial 36 finished with value: 0.6697547055038168 and parameters: {'hidden_dim': 50, 'dropout': 0.12798064250681018, 'learning_rate': 0.0020246832174649057, 'batch_size': 64, 'weight_decay': 2.8016813613165302e-05}. Best is trial 29 with value: 0.6823816972656531.\n",
      "[I 2025-03-20 05:06:02,940] Trial 37 finished with value: 0.6269660313696575 and parameters: {'hidden_dim': 68, 'dropout': 0.20348347732804756, 'learning_rate': 0.001474158274684299, 'batch_size': 64, 'weight_decay': 6.107940586195808e-05}. Best is trial 29 with value: 0.6823816972656531.\n",
      "[I 2025-03-20 05:06:23,608] Trial 38 finished with value: 0.5925094781640589 and parameters: {'hidden_dim': 58, 'dropout': 0.29536268472114047, 'learning_rate': 0.003673406614634264, 'batch_size': 32, 'weight_decay': 4.026213427303051e-05}. Best is trial 29 with value: 0.6823816972656531.\n",
      "[I 2025-03-20 05:06:33,189] Trial 39 finished with value: 0.6236332202578291 and parameters: {'hidden_dim': 38, 'dropout': 0.10695436380859222, 'learning_rate': 0.0009418097746777069, 'batch_size': 64, 'weight_decay': 6.995604534211383e-05}. Best is trial 29 with value: 0.6823816972656531.\n",
      "[I 2025-03-20 05:06:42,698] Trial 40 finished with value: 0.5475971571249665 and parameters: {'hidden_dim': 82, 'dropout': 0.4925372685628688, 'learning_rate': 0.006122841053976072, 'batch_size': 64, 'weight_decay': 2.8171912384554842e-05}. Best is trial 29 with value: 0.6823816972656531.\n",
      "[I 2025-03-20 05:07:19,743] Trial 41 finished with value: 0.6283562642484247 and parameters: {'hidden_dim': 44, 'dropout': 0.15394449016051034, 'learning_rate': 0.002378249359153111, 'batch_size': 16, 'weight_decay': 1.3145289149890038e-05}. Best is trial 29 with value: 0.6823816972656531.\n",
      "[I 2025-03-20 05:07:19,751] A new study created in memory with name: no-name-6c34f90e-056e-4a8d-9c13-9018246b87f2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best LSTM Parameters:\n",
      "  hidden_dim: 48\n",
      "  dropout: 0.13666744458353786\n",
      "  learning_rate: 0.0015516261633503558\n",
      "  batch_size: 64\n",
      "  weight_decay: 2.3806970808760897e-05\n",
      "\n",
      "Optimizing LightGBM for fold 10 using min_max normalization\n",
      "Optimizing LightGBM hyperparameters with CV...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-20 05:07:20,127] Trial 0 finished with value: 0.7048577574649746 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.013661178428178952, 'n_estimators': 456, 'num_leaves': 48, 'max_depth': 6, 'subsample': 0.7552942184455931, 'colsample_bytree': 0.7030385741204636, 'reg_alpha': 1.3087232248047334, 'reg_lambda': 0.6869757398160233, 'min_child_samples': 49}. Best is trial 0 with value: 0.7048577574649746.\n",
      "[I 2025-03-20 05:07:20,259] Trial 1 finished with value: 0.6900410394378389 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.06323892443630524, 'n_estimators': 282, 'num_leaves': 42, 'max_depth': 3, 'subsample': 0.9077831487751247, 'colsample_bytree': 0.6012684467021177, 'reg_alpha': 0.31439409038438626, 'reg_lambda': 1.0912521853098582, 'min_child_samples': 47}. Best is trial 0 with value: 0.7048577574649746.\n",
      "[I 2025-03-20 05:07:20,583] Trial 2 finished with value: 0.7132855773882645 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.019957907467756848, 'n_estimators': 199, 'num_leaves': 37, 'max_depth': 10, 'subsample': 0.7873081624297713, 'colsample_bytree': 0.6493149518105418, 'reg_alpha': 3.6000609130029044, 'reg_lambda': 4.050134848257446, 'min_child_samples': 21}. Best is trial 2 with value: 0.7132855773882645.\n",
      "[I 2025-03-20 05:07:20,719] Trial 3 finished with value: 0.6882286243120068 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.03308671790989007, 'n_estimators': 162, 'num_leaves': 10, 'max_depth': 5, 'subsample': 0.9963593754983149, 'colsample_bytree': 0.805256515122397, 'reg_alpha': 3.0841806167907238, 'reg_lambda': 0.1301677362213169, 'min_child_samples': 21}. Best is trial 2 with value: 0.7132855773882645.\n",
      "[I 2025-03-20 05:07:24,352] Trial 4 finished with value: 0.7394746078323216 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.029437387715603364, 'n_estimators': 405, 'num_leaves': 47, 'max_depth': 6, 'subsample': 0.9716350708762611, 'colsample_bytree': 0.7998448041733087, 'reg_alpha': 2.304933318498776, 'reg_lambda': 3.3362817514757888, 'min_child_samples': 29}. Best is trial 4 with value: 0.7394746078323216.\n",
      "[I 2025-03-20 05:07:26,245] Trial 5 finished with value: 0.6941510313956506 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.07045793365915588, 'n_estimators': 210, 'num_leaves': 23, 'max_depth': 3, 'subsample': 0.8092590874861125, 'colsample_bytree': 0.859403208540551, 'reg_alpha': 3.3760828530802196, 'reg_lambda': 0.15012918259918107, 'min_child_samples': 22}. Best is trial 4 with value: 0.7394746078323216.\n",
      "[I 2025-03-20 05:07:26,568] Trial 6 finished with value: 0.687744192521823 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.011970252710206382, 'n_estimators': 476, 'num_leaves': 49, 'max_depth': 4, 'subsample': 0.9816084577717837, 'colsample_bytree': 0.7776193095921519, 'reg_alpha': 0.2802529145561249, 'reg_lambda': 1.3744727196612017, 'min_child_samples': 25}. Best is trial 4 with value: 0.7394746078323216.\n",
      "[I 2025-03-20 05:07:27,021] Trial 7 finished with value: 0.764230419990241 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.0967088301559984, 'n_estimators': 367, 'num_leaves': 50, 'max_depth': 10, 'subsample': 0.6725825297010686, 'colsample_bytree': 0.7765487989776441, 'reg_alpha': 1.3901311581414446, 'reg_lambda': 1.2894120399825089, 'min_child_samples': 25}. Best is trial 7 with value: 0.764230419990241.\n",
      "[I 2025-03-20 05:07:27,307] Trial 8 finished with value: 0.7313555588872009 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.04669085237595252, 'n_estimators': 388, 'num_leaves': 42, 'max_depth': 5, 'subsample': 0.6388242673991037, 'colsample_bytree': 0.9337670455562896, 'reg_alpha': 0.11037032003620384, 'reg_lambda': 0.25448376172072, 'min_child_samples': 45}. Best is trial 7 with value: 0.764230419990241.\n",
      "[I 2025-03-20 05:07:27,456] Trial 9 finished with value: 0.6883927617436049 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.011232085595448875, 'n_estimators': 177, 'num_leaves': 29, 'max_depth': 4, 'subsample': 0.7436406503252848, 'colsample_bytree': 0.6580654068535353, 'reg_alpha': 0.1699984374960256, 'reg_lambda': 0.1466016632681982, 'min_child_samples': 16}. Best is trial 7 with value: 0.764230419990241.\n",
      "[I 2025-03-20 05:07:27,923] Trial 10 finished with value: 0.7599663113374963 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.0987558719383339, 'n_estimators': 337, 'num_leaves': 18, 'max_depth': 10, 'subsample': 0.642242017563948, 'colsample_bytree': 0.9614634142305828, 'reg_alpha': 0.7548915517607346, 'reg_lambda': 0.47191940414066896, 'min_child_samples': 37}. Best is trial 7 with value: 0.764230419990241.\n",
      "[I 2025-03-20 05:07:28,350] Trial 11 finished with value: 0.7631698587808472 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.08811492902543544, 'n_estimators': 327, 'num_leaves': 17, 'max_depth': 10, 'subsample': 0.6019793854602531, 'colsample_bytree': 0.993860589036455, 'reg_alpha': 0.7915653922317443, 'reg_lambda': 0.4908802288038389, 'min_child_samples': 38}. Best is trial 7 with value: 0.764230419990241.\n",
      "[I 2025-03-20 05:07:28,611] Trial 12 finished with value: 0.7434716473764647 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.0990179709954607, 'n_estimators': 280, 'num_leaves': 10, 'max_depth': 8, 'subsample': 0.6033581704047635, 'colsample_bytree': 0.8896098816778567, 'reg_alpha': 0.907421645328279, 'reg_lambda': 1.8653713281408886, 'min_child_samples': 37}. Best is trial 7 with value: 0.764230419990241.\n",
      "[I 2025-03-20 05:07:29,189] Trial 13 finished with value: 0.7741224906948874 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.059391142739541755, 'n_estimators': 337, 'num_leaves': 31, 'max_depth': 8, 'subsample': 0.6877372513421857, 'colsample_bytree': 0.7437973057303883, 'reg_alpha': 1.3765039473276297, 'reg_lambda': 0.36073977073087093, 'min_child_samples': 10}. Best is trial 13 with value: 0.7741224906948874.\n",
      "[I 2025-03-20 05:07:29,431] Trial 14 finished with value: 0.7555537212588985 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.054107603519745036, 'n_estimators': 106, 'num_leaves': 32, 'max_depth': 8, 'subsample': 0.7003420127694024, 'colsample_bytree': 0.7199502625390595, 'reg_alpha': 1.6169271278054258, 'reg_lambda': 0.26799625954839545, 'min_child_samples': 10}. Best is trial 13 with value: 0.7741224906948874.\n",
      "[I 2025-03-20 05:07:30,155] Trial 15 finished with value: 0.7774985382624306 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.040433421746416294, 'n_estimators': 396, 'num_leaves': 30, 'max_depth': 8, 'subsample': 0.7027425747705485, 'colsample_bytree': 0.7470184566527958, 'reg_alpha': 0.4036586343062373, 'reg_lambda': 2.046660093391063, 'min_child_samples': 12}. Best is trial 15 with value: 0.7774985382624306.\n",
      "[I 2025-03-20 05:07:30,958] Trial 16 finished with value: 0.7785914753137924 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.03886496796752491, 'n_estimators': 431, 'num_leaves': 29, 'max_depth': 8, 'subsample': 0.8460344390937014, 'colsample_bytree': 0.7232415113894823, 'reg_alpha': 0.4116078917604264, 'reg_lambda': 2.6533031074045117, 'min_child_samples': 10}. Best is trial 16 with value: 0.7785914753137924.\n",
      "[I 2025-03-20 05:07:31,624] Trial 17 finished with value: 0.7692932455525404 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.037464204026427694, 'n_estimators': 433, 'num_leaves': 26, 'max_depth': 7, 'subsample': 0.872602340863694, 'colsample_bytree': 0.8453652023317368, 'reg_alpha': 0.444114994392865, 'reg_lambda': 2.4475129021666806, 'min_child_samples': 15}. Best is trial 16 with value: 0.7785914753137924.\n",
      "[I 2025-03-20 05:07:32,546] Trial 18 finished with value: 0.7654493337013297 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.0276669503148614, 'n_estimators': 485, 'num_leaves': 36, 'max_depth': 9, 'subsample': 0.8556167667539123, 'colsample_bytree': 0.6837107869167542, 'reg_alpha': 0.45729733448074894, 'reg_lambda': 4.804519372092108, 'min_child_samples': 16}. Best is trial 16 with value: 0.7785914753137924.\n",
      "[I 2025-03-20 05:07:33,092] Trial 19 finished with value: 0.7607639914131502 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.022041541927620062, 'n_estimators': 419, 'num_leaves': 23, 'max_depth': 7, 'subsample': 0.8211640614930323, 'colsample_bytree': 0.7559894786501817, 'reg_alpha': 0.19765205253500492, 'reg_lambda': 2.5249168808283144, 'min_child_samples': 13}. Best is trial 16 with value: 0.7785914753137924.\n",
      "[I 2025-03-20 05:07:33,589] Trial 20 finished with value: 0.7653441670681144 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.04294111195636757, 'n_estimators': 377, 'num_leaves': 36, 'max_depth': 9, 'subsample': 0.9350067851755174, 'colsample_bytree': 0.6117390224814703, 'reg_alpha': 0.46207069744504387, 'reg_lambda': 0.8270108477006785, 'min_child_samples': 31}. Best is trial 16 with value: 0.7785914753137924.\n",
      "[I 2025-03-20 05:07:34,190] Trial 21 finished with value: 0.7785701434741235 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.053742310363987036, 'n_estimators': 322, 'num_leaves': 31, 'max_depth': 8, 'subsample': 0.7324837950344805, 'colsample_bytree': 0.7264614899299321, 'reg_alpha': 0.5581735521015109, 'reg_lambda': 1.9366445402626908, 'min_child_samples': 10}. Best is trial 16 with value: 0.7785914753137924.\n",
      "[I 2025-03-20 05:07:34,626] Trial 22 finished with value: 0.7688549098966764 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.04268047014433742, 'n_estimators': 249, 'num_leaves': 27, 'max_depth': 9, 'subsample': 0.7392378424551677, 'colsample_bytree': 0.7274788609192808, 'reg_alpha': 0.5684482953319147, 'reg_lambda': 1.8757624906581742, 'min_child_samples': 13}. Best is trial 16 with value: 0.7785914753137924.\n",
      "[I 2025-03-20 05:07:35,128] Trial 23 finished with value: 0.7674952789750723 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.04993304543971364, 'n_estimators': 363, 'num_leaves': 33, 'max_depth': 7, 'subsample': 0.724476370879777, 'colsample_bytree': 0.6806294635356269, 'reg_alpha': 0.2794104744469828, 'reg_lambda': 2.98661362681587, 'min_child_samples': 18}. Best is trial 16 with value: 0.7785914753137924.\n",
      "[I 2025-03-20 05:07:35,857] Trial 24 finished with value: 0.7796217513622834 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.07587861718067437, 'n_estimators': 444, 'num_leaves': 23, 'max_depth': 8, 'subsample': 0.7790390842332888, 'colsample_bytree': 0.829530453904398, 'reg_alpha': 0.3333361494403099, 'reg_lambda': 1.8686880133435015, 'min_child_samples': 10}. Best is trial 24 with value: 0.7796217513622834.\n",
      "[I 2025-03-20 05:07:36,638] Trial 25 finished with value: 0.7785371853086487 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.07784689240290774, 'n_estimators': 498, 'num_leaves': 21, 'max_depth': 9, 'subsample': 0.7698700222030773, 'colsample_bytree': 0.8191405547318434, 'reg_alpha': 0.1799693832133791, 'reg_lambda': 1.5485796462374646, 'min_child_samples': 18}. Best is trial 24 with value: 0.7796217513622834.\n",
      "[I 2025-03-20 05:07:37,200] Trial 26 finished with value: 0.7768608605537531 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.06345245012844694, 'n_estimators': 445, 'num_leaves': 16, 'max_depth': 8, 'subsample': 0.8392098112407731, 'colsample_bytree': 0.8982156754639485, 'reg_alpha': 0.5741599686493045, 'reg_lambda': 1.0072836772021072, 'min_child_samples': 11}. Best is trial 24 with value: 0.7796217513622834.\n",
      "[I 2025-03-20 05:07:37,696] Trial 27 finished with value: 0.7703466718569195 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.07714317599092091, 'n_estimators': 307, 'num_leaves': 25, 'max_depth': 7, 'subsample': 0.8916913075050765, 'colsample_bytree': 0.8657922452904462, 'reg_alpha': 0.9969363911419232, 'reg_lambda': 3.2426501817015643, 'min_child_samples': 14}. Best is trial 24 with value: 0.7796217513622834.\n",
      "[I 2025-03-20 05:07:38,218] Trial 28 finished with value: 0.7646675314516256 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.052973620113314975, 'n_estimators': 459, 'num_leaves': 20, 'max_depth': 6, 'subsample': 0.7813278150057494, 'colsample_bytree': 0.826101235514139, 'reg_alpha': 0.23224011800752511, 'reg_lambda': 4.89726468724286, 'min_child_samples': 19}. Best is trial 24 with value: 0.7796217513622834.\n",
      "[I 2025-03-20 05:07:38,656] Trial 29 finished with value: 0.7493615117201113 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.025019343925622817, 'n_estimators': 456, 'num_leaves': 40, 'max_depth': 6, 'subsample': 0.8311590186842902, 'colsample_bytree': 0.692555650891773, 'reg_alpha': 0.13215010956184592, 'reg_lambda': 0.6440961910927886, 'min_child_samples': 25}. Best is trial 24 with value: 0.7796217513622834.\n",
      "[I 2025-03-20 05:07:38,938] Trial 30 finished with value: 0.7468276401519491 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.034730646574473764, 'n_estimators': 258, 'num_leaves': 13, 'max_depth': 9, 'subsample': 0.7580447718151729, 'colsample_bytree': 0.7786491043772257, 'reg_alpha': 0.3439469694668706, 'reg_lambda': 0.8362542918685727, 'min_child_samples': 10}. Best is trial 24 with value: 0.7796217513622834.\n",
      "[I 2025-03-20 05:07:39,686] Trial 31 finished with value: 0.7825702718412705 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.08218929332625717, 'n_estimators': 491, 'num_leaves': 22, 'max_depth': 9, 'subsample': 0.7729088587284306, 'colsample_bytree': 0.8230443984184583, 'reg_alpha': 0.16937248723810025, 'reg_lambda': 1.4761730195150649, 'min_child_samples': 18}. Best is trial 31 with value: 0.7825702718412705.\n",
      "[I 2025-03-20 05:07:40,385] Trial 32 finished with value: 0.7794430815340443 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.06908552115669746, 'n_estimators': 429, 'num_leaves': 27, 'max_depth': 8, 'subsample': 0.7995709456048835, 'colsample_bytree': 0.7104483018255434, 'reg_alpha': 0.5666412001765936, 'reg_lambda': 1.6993577718412907, 'min_child_samples': 15}. Best is trial 31 with value: 0.7825702718412705.\n",
      "[I 2025-03-20 05:07:41,023] Trial 33 finished with value: 0.7709477629805637 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.01663636496123175, 'n_estimators': 419, 'num_leaves': 28, 'max_depth': 9, 'subsample': 0.8572590820925617, 'colsample_bytree': 0.6429504375875497, 'reg_alpha': 0.14041934441961001, 'reg_lambda': 1.5180409744472128, 'min_child_samples': 16}. Best is trial 31 with value: 0.7825702718412705.\n",
      "[I 2025-03-20 05:07:41,724] Trial 34 finished with value: 0.7856822157679966 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.07923781116698583, 'n_estimators': 475, 'num_leaves': 24, 'max_depth': 8, 'subsample': 0.7947637714141057, 'colsample_bytree': 0.8357132646540617, 'reg_alpha': 0.23681235761179076, 'reg_lambda': 1.1239847682431456, 'min_child_samples': 20}. Best is trial 34 with value: 0.7856822157679966.\n",
      "[I 2025-03-20 05:07:42,365] Trial 35 finished with value: 0.7783905110352248 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.0827441840354009, 'n_estimators': 473, 'num_leaves': 23, 'max_depth': 7, 'subsample': 0.7931580447216158, 'colsample_bytree': 0.8986566288638143, 'reg_alpha': 0.25050102607575736, 'reg_lambda': 1.0956510960328707, 'min_child_samples': 22}. Best is trial 34 with value: 0.7856822157679966.\n",
      "[I 2025-03-20 05:07:43,005] Trial 36 finished with value: 0.7765801587427943 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.06882848949889413, 'n_estimators': 497, 'num_leaves': 20, 'max_depth': 9, 'subsample': 0.8065328184675857, 'colsample_bytree': 0.836438193463133, 'reg_alpha': 0.31573614492844077, 'reg_lambda': 1.1046290863523984, 'min_child_samples': 30}. Best is trial 34 with value: 0.7856822157679966.\n",
      "[I 2025-03-20 05:07:43,511] Trial 37 finished with value: 0.7714145905887839 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.0725432720199171, 'n_estimators': 461, 'num_leaves': 14, 'max_depth': 10, 'subsample': 0.7672517042725225, 'colsample_bytree': 0.8735316829206282, 'reg_alpha': 0.21429809784642595, 'reg_lambda': 0.724333074416839, 'min_child_samples': 21}. Best is trial 34 with value: 0.7856822157679966.\n",
      "[I 2025-03-20 05:07:44,068] Trial 38 finished with value: 0.7720735667563315 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.062146052332771616, 'n_estimators': 414, 'num_leaves': 25, 'max_depth': 8, 'subsample': 0.8035488175162635, 'colsample_bytree': 0.7989513322179396, 'reg_alpha': 0.16074291239263971, 'reg_lambda': 1.3264429853004072, 'min_child_samples': 27}. Best is trial 34 with value: 0.7856822157679966.\n",
      "[I 2025-03-20 05:07:44,657] Trial 39 finished with value: 0.7740767816133142 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.08950897842984315, 'n_estimators': 444, 'num_leaves': 22, 'max_depth': 7, 'subsample': 0.7832114653691818, 'colsample_bytree': 0.8067415032990268, 'reg_alpha': 0.11188155378204465, 'reg_lambda': 3.8455829901655743, 'min_child_samples': 19}. Best is trial 34 with value: 0.7856822157679966.\n",
      "[I 2025-03-20 05:07:45,418] Trial 40 finished with value: 0.7718764425988838 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.06847251678623954, 'n_estimators': 474, 'num_leaves': 24, 'max_depth': 9, 'subsample': 0.8219336959481144, 'colsample_bytree': 0.926530131744372, 'reg_alpha': 0.3328688056532919, 'reg_lambda': 1.647208421651222, 'min_child_samples': 23}. Best is trial 34 with value: 0.7856822157679966.\n",
      "[I 2025-03-20 05:07:46,167] Trial 41 finished with value: 0.7844551791909201 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.0844801019222892, 'n_estimators': 436, 'num_leaves': 28, 'max_depth': 8, 'subsample': 0.9347849384957223, 'colsample_bytree': 0.7631614379939149, 'reg_alpha': 0.2645125600995368, 'reg_lambda': 2.6648575833734296, 'min_child_samples': 15}. Best is trial 34 with value: 0.7856822157679966.\n",
      "[I 2025-03-20 05:07:46,918] Trial 42 finished with value: 0.7888335055640165 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.08475410321394156, 'n_estimators': 400, 'num_leaves': 34, 'max_depth': 8, 'subsample': 0.9102906521868761, 'colsample_bytree': 0.7868463904675783, 'reg_alpha': 0.23421693593995324, 'reg_lambda': 2.109557419848068, 'min_child_samples': 14}. Best is trial 42 with value: 0.7888335055640165.\n",
      "[I 2025-03-20 05:07:47,625] Trial 43 finished with value: 0.7787473063791286 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.08500315524381467, 'n_estimators': 403, 'num_leaves': 34, 'max_depth': 8, 'subsample': 0.9334010187814712, 'colsample_bytree': 0.7872941949047336, 'reg_alpha': 0.2634322046551822, 'reg_lambda': 2.2676086993999847, 'min_child_samples': 18}. Best is trial 42 with value: 0.7888335055640165.\n",
      "[I 2025-03-20 05:07:47,893] Trial 44 finished with value: 0.727492210327081 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.07882701386661421, 'n_estimators': 483, 'num_leaves': 38, 'max_depth': 10, 'subsample': 0.9640643556603123, 'colsample_bytree': 0.7620275280815318, 'reg_alpha': 4.673879544484267, 'reg_lambda': 3.6599388055404805, 'min_child_samples': 14}. Best is trial 42 with value: 0.7888335055640165.\n",
      "[I 2025-03-20 05:07:48,280] Trial 45 finished with value: 0.7666726886354039 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.0922372754241078, 'n_estimators': 446, 'num_leaves': 47, 'max_depth': 5, 'subsample': 0.899647793396936, 'colsample_bytree': 0.8433414987269275, 'reg_alpha': 0.15138462906754574, 'reg_lambda': 2.8031899228770296, 'min_child_samples': 33}. Best is trial 42 with value: 0.7888335055640165.\n",
      "[I 2025-03-20 05:07:48,703] Trial 46 finished with value: 0.7721047812206245 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.05893265867975794, 'n_estimators': 355, 'num_leaves': 18, 'max_depth': 7, 'subsample': 0.9239353031342249, 'colsample_bytree': 0.8231275795426853, 'reg_alpha': 0.20362471127722348, 'reg_lambda': 1.2770802404446837, 'min_child_samples': 17}. Best is trial 42 with value: 0.7888335055640165.\n",
      "[I 2025-03-20 05:07:49,385] Trial 47 finished with value: 0.7846542822460545 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.09811531181971754, 'n_estimators': 381, 'num_leaves': 34, 'max_depth': 9, 'subsample': 0.9557980737694479, 'colsample_bytree': 0.8022041320364917, 'reg_alpha': 0.12146105640237952, 'reg_lambda': 2.2715369591283765, 'min_child_samples': 20}. Best is trial 42 with value: 0.7888335055640165.\n",
      "[I 2025-03-20 05:07:50,081] Trial 48 finished with value: 0.7921491289518431 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.09574317684350614, 'n_estimators': 383, 'num_leaves': 35, 'max_depth': 10, 'subsample': 0.9582897849444949, 'colsample_bytree': 0.7984728052482307, 'reg_alpha': 0.10473363490116507, 'reg_lambda': 0.11123155755853965, 'min_child_samples': 20}. Best is trial 48 with value: 0.7921491289518431.\n",
      "[I 2025-03-20 05:07:50,736] Trial 49 finished with value: 0.7859280274438973 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.09614202317520154, 'n_estimators': 378, 'num_leaves': 44, 'max_depth': 10, 'subsample': 0.9989215808749621, 'colsample_bytree': 0.7997562969910458, 'reg_alpha': 0.13696336118425695, 'reg_lambda': 0.48073717254775117, 'min_child_samples': 24}. Best is trial 48 with value: 0.7921491289518431.\n",
      "[I 2025-03-20 05:07:50,902] A new study created in memory with name: no-name-a125906d-2d5c-445b-a09a-5708b8ae503c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best LightGBM Parameters:\n",
      "  boosting_type: gbdt\n",
      "  learning_rate: 0.09574317684350614\n",
      "  n_estimators: 383\n",
      "  num_leaves: 35\n",
      "  max_depth: 10\n",
      "  subsample: 0.9582897849444949\n",
      "  colsample_bytree: 0.7984728052482307\n",
      "  reg_alpha: 0.10473363490116507\n",
      "  reg_lambda: 0.11123155755853965\n",
      "  min_child_samples: 20\n",
      "\n",
      "Optimizing LSTM for fold 10 using min_max normalization\n",
      "Created LSTM sequences with lookback=10: 1538 train, 145 test\n",
      "Optimizing LSTM hyperparameters with CV...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-20 05:08:35,057] Trial 0 finished with value: 0.5514259395725866 and parameters: {'hidden_dim': 45, 'dropout': 0.4551406810921512, 'learning_rate': 0.007331811314274292, 'batch_size': 16, 'weight_decay': 2.064121088592392e-05}. Best is trial 0 with value: 0.5514259395725866.\n",
      "[I 2025-03-20 05:08:55,231] Trial 1 finished with value: 0.5562980800431258 and parameters: {'hidden_dim': 79, 'dropout': 0.48569536770002286, 'learning_rate': 0.003999161563860724, 'batch_size': 32, 'weight_decay': 3.45872269711161e-05}. Best is trial 1 with value: 0.5562980800431258.\n",
      "[I 2025-03-20 05:09:39,936] Trial 2 finished with value: 0.6307403818611373 and parameters: {'hidden_dim': 32, 'dropout': 0.21712375681979076, 'learning_rate': 0.0016665895921660098, 'batch_size': 16, 'weight_decay': 2.1517123363927774e-05}. Best is trial 2 with value: 0.6307403818611373.\n",
      "[I 2025-03-20 05:09:59,959] Trial 3 finished with value: 0.5916698529958232 and parameters: {'hidden_dim': 127, 'dropout': 0.2873081624297713, 'learning_rate': 0.00017643094449433023, 'batch_size': 32, 'weight_decay': 1.0947309020486406e-05}. Best is trial 2 with value: 0.6307403818611373.\n",
      "[I 2025-03-20 05:10:43,948] Trial 4 finished with value: 0.645813877550886 and parameters: {'hidden_dim': 47, 'dropout': 0.10585094112968818, 'learning_rate': 0.0004451295365396247, 'batch_size': 16, 'weight_decay': 1.3639281514957935e-06}. Best is trial 4 with value: 0.645813877550886.\n",
      "[I 2025-03-20 05:10:54,872] Trial 5 finished with value: 0.5741938760250735 and parameters: {'hidden_dim': 59, 'dropout': 0.2875597071705984, 'learning_rate': 0.0033384615669657483, 'batch_size': 64, 'weight_decay': 9.98214837316597e-06}. Best is trial 4 with value: 0.645813877550886.\n",
      "[I 2025-03-20 05:11:35,724] Trial 6 finished with value: 0.624683189472058 and parameters: {'hidden_dim': 109, 'dropout': 0.4586320455614753, 'learning_rate': 0.0009209968619749436, 'batch_size': 16, 'weight_decay': 1.6223673683559225e-06}. Best is trial 4 with value: 0.645813877550886.\n",
      "[I 2025-03-20 05:11:58,817] Trial 7 finished with value: 0.5548638731628672 and parameters: {'hidden_dim': 82, 'dropout': 0.3594032085405511, 'learning_rate': 0.006298297451196278, 'batch_size': 32, 'weight_decay': 7.511737052942637e-05}. Best is trial 4 with value: 0.645813877550886.\n",
      "[I 2025-03-20 05:12:09,534] Trial 8 finished with value: 0.5730062905333316 and parameters: {'hidden_dim': 125, 'dropout': 0.17649687394806254, 'learning_rate': 0.00809174687672524, 'batch_size': 64, 'weight_decay': 5.656354626844694e-06}. Best is trial 4 with value: 0.645813877550886.\n",
      "[I 2025-03-20 05:12:49,987] Trial 9 finished with value: 0.516135470400393 and parameters: {'hidden_dim': 127, 'dropout': 0.3668293205677101, 'learning_rate': 0.009614679235250567, 'batch_size': 16, 'weight_decay': 2.2160868002868673e-05}. Best is trial 4 with value: 0.645813877550886.\n",
      "[I 2025-03-20 05:13:34,361] Trial 10 finished with value: 0.6121982153033142 and parameters: {'hidden_dim': 64, 'dropout': 0.10602595444981365, 'learning_rate': 0.00021457338146118793, 'batch_size': 16, 'weight_decay': 1.6263352971939932e-06}. Best is trial 4 with value: 0.645813877550886.\n",
      "[I 2025-03-20 05:14:15,741] Trial 11 finished with value: 0.6486289535503693 and parameters: {'hidden_dim': 35, 'dropout': 0.16969359886284505, 'learning_rate': 0.000706760286833897, 'batch_size': 16, 'weight_decay': 4.899133576690419e-06}. Best is trial 11 with value: 0.6486289535503693.\n",
      "[I 2025-03-20 05:14:56,740] Trial 12 finished with value: 0.6344082575784621 and parameters: {'hidden_dim': 33, 'dropout': 0.10194648128200001, 'learning_rate': 0.0004983694339427693, 'batch_size': 16, 'weight_decay': 3.460656555538206e-06}. Best is trial 11 with value: 0.6486289535503693.\n",
      "[I 2025-03-20 05:15:41,156] Trial 13 finished with value: 0.6310189414065669 and parameters: {'hidden_dim': 51, 'dropout': 0.1777185492922098, 'learning_rate': 0.000541576996119572, 'batch_size': 16, 'weight_decay': 1.008844643409801e-06}. Best is trial 11 with value: 0.6486289535503693.\n",
      "[I 2025-03-20 05:16:22,284] Trial 14 finished with value: 0.6346683858603637 and parameters: {'hidden_dim': 70, 'dropout': 0.16699119333087606, 'learning_rate': 0.00036615062652768117, 'batch_size': 16, 'weight_decay': 3.462196045065045e-06}. Best is trial 11 with value: 0.6486289535503693.\n",
      "[I 2025-03-20 05:16:33,091] Trial 15 finished with value: 0.6028776258551903 and parameters: {'hidden_dim': 45, 'dropout': 0.2276712380338284, 'learning_rate': 0.0010863059735504415, 'batch_size': 64, 'weight_decay': 3.08987122356275e-06}. Best is trial 11 with value: 0.6486289535503693.\n",
      "[I 2025-03-20 05:17:14,107] Trial 16 finished with value: 0.5867719978455875 and parameters: {'hidden_dim': 92, 'dropout': 0.14158886904771312, 'learning_rate': 0.00010890852337981806, 'batch_size': 16, 'weight_decay': 6.343940532872012e-06}. Best is trial 11 with value: 0.6486289535503693.\n",
      "[I 2025-03-20 05:17:58,540] Trial 17 finished with value: 0.6637201080269978 and parameters: {'hidden_dim': 43, 'dropout': 0.2315407011326211, 'learning_rate': 0.001699588876999364, 'batch_size': 16, 'weight_decay': 1.0228043803162173e-06}. Best is trial 17 with value: 0.6637201080269978.\n",
      "[I 2025-03-20 05:18:18,323] Trial 18 finished with value: 0.5911545407044382 and parameters: {'hidden_dim': 38, 'dropout': 0.2227704837739086, 'learning_rate': 0.0020475377711179775, 'batch_size': 32, 'weight_decay': 2.4392815401084376e-06}. Best is trial 17 with value: 0.6637201080269978.\n",
      "[I 2025-03-20 05:18:32,344] Trial 19 finished with value: 0.587009869865805 and parameters: {'hidden_dim': 55, 'dropout': 0.3337601193345283, 'learning_rate': 0.001037749828275765, 'batch_size': 64, 'weight_decay': 5.7777807335176365e-06}. Best is trial 17 with value: 0.6637201080269978.\n",
      "[I 2025-03-20 05:19:13,302] Trial 20 finished with value: 0.5919452159017226 and parameters: {'hidden_dim': 72, 'dropout': 0.24741716682837878, 'learning_rate': 0.0018811469204442152, 'batch_size': 16, 'weight_decay': 1.0447145537690869e-05}. Best is trial 17 with value: 0.6637201080269978.\n",
      "[I 2025-03-20 05:19:54,401] Trial 21 finished with value: 0.6270813818372166 and parameters: {'hidden_dim': 44, 'dropout': 0.13005148944768452, 'learning_rate': 0.0003344950192525679, 'batch_size': 16, 'weight_decay': 1.2045473680060215e-06}. Best is trial 17 with value: 0.6637201080269978.\n",
      "[I 2025-03-20 05:20:35,559] Trial 22 finished with value: 0.6520466157456289 and parameters: {'hidden_dim': 52, 'dropout': 0.1872378638339699, 'learning_rate': 0.0006751346843032882, 'batch_size': 16, 'weight_decay': 1.9772119294948297e-06}. Best is trial 17 with value: 0.6637201080269978.\n",
      "[I 2025-03-20 05:21:19,992] Trial 23 finished with value: 0.6619806673107635 and parameters: {'hidden_dim': 38, 'dropout': 0.19411596414707713, 'learning_rate': 0.0007051304134400658, 'batch_size': 16, 'weight_decay': 1.881834459682053e-06}. Best is trial 17 with value: 0.6637201080269978.\n",
      "[I 2025-03-20 05:22:01,126] Trial 24 finished with value: 0.65758646796355 and parameters: {'hidden_dim': 59, 'dropout': 0.26721786866734465, 'learning_rate': 0.0014129955133164798, 'batch_size': 16, 'weight_decay': 2.2352689857520247e-06}. Best is trial 17 with value: 0.6637201080269978.\n",
      "[I 2025-03-20 05:22:42,142] Trial 25 finished with value: 0.6057248407506917 and parameters: {'hidden_dim': 62, 'dropout': 0.25250711819449856, 'learning_rate': 0.0031899117287056363, 'batch_size': 16, 'weight_decay': 2.3866263029485008e-06}. Best is trial 17 with value: 0.6637201080269978.\n",
      "[I 2025-03-20 05:23:26,443] Trial 26 finished with value: 0.6460906713358376 and parameters: {'hidden_dim': 39, 'dropout': 0.32407165127011783, 'learning_rate': 0.0013676479823462877, 'batch_size': 16, 'weight_decay': 1.1652018585221186e-06}. Best is trial 17 with value: 0.6637201080269978.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best LSTM Parameters:\n",
      "  hidden_dim: 43\n",
      "  dropout: 0.2315407011326211\n",
      "  learning_rate: 0.001699588876999364\n",
      "  batch_size: 16\n",
      "  weight_decay: 1.0228043803162173e-06\n",
      "\n",
      "Starting k-fold evaluation for all normalization methods\n",
      "\n",
      "Processing fold 1/10\n",
      "Class distribution in fold 1: {1: 90, 0: 63}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 1 - Evaluating methods:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing normalization method: min_max (Fold 1)\n",
      "Created LSTM sequences with lookback=10: 143 train, 145 test\n",
      "Training LSTM model...\n",
      "Epoch 1/30, Loss: 0.6961\n",
      "Epoch 2/30, Loss: 0.6829\n",
      "Epoch 3/30, Loss: 0.6725\n",
      "Epoch 4/30, Loss: 0.6582\n",
      "Epoch 5/30, Loss: 0.6452\n",
      "Epoch 6/30, Loss: 0.6271\n",
      "Epoch 7/30, Loss: 0.6063\n",
      "Epoch 8/30, Loss: 0.5912\n",
      "Epoch 9/30, Loss: 0.6310\n",
      "Epoch 10/30, Loss: 0.5741\n",
      "Epoch 11/30, Loss: 0.5525\n",
      "Epoch 12/30, Loss: 0.5505\n",
      "Epoch 13/30, Loss: 0.5036\n",
      "Epoch 14/30, Loss: 0.4967\n",
      "Epoch 15/30, Loss: 0.5549\n",
      "Epoch 16/30, Loss: 0.4663\n",
      "Epoch 17/30, Loss: 0.4770\n",
      "Epoch 18/30, Loss: 0.4755\n",
      "Epoch 19/30, Loss: 0.5074\n",
      "Epoch 20/30, Loss: 0.5549\n",
      "Epoch 21/30, Loss: 0.4389\n",
      "Epoch 22/30, Loss: 0.4567\n",
      "Epoch 23/30, Loss: 0.4263\n",
      "Epoch 24/30, Loss: 0.3965\n",
      "Epoch 25/30, Loss: 0.4042\n",
      "Epoch 26/30, Loss: 0.3956\n",
      "Epoch 27/30, Loss: 0.3700\n",
      "Epoch 28/30, Loss: 0.3431\n",
      "Epoch 29/30, Loss: 0.3567\n",
      "Epoch 30/30, Loss: 0.3732\n",
      "Evaluating models...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 1 - Evaluating methods:  20%|        | 1/5 [00:00<00:02,  1.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully aligned predictions with 10 NaN padding values\n",
      "LSTM - Accuracy: 0.5034, F1: 0.5000, ROC AUC: 0.5103\n",
      "LightGBM - Accuracy: 0.5484, F1: 0.5977, ROC AUC: 0.5899\n",
      "\n",
      "Testing normalization method: z_score (Fold 1)\n",
      "Created LSTM sequences with lookback=10: 143 train, 145 test\n",
      "Training LSTM model...\n",
      "Epoch 1/30, Loss: 0.6848\n",
      "Epoch 2/30, Loss: 0.6584\n",
      "Epoch 3/30, Loss: 0.5995\n",
      "Epoch 4/30, Loss: 0.5404\n",
      "Epoch 5/30, Loss: 0.4602\n",
      "Epoch 6/30, Loss: 0.4264\n",
      "Epoch 7/30, Loss: 0.3853\n",
      "Epoch 8/30, Loss: 0.3601\n",
      "Epoch 9/30, Loss: 0.2828\n",
      "Epoch 10/30, Loss: 0.2170\n",
      "Epoch 11/30, Loss: 0.2609\n",
      "Epoch 12/30, Loss: 0.2357\n",
      "Epoch 13/30, Loss: 0.2502\n",
      "Epoch 14/30, Loss: 0.1812\n",
      "Epoch 15/30, Loss: 0.1844\n",
      "Epoch 16/30, Loss: 0.1677\n",
      "Epoch 17/30, Loss: 0.1677\n",
      "Epoch 18/30, Loss: 0.1180\n",
      "Epoch 19/30, Loss: 0.1445\n",
      "Epoch 20/30, Loss: 0.1000\n",
      "Epoch 21/30, Loss: 0.0958\n",
      "Epoch 22/30, Loss: 0.0969\n",
      "Epoch 23/30, Loss: 0.0893\n",
      "Epoch 24/30, Loss: 0.0774\n",
      "Epoch 25/30, Loss: 0.0843\n",
      "Epoch 26/30, Loss: 0.0643\n",
      "Epoch 27/30, Loss: 0.0421\n",
      "Epoch 28/30, Loss: 0.0636\n",
      "Epoch 29/30, Loss: 0.0484\n",
      "Epoch 30/30, Loss: 0.0301\n",
      "Evaluating models...\n",
      "Successfully aligned predictions with 10 NaN padding values\n",
      "LSTM - Accuracy: 0.5172, F1: 0.4167, ROC AUC: 0.5705\n",
      "LightGBM - Accuracy: 0.5548, F1: 0.6012, ROC AUC: 0.6015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 1 - Evaluating methods:  40%|      | 2/5 [00:01<00:01,  1.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing normalization method: median (Fold 1)\n",
      "Created LSTM sequences with lookback=10: 143 train, 145 test\n",
      "Training LSTM model...\n",
      "Epoch 1/30, Loss: 0.6911\n",
      "Epoch 2/30, Loss: 0.6752\n",
      "Epoch 3/30, Loss: 0.6315\n",
      "Epoch 4/30, Loss: 0.5833\n",
      "Epoch 5/30, Loss: 0.5194\n",
      "Epoch 6/30, Loss: 0.4289\n",
      "Epoch 7/30, Loss: 0.3729\n",
      "Epoch 8/30, Loss: 0.3034\n",
      "Epoch 9/30, Loss: 0.1911\n",
      "Epoch 10/30, Loss: 0.1892\n",
      "Epoch 11/30, Loss: 0.1871\n",
      "Epoch 12/30, Loss: 0.1644\n",
      "Epoch 13/30, Loss: 0.1091\n",
      "Epoch 14/30, Loss: 0.1692\n",
      "Epoch 15/30, Loss: 0.0803\n",
      "Epoch 16/30, Loss: 0.1807\n",
      "Epoch 17/30, Loss: 0.1223\n",
      "Epoch 18/30, Loss: 0.0611\n",
      "Epoch 19/30, Loss: 0.0891\n",
      "Epoch 20/30, Loss: 0.0473\n",
      "Epoch 21/30, Loss: 0.1257\n",
      "Epoch 22/30, Loss: 0.0488\n",
      "Epoch 23/30, Loss: 0.1085\n",
      "Epoch 24/30, Loss: 0.0815\n",
      "Epoch 25/30, Loss: 0.0366\n",
      "Epoch 26/30, Loss: 0.0695\n",
      "Epoch 27/30, Loss: 0.0231\n",
      "Epoch 28/30, Loss: 0.0242\n",
      "Epoch 29/30, Loss: 0.0695\n",
      "Epoch 30/30, Loss: 0.0375\n",
      "Evaluating models...\n",
      "Successfully aligned predictions with 10 NaN padding values\n",
      "LSTM - Accuracy: 0.4621, F1: 0.4179, ROC AUC: 0.4482\n",
      "LightGBM - Accuracy: 0.5290, F1: 0.5876, ROC AUC: 0.6025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 1 - Evaluating methods:  60%|    | 3/5 [00:01<00:01,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing normalization method: sigmoid (Fold 1)\n",
      "Created LSTM sequences with lookback=10: 143 train, 145 test\n",
      "Training LSTM model...\n",
      "Epoch 1/30, Loss: 0.6905\n",
      "Epoch 2/30, Loss: 0.6878\n",
      "Epoch 3/30, Loss: 0.6853\n",
      "Epoch 4/30, Loss: 0.6845\n",
      "Epoch 5/30, Loss: 0.6864\n",
      "Epoch 6/30, Loss: 0.6897\n",
      "Epoch 7/30, Loss: 0.6880\n",
      "Epoch 8/30, Loss: 0.6882\n",
      "Epoch 9/30, Loss: 0.6829\n",
      "Epoch 10/30, Loss: 0.6761\n",
      "Epoch 11/30, Loss: 0.6930\n",
      "Epoch 12/30, Loss: 0.6789\n",
      "Epoch 13/30, Loss: 0.6881\n",
      "Epoch 14/30, Loss: 0.6855\n",
      "Epoch 15/30, Loss: 0.6802\n",
      "Epoch 16/30, Loss: 0.6581\n",
      "Epoch 17/30, Loss: 0.6353\n",
      "Epoch 18/30, Loss: 0.8431\n",
      "Epoch 19/30, Loss: 0.6660\n",
      "Epoch 20/30, Loss: 0.6667\n",
      "Epoch 21/30, Loss: 0.6536\n",
      "Epoch 22/30, Loss: 0.6473\n",
      "Epoch 23/30, Loss: 0.6530\n",
      "Epoch 24/30, Loss: 0.6690\n",
      "Epoch 25/30, Loss: 0.6832\n",
      "Epoch 26/30, Loss: 0.6927\n",
      "Epoch 27/30, Loss: 0.6872\n",
      "Early stopping at epoch 27\n",
      "Evaluating models...\n",
      "Successfully aligned predictions with 10 NaN padding values\n",
      "LSTM - Accuracy: 0.5172, F1: 0.6818, ROC AUC: 0.4581\n",
      "LightGBM - Accuracy: 0.5677, F1: 0.6528, ROC AUC: 0.5971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 1 - Evaluating methods:  80%|  | 4/5 [00:01<00:00,  2.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing normalization method: tanh_estimator (Fold 1)\n",
      "Created LSTM sequences with lookback=10: 143 train, 145 test\n",
      "Training LSTM model...\n",
      "Epoch 1/30, Loss: 0.6925\n",
      "Epoch 2/30, Loss: 0.6870\n",
      "Epoch 3/30, Loss: 0.6882\n",
      "Epoch 4/30, Loss: 0.6813\n",
      "Epoch 5/30, Loss: 0.6820\n",
      "Epoch 6/30, Loss: 0.6804\n",
      "Epoch 7/30, Loss: 0.7105\n",
      "Epoch 8/30, Loss: 0.6949\n",
      "Epoch 9/30, Loss: 0.6790\n",
      "Epoch 10/30, Loss: 0.6850\n",
      "Epoch 11/30, Loss: 0.6911\n",
      "Epoch 12/30, Loss: 0.6834\n",
      "Epoch 13/30, Loss: 0.6861\n",
      "Epoch 14/30, Loss: 0.6784\n",
      "Epoch 15/30, Loss: 0.6865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 1 - Evaluating methods: 100%|| 5/5 [00:02<00:00,  2.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/30, Loss: 0.6882\n",
      "Epoch 17/30, Loss: 0.6843\n",
      "Epoch 18/30, Loss: 0.6870\n",
      "Epoch 19/30, Loss: 0.6866\n",
      "Epoch 20/30, Loss: 0.6834\n",
      "Epoch 21/30, Loss: 0.6841\n",
      "Epoch 22/30, Loss: 0.6872\n",
      "Epoch 23/30, Loss: 0.6785\n",
      "Epoch 24/30, Loss: 0.6807\n",
      "Early stopping at epoch 24\n",
      "Evaluating models...\n",
      "Successfully aligned predictions with 10 NaN padding values\n",
      "LSTM - Accuracy: 0.5172, F1: 0.6818, ROC AUC: 0.4196\n",
      "LightGBM - Accuracy: 0.5419, F1: 0.5943, ROC AUC: 0.5968\n",
      "\n",
      "Processing fold 2/10\n",
      "Class distribution in fold 2: {1: 178, 0: 130}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 2 - Evaluating methods:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing normalization method: min_max (Fold 2)\n",
      "Created LSTM sequences with lookback=10: 298 train, 145 test\n",
      "Training LSTM model...\n",
      "Epoch 1/30, Loss: 0.6871\n",
      "Epoch 2/30, Loss: 0.6788\n",
      "Epoch 3/30, Loss: 0.6756\n",
      "Epoch 4/30, Loss: 0.6786\n",
      "Epoch 5/30, Loss: 0.6657\n",
      "Epoch 6/30, Loss: 0.6683\n",
      "Epoch 7/30, Loss: 0.6606\n",
      "Epoch 8/30, Loss: 0.6567\n",
      "Epoch 9/30, Loss: 0.6445\n",
      "Epoch 10/30, Loss: 0.6368\n",
      "Epoch 11/30, Loss: 0.6354\n",
      "Epoch 12/30, Loss: 0.6372\n",
      "Epoch 13/30, Loss: 0.6231\n",
      "Epoch 14/30, Loss: 0.6031\n",
      "Epoch 15/30, Loss: 0.5975\n",
      "Epoch 16/30, Loss: 0.5962\n",
      "Epoch 17/30, Loss: 0.5669\n",
      "Epoch 18/30, Loss: 0.5658\n",
      "Epoch 19/30, Loss: 0.5551\n",
      "Epoch 20/30, Loss: 0.5538\n",
      "Epoch 21/30, Loss: 0.5326\n",
      "Epoch 22/30, Loss: 0.5377\n",
      "Epoch 23/30, Loss: 0.5062\n",
      "Epoch 24/30, Loss: 0.5047\n",
      "Epoch 25/30, Loss: 0.4697\n",
      "Epoch 26/30, Loss: 0.4786\n",
      "Epoch 27/30, Loss: 0.4807\n",
      "Epoch 28/30, Loss: 0.4963\n",
      "Epoch 29/30, Loss: 0.4899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 2 - Evaluating methods:  20%|        | 1/5 [00:01<00:05,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/30, Loss: 0.4903\n",
      "Evaluating models...\n",
      "Successfully aligned predictions with 10 NaN padding values\n",
      "LSTM - Accuracy: 0.6000, F1: 0.7500, ROC AUC: 0.5151\n",
      "LightGBM - Accuracy: 0.6387, F1: 0.7200, ROC AUC: 0.5872\n",
      "\n",
      "Testing normalization method: z_score (Fold 2)\n",
      "Created LSTM sequences with lookback=10: 298 train, 145 test\n",
      "Training LSTM model...\n",
      "Epoch 1/30, Loss: 0.6868\n",
      "Epoch 2/30, Loss: 0.6672\n",
      "Epoch 3/30, Loss: 0.6353\n",
      "Epoch 4/30, Loss: 0.6017\n",
      "Epoch 5/30, Loss: 0.5747\n",
      "Epoch 6/30, Loss: 0.5305\n",
      "Epoch 7/30, Loss: 0.4826\n",
      "Epoch 8/30, Loss: 0.4473\n",
      "Epoch 9/30, Loss: 0.4153\n",
      "Epoch 10/30, Loss: 0.3665\n",
      "Epoch 11/30, Loss: 0.3348\n",
      "Epoch 12/30, Loss: 0.3316\n",
      "Epoch 13/30, Loss: 0.3178\n",
      "Epoch 14/30, Loss: 0.3060\n",
      "Epoch 15/30, Loss: 0.2855\n",
      "Epoch 16/30, Loss: 0.2656\n",
      "Epoch 17/30, Loss: 0.2587\n",
      "Epoch 18/30, Loss: 0.2490\n",
      "Epoch 19/30, Loss: 0.2309\n",
      "Epoch 20/30, Loss: 0.2281\n",
      "Epoch 21/30, Loss: 0.2108\n",
      "Epoch 22/30, Loss: 0.2113\n",
      "Epoch 23/30, Loss: 0.2158\n",
      "Epoch 24/30, Loss: 0.1645\n",
      "Epoch 25/30, Loss: 0.1444\n",
      "Epoch 26/30, Loss: 0.1534\n",
      "Epoch 27/30, Loss: 0.1385\n",
      "Epoch 28/30, Loss: 0.1278\n",
      "Epoch 29/30, Loss: 0.1161\n",
      "Epoch 30/30, Loss: 0.1127\n",
      "Evaluating models...\n",
      "Successfully aligned predictions with 10 NaN padding values\n",
      "LSTM - Accuracy: 0.5724, F1: 0.6737, ROC AUC: 0.5331\n",
      "LightGBM - Accuracy: 0.6000, F1: 0.6869, ROC AUC: 0.5685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 2 - Evaluating methods:  40%|      | 2/5 [00:02<00:03,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing normalization method: median (Fold 2)\n",
      "Created LSTM sequences with lookback=10: 298 train, 145 test\n",
      "Training LSTM model...\n",
      "Epoch 1/30, Loss: 0.6946\n",
      "Epoch 2/30, Loss: 0.6506\n",
      "Epoch 3/30, Loss: 0.6190\n",
      "Epoch 4/30, Loss: 0.5724\n",
      "Epoch 5/30, Loss: 0.5082\n",
      "Epoch 6/30, Loss: 0.4670\n",
      "Epoch 7/30, Loss: 0.3679\n",
      "Epoch 8/30, Loss: 0.3157\n",
      "Epoch 9/30, Loss: 0.2726\n",
      "Epoch 10/30, Loss: 0.2442\n",
      "Epoch 11/30, Loss: 0.2283\n",
      "Epoch 12/30, Loss: 0.1760\n",
      "Epoch 13/30, Loss: 0.1606\n",
      "Epoch 14/30, Loss: 0.1240\n",
      "Epoch 15/30, Loss: 0.1106\n",
      "Epoch 16/30, Loss: 0.1143\n",
      "Epoch 17/30, Loss: 0.0896\n",
      "Epoch 18/30, Loss: 0.0891\n",
      "Epoch 19/30, Loss: 0.0790\n",
      "Epoch 20/30, Loss: 0.0761\n",
      "Epoch 21/30, Loss: 0.0552\n",
      "Epoch 22/30, Loss: 0.0578\n",
      "Epoch 23/30, Loss: 0.0678\n",
      "Epoch 24/30, Loss: 0.0505\n",
      "Epoch 25/30, Loss: 0.0339\n",
      "Epoch 26/30, Loss: 0.0334\n",
      "Epoch 27/30, Loss: 0.0396\n",
      "Epoch 28/30, Loss: 0.0474\n",
      "Epoch 29/30, Loss: 0.0414\n",
      "Epoch 30/30, Loss: 0.0373\n",
      "Evaluating models...\n",
      "Successfully aligned predictions with 10 NaN padding values\n",
      "LSTM - Accuracy: 0.5034, F1: 0.5000, ROC AUC: 0.4857\n",
      "LightGBM - Accuracy: 0.6387, F1: 0.7200, ROC AUC: 0.5921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 2 - Evaluating methods:  60%|    | 3/5 [00:03<00:02,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing normalization method: sigmoid (Fold 2)\n",
      "Created LSTM sequences with lookback=10: 298 train, 145 test\n",
      "Training LSTM model...\n",
      "Epoch 1/30, Loss: 0.6890\n",
      "Epoch 2/30, Loss: 0.6859\n",
      "Epoch 3/30, Loss: 0.6841\n",
      "Epoch 4/30, Loss: 0.6861\n",
      "Epoch 5/30, Loss: 0.6865\n",
      "Epoch 6/30, Loss: 0.6830\n",
      "Epoch 7/30, Loss: 0.6886\n",
      "Epoch 8/30, Loss: 0.6847\n",
      "Epoch 9/30, Loss: 0.6821\n",
      "Epoch 10/30, Loss: 0.6845\n",
      "Epoch 11/30, Loss: 0.6775\n",
      "Epoch 12/30, Loss: 0.6763\n",
      "Epoch 13/30, Loss: 0.6621\n",
      "Epoch 14/30, Loss: 0.6714\n",
      "Epoch 15/30, Loss: 0.6775\n",
      "Epoch 16/30, Loss: 0.6650\n",
      "Epoch 17/30, Loss: 0.6732\n",
      "Epoch 18/30, Loss: 0.6626\n",
      "Epoch 19/30, Loss: 0.6614\n",
      "Epoch 20/30, Loss: 0.6615\n",
      "Epoch 21/30, Loss: 0.6753\n",
      "Epoch 22/30, Loss: 0.6731\n",
      "Epoch 23/30, Loss: 0.6627\n",
      "Epoch 24/30, Loss: 0.6572\n",
      "Epoch 25/30, Loss: 0.6615\n",
      "Epoch 26/30, Loss: 0.6661\n",
      "Epoch 27/30, Loss: 0.6622\n",
      "Epoch 28/30, Loss: 0.6534\n",
      "Epoch 29/30, Loss: 0.6550\n",
      "Epoch 30/30, Loss: 0.6891\n",
      "Evaluating models...\n",
      "Successfully aligned predictions with 10 NaN padding values\n",
      "LSTM - Accuracy: 0.4897, F1: 0.6022, ROC AUC: 0.4800\n",
      "LightGBM - Accuracy: 0.5806, F1: 0.6597, ROC AUC: 0.5872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 2 - Evaluating methods:  80%|  | 4/5 [00:05<00:01,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing normalization method: tanh_estimator (Fold 2)\n",
      "Created LSTM sequences with lookback=10: 298 train, 145 test\n",
      "Training LSTM model...\n",
      "Epoch 1/30, Loss: 0.6868\n",
      "Epoch 2/30, Loss: 0.6844\n",
      "Epoch 3/30, Loss: 0.6856\n",
      "Epoch 4/30, Loss: 0.6854\n",
      "Epoch 5/30, Loss: 0.6852\n",
      "Epoch 6/30, Loss: 0.6873\n",
      "Epoch 7/30, Loss: 0.6855\n",
      "Epoch 8/30, Loss: 0.6831\n",
      "Epoch 9/30, Loss: 0.6835\n",
      "Epoch 10/30, Loss: 0.6874\n",
      "Epoch 11/30, Loss: 0.6826\n",
      "Epoch 12/30, Loss: 0.6861\n",
      "Epoch 13/30, Loss: 0.6846\n",
      "Epoch 14/30, Loss: 0.6865\n",
      "Epoch 15/30, Loss: 0.6856\n",
      "Epoch 16/30, Loss: 0.6851\n",
      "Epoch 17/30, Loss: 0.6845\n",
      "Epoch 18/30, Loss: 0.6839\n",
      "Epoch 19/30, Loss: 0.6848\n",
      "Epoch 20/30, Loss: 0.6867\n",
      "Epoch 21/30, Loss: 0.6834\n",
      "Early stopping at epoch 21\n",
      "Evaluating models...\n",
      "Successfully aligned predictions with 10 NaN padding values\n",
      "LSTM - Accuracy: 0.6000, F1: 0.7500, ROC AUC: 0.5309\n",
      "LightGBM - Accuracy: 0.6387, F1: 0.7200, ROC AUC: 0.5872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 2 - Evaluating methods: 100%|| 5/5 [00:06<00:00,  1.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing fold 3/10\n",
      "Class distribution in fold 3: {1: 267, 0: 196}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 3 - Evaluating methods:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing normalization method: min_max (Fold 3)\n",
      "Created LSTM sequences with lookback=10: 453 train, 145 test\n",
      "Training LSTM model...\n",
      "Epoch 1/30, Loss: 0.6915\n",
      "Epoch 2/30, Loss: 0.6856\n",
      "Epoch 3/30, Loss: 0.6876\n",
      "Epoch 4/30, Loss: 0.6810\n",
      "Epoch 5/30, Loss: 0.6785\n",
      "Epoch 6/30, Loss: 0.6847\n",
      "Epoch 7/30, Loss: 0.6731\n",
      "Epoch 8/30, Loss: 0.6692\n",
      "Epoch 9/30, Loss: 0.6748\n",
      "Epoch 10/30, Loss: 0.6747\n",
      "Epoch 11/30, Loss: 0.6687\n",
      "Epoch 12/30, Loss: 0.6640\n",
      "Epoch 13/30, Loss: 0.6579\n",
      "Epoch 14/30, Loss: 0.6605\n",
      "Epoch 15/30, Loss: 0.6645\n",
      "Epoch 16/30, Loss: 0.6495\n",
      "Epoch 17/30, Loss: 0.6649\n",
      "Epoch 18/30, Loss: 0.6523\n",
      "Epoch 19/30, Loss: 0.6441\n",
      "Epoch 20/30, Loss: 0.6624\n",
      "Epoch 21/30, Loss: 0.6523\n",
      "Epoch 22/30, Loss: 0.6429\n",
      "Epoch 23/30, Loss: 0.6247\n",
      "Epoch 24/30, Loss: 0.6368\n",
      "Epoch 25/30, Loss: 0.6365\n",
      "Epoch 26/30, Loss: 0.6723\n",
      "Epoch 27/30, Loss: 0.6345\n",
      "Epoch 28/30, Loss: 0.6602\n",
      "Epoch 29/30, Loss: 0.6449\n",
      "Epoch 30/30, Loss: 0.6490\n",
      "Evaluating models...\n",
      "Successfully aligned predictions with 10 NaN padding values\n",
      "LSTM - Accuracy: 0.5448, F1: 0.7054, ROC AUC: 0.6600\n",
      "LightGBM - Accuracy: 0.5419, F1: 0.6502, ROC AUC: 0.4825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 3 - Evaluating methods:  20%|        | 1/5 [00:01<00:04,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing normalization method: z_score (Fold 3)\n",
      "Created LSTM sequences with lookback=10: 453 train, 145 test\n",
      "Training LSTM model...\n",
      "Epoch 1/30, Loss: 0.6923\n",
      "Epoch 2/30, Loss: 0.6594\n",
      "Epoch 3/30, Loss: 0.6398\n",
      "Epoch 4/30, Loss: 0.6149\n",
      "Epoch 5/30, Loss: 0.5871\n",
      "Epoch 6/30, Loss: 0.5678\n",
      "Epoch 7/30, Loss: 0.5304\n",
      "Epoch 8/30, Loss: 0.5097\n",
      "Epoch 9/30, Loss: 0.4821\n",
      "Epoch 10/30, Loss: 0.4320\n",
      "Epoch 11/30, Loss: 0.3787\n",
      "Epoch 12/30, Loss: 0.3532\n",
      "Epoch 13/30, Loss: 0.3089\n",
      "Epoch 14/30, Loss: 0.2899\n",
      "Epoch 15/30, Loss: 0.2787\n",
      "Epoch 16/30, Loss: 0.2213\n",
      "Epoch 17/30, Loss: 0.2018\n",
      "Epoch 18/30, Loss: 0.1748\n",
      "Epoch 19/30, Loss: 0.1584\n",
      "Epoch 20/30, Loss: 0.1343\n",
      "Epoch 21/30, Loss: 0.1381\n",
      "Epoch 22/30, Loss: 0.1332\n",
      "Epoch 23/30, Loss: 0.1240\n",
      "Epoch 24/30, Loss: 0.1062\n",
      "Epoch 25/30, Loss: 0.0840\n",
      "Epoch 26/30, Loss: 0.1005\n",
      "Epoch 27/30, Loss: 0.1237\n",
      "Epoch 28/30, Loss: 0.1058\n",
      "Epoch 29/30, Loss: 0.0634\n",
      "Epoch 30/30, Loss: 0.0703\n",
      "Evaluating models...\n",
      "Successfully aligned predictions with 10 NaN padding values\n",
      "LSTM - Accuracy: 0.4897, F1: 0.6337, ROC AUC: 0.5256\n",
      "LightGBM - Accuracy: 0.5548, F1: 0.6761, ROC AUC: 0.4645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 3 - Evaluating methods:  40%|      | 2/5 [00:02<00:03,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing normalization method: median (Fold 3)\n",
      "Created LSTM sequences with lookback=10: 453 train, 145 test\n",
      "Training LSTM model...\n",
      "Epoch 1/30, Loss: 0.6891\n",
      "Epoch 2/30, Loss: 0.6609\n",
      "Epoch 3/30, Loss: 0.6339\n",
      "Epoch 4/30, Loss: 0.6311\n",
      "Epoch 5/30, Loss: 0.5566\n",
      "Epoch 6/30, Loss: 0.5007\n",
      "Epoch 7/30, Loss: 0.4085\n",
      "Epoch 8/30, Loss: 0.3617\n",
      "Epoch 9/30, Loss: 0.3182\n",
      "Epoch 10/30, Loss: 0.2549\n",
      "Epoch 11/30, Loss: 0.1988\n",
      "Epoch 12/30, Loss: 0.1869\n",
      "Epoch 13/30, Loss: 0.1372\n",
      "Epoch 14/30, Loss: 0.1356\n",
      "Epoch 15/30, Loss: 0.0908\n",
      "Epoch 16/30, Loss: 0.0970\n",
      "Epoch 17/30, Loss: 0.0822\n",
      "Epoch 18/30, Loss: 0.0477\n",
      "Epoch 19/30, Loss: 0.0352\n",
      "Epoch 20/30, Loss: 0.0301\n",
      "Epoch 21/30, Loss: 0.0452\n",
      "Epoch 22/30, Loss: 0.0344\n",
      "Epoch 23/30, Loss: 0.0281\n",
      "Epoch 24/30, Loss: 0.0360\n",
      "Epoch 25/30, Loss: 0.0127\n",
      "Epoch 26/30, Loss: 0.0163\n",
      "Epoch 27/30, Loss: 0.0262\n",
      "Epoch 28/30, Loss: 0.0157\n",
      "Epoch 29/30, Loss: 0.0096\n",
      "Epoch 30/30, Loss: 0.0114\n",
      "Evaluating models...\n",
      "Successfully aligned predictions with 10 NaN padding values\n",
      "LSTM - Accuracy: 0.5586, F1: 0.6404, ROC AUC: 0.5565\n",
      "LightGBM - Accuracy: 0.5097, F1: 0.6122, ROC AUC: 0.4612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 3 - Evaluating methods:  60%|    | 3/5 [00:03<00:02,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing normalization method: sigmoid (Fold 3)\n",
      "Created LSTM sequences with lookback=10: 453 train, 145 test\n",
      "Training LSTM model...\n",
      "Epoch 1/30, Loss: 0.6817\n",
      "Epoch 2/30, Loss: 0.6902\n",
      "Epoch 3/30, Loss: 0.6830\n",
      "Epoch 4/30, Loss: 0.6871\n",
      "Epoch 5/30, Loss: 0.6817\n",
      "Epoch 6/30, Loss: 0.6898\n",
      "Epoch 7/30, Loss: 0.6799\n",
      "Epoch 8/30, Loss: 0.6822\n",
      "Epoch 9/30, Loss: 0.6864\n",
      "Epoch 10/30, Loss: 0.6804\n",
      "Epoch 11/30, Loss: 0.6814\n",
      "Epoch 12/30, Loss: 0.6832\n",
      "Epoch 13/30, Loss: 0.6842\n",
      "Epoch 14/30, Loss: 0.6796\n",
      "Epoch 15/30, Loss: 0.6739\n",
      "Epoch 16/30, Loss: 0.6742\n",
      "Epoch 17/30, Loss: 0.6833\n",
      "Epoch 18/30, Loss: 0.6827\n",
      "Epoch 19/30, Loss: 0.6890\n",
      "Epoch 20/30, Loss: 0.6790\n",
      "Epoch 21/30, Loss: 0.6819\n",
      "Epoch 22/30, Loss: 0.6871\n",
      "Epoch 23/30, Loss: 0.6809\n",
      "Epoch 24/30, Loss: 0.6803\n",
      "Epoch 25/30, Loss: 0.6845\n",
      "Early stopping at epoch 25\n",
      "Evaluating models...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 3 - Evaluating methods:  80%|  | 4/5 [00:04<00:01,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully aligned predictions with 10 NaN padding values\n",
      "LSTM - Accuracy: 0.5448, F1: 0.7054, ROC AUC: 0.5222\n",
      "LightGBM - Accuracy: 0.5677, F1: 0.6700, ROC AUC: 0.5062\n",
      "\n",
      "Testing normalization method: tanh_estimator (Fold 3)\n",
      "Created LSTM sequences with lookback=10: 453 train, 145 test\n",
      "Training LSTM model...\n",
      "Epoch 1/30, Loss: 0.6874\n",
      "Epoch 2/30, Loss: 0.6888\n",
      "Epoch 3/30, Loss: 0.6828\n",
      "Epoch 4/30, Loss: 0.6814\n",
      "Epoch 5/30, Loss: 0.6762\n",
      "Epoch 6/30, Loss: 0.6830\n",
      "Epoch 7/30, Loss: 0.6876\n",
      "Epoch 8/30, Loss: 0.6866\n",
      "Epoch 9/30, Loss: 0.6843\n",
      "Epoch 10/30, Loss: 0.6892\n",
      "Epoch 11/30, Loss: 0.6860\n",
      "Epoch 12/30, Loss: 0.6861\n",
      "Epoch 13/30, Loss: 0.6834\n",
      "Epoch 14/30, Loss: 0.6835\n",
      "Epoch 15/30, Loss: 0.6786\n",
      "Early stopping at epoch 15\n",
      "Evaluating models...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 3 - Evaluating methods: 100%|| 5/5 [00:05<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully aligned predictions with 10 NaN padding values\n",
      "LSTM - Accuracy: 0.5448, F1: 0.7054, ROC AUC: 0.6066\n",
      "LightGBM - Accuracy: 0.5097, F1: 0.6162, ROC AUC: 0.4566\n",
      "\n",
      "Processing fold 4/10\n",
      "Class distribution in fold 4: {1: 355, 0: 263}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 4 - Evaluating methods:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing normalization method: min_max (Fold 4)\n",
      "Created LSTM sequences with lookback=10: 608 train, 145 test\n",
      "Training LSTM model...\n",
      "Epoch 1/30, Loss: 0.6882\n",
      "Epoch 2/30, Loss: 0.6823\n",
      "Epoch 3/30, Loss: 0.6793\n",
      "Epoch 4/30, Loss: 0.6747\n",
      "Epoch 5/30, Loss: 0.6803\n",
      "Epoch 6/30, Loss: 0.6700\n",
      "Epoch 7/30, Loss: 0.6727\n",
      "Epoch 8/30, Loss: 0.6694\n",
      "Epoch 9/30, Loss: 0.6716\n",
      "Epoch 10/30, Loss: 0.6664\n",
      "Epoch 11/30, Loss: 0.6668\n",
      "Epoch 12/30, Loss: 0.6724\n",
      "Epoch 13/30, Loss: 0.6655\n",
      "Epoch 14/30, Loss: 0.6630\n",
      "Epoch 15/30, Loss: 0.6652\n",
      "Epoch 16/30, Loss: 0.6620\n",
      "Epoch 17/30, Loss: 0.6574\n",
      "Epoch 18/30, Loss: 0.6654\n",
      "Epoch 19/30, Loss: 0.6539\n",
      "Epoch 20/30, Loss: 0.6597\n",
      "Epoch 21/30, Loss: 0.6517\n",
      "Epoch 22/30, Loss: 0.6499\n",
      "Epoch 23/30, Loss: 0.6420\n",
      "Epoch 24/30, Loss: 0.6576\n",
      "Epoch 25/30, Loss: 0.6415\n",
      "Epoch 26/30, Loss: 0.6381\n",
      "Epoch 27/30, Loss: 0.6353\n",
      "Epoch 28/30, Loss: 0.6486\n",
      "Epoch 29/30, Loss: 0.6619\n",
      "Epoch 30/30, Loss: 0.6397\n",
      "Evaluating models...\n",
      "Successfully aligned predictions with 10 NaN padding values\n",
      "LSTM - Accuracy: 0.6690, F1: 0.7818, ROC AUC: 0.6377\n",
      "LightGBM - Accuracy: 0.4581, F1: 0.4474, ROC AUC: 0.4918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 4 - Evaluating methods:  20%|        | 1/5 [00:01<00:05,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing normalization method: z_score (Fold 4)\n",
      "Created LSTM sequences with lookback=10: 608 train, 145 test\n",
      "Training LSTM model...\n",
      "Epoch 1/30, Loss: 0.6902\n",
      "Epoch 2/30, Loss: 0.6651\n",
      "Epoch 3/30, Loss: 0.6418\n",
      "Epoch 4/30, Loss: 0.6290\n",
      "Epoch 5/30, Loss: 0.6073\n",
      "Epoch 6/30, Loss: 0.5924\n",
      "Epoch 7/30, Loss: 0.5724\n",
      "Epoch 8/30, Loss: 0.5585\n",
      "Epoch 9/30, Loss: 0.5499\n",
      "Epoch 10/30, Loss: 0.5212\n",
      "Epoch 11/30, Loss: 0.4997\n",
      "Epoch 12/30, Loss: 0.4692\n",
      "Epoch 13/30, Loss: 0.4386\n",
      "Epoch 14/30, Loss: 0.4154\n",
      "Epoch 15/30, Loss: 0.3636\n",
      "Epoch 16/30, Loss: 0.3460\n",
      "Epoch 17/30, Loss: 0.3234\n",
      "Epoch 18/30, Loss: 0.3096\n",
      "Epoch 19/30, Loss: 0.2968\n",
      "Epoch 20/30, Loss: 0.2888\n",
      "Epoch 21/30, Loss: 0.2620\n",
      "Epoch 22/30, Loss: 0.2292\n",
      "Epoch 23/30, Loss: 0.2051\n",
      "Epoch 24/30, Loss: 0.1912\n",
      "Epoch 25/30, Loss: 0.1906\n",
      "Epoch 26/30, Loss: 0.1699\n",
      "Epoch 27/30, Loss: 0.1994\n",
      "Epoch 28/30, Loss: 0.1545\n",
      "Epoch 29/30, Loss: 0.1845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 4 - Evaluating methods:  40%|      | 2/5 [00:02<00:04,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/30, Loss: 0.1410\n",
      "Evaluating models...\n",
      "Successfully aligned predictions with 10 NaN padding values\n",
      "LSTM - Accuracy: 0.6138, F1: 0.7455, ROC AUC: 0.4945\n",
      "LightGBM - Accuracy: 0.4581, F1: 0.4474, ROC AUC: 0.4971\n",
      "\n",
      "Testing normalization method: median (Fold 4)\n",
      "Created LSTM sequences with lookback=10: 608 train, 145 test\n",
      "Training LSTM model...\n",
      "Epoch 1/30, Loss: 0.6845\n",
      "Epoch 2/30, Loss: 0.6611\n",
      "Epoch 3/30, Loss: 0.6312\n",
      "Epoch 4/30, Loss: 0.6001\n",
      "Epoch 5/30, Loss: 0.5354\n",
      "Epoch 6/30, Loss: 0.4841\n",
      "Epoch 7/30, Loss: 0.3972\n",
      "Epoch 8/30, Loss: 0.3452\n",
      "Epoch 9/30, Loss: 0.3235\n",
      "Epoch 10/30, Loss: 0.2480\n",
      "Epoch 11/30, Loss: 0.2152\n",
      "Epoch 12/30, Loss: 0.1763\n",
      "Epoch 13/30, Loss: 0.2001\n",
      "Epoch 14/30, Loss: 0.1609\n",
      "Epoch 15/30, Loss: 0.1401\n",
      "Epoch 16/30, Loss: 0.1101\n",
      "Epoch 17/30, Loss: 0.1002\n",
      "Epoch 18/30, Loss: 0.0693\n",
      "Epoch 19/30, Loss: 0.0560\n",
      "Epoch 20/30, Loss: 0.0464\n",
      "Epoch 21/30, Loss: 0.0448\n",
      "Epoch 22/30, Loss: 0.0386\n",
      "Epoch 23/30, Loss: 0.0271\n",
      "Epoch 24/30, Loss: 0.0368\n",
      "Epoch 25/30, Loss: 0.0205\n",
      "Epoch 26/30, Loss: 0.0198\n",
      "Epoch 27/30, Loss: 0.0210\n",
      "Epoch 28/30, Loss: 0.0274\n",
      "Epoch 29/30, Loss: 0.0103\n",
      "Epoch 30/30, Loss: 0.0114\n",
      "Evaluating models...\n",
      "Successfully aligned predictions with 10 NaN padding values\n",
      "LSTM - Accuracy: 0.5517, F1: 0.6328, ROC AUC: 0.5389\n",
      "LightGBM - Accuracy: 0.4387, F1: 0.3916, ROC AUC: 0.5147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 4 - Evaluating methods:  60%|    | 3/5 [00:04<00:02,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing normalization method: sigmoid (Fold 4)\n",
      "Created LSTM sequences with lookback=10: 608 train, 145 test\n",
      "Training LSTM model...\n",
      "Epoch 1/30, Loss: 0.6866\n",
      "Epoch 2/30, Loss: 0.6856\n",
      "Epoch 3/30, Loss: 0.6867\n",
      "Epoch 4/30, Loss: 0.6843\n",
      "Epoch 5/30, Loss: 0.6841\n",
      "Epoch 6/30, Loss: 0.6835\n",
      "Epoch 7/30, Loss: 0.6820\n",
      "Epoch 8/30, Loss: 0.6826\n",
      "Epoch 9/30, Loss: 0.6806\n",
      "Epoch 10/30, Loss: 0.6825\n",
      "Epoch 11/30, Loss: 0.6826\n",
      "Epoch 12/30, Loss: 0.6834\n",
      "Epoch 13/30, Loss: 0.6826\n",
      "Epoch 14/30, Loss: 0.6806\n",
      "Epoch 15/30, Loss: 0.6838\n",
      "Epoch 16/30, Loss: 0.6794\n",
      "Epoch 17/30, Loss: 0.6802\n",
      "Epoch 18/30, Loss: 0.6768\n",
      "Epoch 19/30, Loss: 0.6752\n",
      "Epoch 20/30, Loss: 0.6724\n",
      "Epoch 21/30, Loss: 0.6704\n",
      "Epoch 22/30, Loss: 0.6750\n",
      "Epoch 23/30, Loss: 0.6722\n",
      "Epoch 24/30, Loss: 0.6736\n",
      "Epoch 25/30, Loss: 0.6704\n",
      "Epoch 26/30, Loss: 0.6651\n",
      "Epoch 27/30, Loss: 0.6660\n",
      "Epoch 28/30, Loss: 0.6661\n",
      "Epoch 29/30, Loss: 0.6672\n",
      "Epoch 30/30, Loss: 0.6720\n",
      "Evaluating models...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 4 - Evaluating methods:  80%|  | 4/5 [00:05<00:01,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully aligned predictions with 10 NaN padding values\n",
      "LSTM - Accuracy: 0.5103, F1: 0.6635, ROC AUC: 0.4065\n",
      "LightGBM - Accuracy: 0.5484, F1: 0.6237, ROC AUC: 0.5371\n",
      "\n",
      "Testing normalization method: tanh_estimator (Fold 4)\n",
      "Created LSTM sequences with lookback=10: 608 train, 145 test\n",
      "Training LSTM model...\n",
      "Epoch 1/30, Loss: 0.6840\n",
      "Epoch 2/30, Loss: 0.6864\n",
      "Epoch 3/30, Loss: 0.6848\n",
      "Epoch 4/30, Loss: 0.6842\n",
      "Epoch 5/30, Loss: 0.6848\n",
      "Epoch 6/30, Loss: 0.6842\n",
      "Epoch 7/30, Loss: 0.6851\n",
      "Epoch 8/30, Loss: 0.6847\n",
      "Epoch 9/30, Loss: 0.6855\n",
      "Epoch 10/30, Loss: 0.6842\n",
      "Epoch 11/30, Loss: 0.6855\n",
      "Early stopping at epoch 11\n",
      "Evaluating models...\n",
      "Successfully aligned predictions with 10 NaN padding values\n",
      "LSTM - Accuracy: 0.6414, F1: 0.7815, ROC AUC: 0.4403\n",
      "LightGBM - Accuracy: 0.4710, F1: 0.4533, ROC AUC: 0.5041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 4 - Evaluating methods: 100%|| 5/5 [00:06<00:00,  1.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing fold 5/10\n",
      "Class distribution in fold 5: {1: 452, 0: 321}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 5 - Evaluating methods:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing normalization method: min_max (Fold 5)\n",
      "Created LSTM sequences with lookback=10: 763 train, 145 test\n",
      "Training LSTM model...\n",
      "Epoch 1/30, Loss: 0.6832\n",
      "Epoch 2/30, Loss: 0.6809\n",
      "Epoch 3/30, Loss: 0.6795\n",
      "Epoch 4/30, Loss: 0.6744\n",
      "Epoch 5/30, Loss: 0.6736\n",
      "Epoch 6/30, Loss: 0.6783\n",
      "Epoch 7/30, Loss: 0.6764\n",
      "Epoch 8/30, Loss: 0.6698\n",
      "Epoch 9/30, Loss: 0.6731\n",
      "Epoch 10/30, Loss: 0.6714\n",
      "Epoch 11/30, Loss: 0.6663\n",
      "Epoch 12/30, Loss: 0.6681\n",
      "Epoch 13/30, Loss: 0.6685\n",
      "Epoch 14/30, Loss: 0.6671\n",
      "Epoch 15/30, Loss: 0.6652\n",
      "Epoch 16/30, Loss: 0.6580\n",
      "Epoch 17/30, Loss: 0.6669\n",
      "Epoch 18/30, Loss: 0.6646\n",
      "Epoch 19/30, Loss: 0.6531\n",
      "Epoch 20/30, Loss: 0.6609\n",
      "Epoch 21/30, Loss: 0.6603\n",
      "Epoch 22/30, Loss: 0.6513\n",
      "Epoch 23/30, Loss: 0.6522\n",
      "Epoch 24/30, Loss: 0.6477\n",
      "Epoch 25/30, Loss: 0.6532\n",
      "Epoch 26/30, Loss: 0.6454\n",
      "Epoch 27/30, Loss: 0.6555\n",
      "Epoch 28/30, Loss: 0.6540\n",
      "Epoch 29/30, Loss: 0.6431\n",
      "Epoch 30/30, Loss: 0.6431\n",
      "Evaluating models...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 5 - Evaluating methods:  20%|        | 1/5 [00:03<00:13,  3.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully aligned predictions with 10 NaN padding values\n",
      "LSTM - Accuracy: 0.6138, F1: 0.7607, ROC AUC: 0.4418\n",
      "LightGBM - Accuracy: 0.5742, F1: 0.6526, ROC AUC: 0.6121\n",
      "\n",
      "Testing normalization method: z_score (Fold 5)\n",
      "Created LSTM sequences with lookback=10: 763 train, 145 test\n",
      "Training LSTM model...\n",
      "Epoch 1/30, Loss: 0.6796\n",
      "Epoch 2/30, Loss: 0.6542\n",
      "Epoch 3/30, Loss: 0.6300\n",
      "Epoch 4/30, Loss: 0.6137\n",
      "Epoch 5/30, Loss: 0.5950\n",
      "Epoch 6/30, Loss: 0.5782\n",
      "Epoch 7/30, Loss: 0.5523\n",
      "Epoch 8/30, Loss: 0.5172\n",
      "Epoch 9/30, Loss: 0.5105\n",
      "Epoch 10/30, Loss: 0.4781\n",
      "Epoch 11/30, Loss: 0.4229\n",
      "Epoch 12/30, Loss: 0.3958\n",
      "Epoch 13/30, Loss: 0.3319\n",
      "Epoch 14/30, Loss: 0.3396\n",
      "Epoch 15/30, Loss: 0.3090\n",
      "Epoch 16/30, Loss: 0.3083\n",
      "Epoch 17/30, Loss: 0.2449\n",
      "Epoch 18/30, Loss: 0.2391\n",
      "Epoch 19/30, Loss: 0.2137\n",
      "Epoch 20/30, Loss: 0.2125\n",
      "Epoch 21/30, Loss: 0.1896\n",
      "Epoch 22/30, Loss: 0.1703\n",
      "Epoch 23/30, Loss: 0.1365\n",
      "Epoch 24/30, Loss: 0.1529\n",
      "Epoch 25/30, Loss: 0.1124\n",
      "Epoch 26/30, Loss: 0.1173\n",
      "Epoch 27/30, Loss: 0.1172\n",
      "Epoch 28/30, Loss: 0.0815\n",
      "Epoch 29/30, Loss: 0.0905\n",
      "Epoch 30/30, Loss: 0.0936\n",
      "Evaluating models...\n",
      "Successfully aligned predictions with 10 NaN padding values\n",
      "LSTM - Accuracy: 0.6138, F1: 0.7607, ROC AUC: 0.4660\n",
      "LightGBM - Accuracy: 0.5806, F1: 0.6524, ROC AUC: 0.6163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 5 - Evaluating methods:  40%|      | 2/5 [00:06<00:09,  3.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing normalization method: median (Fold 5)\n",
      "Created LSTM sequences with lookback=10: 763 train, 145 test\n",
      "Training LSTM model...\n",
      "Epoch 1/30, Loss: 0.6855\n",
      "Epoch 2/30, Loss: 0.6602\n",
      "Epoch 3/30, Loss: 0.6304\n",
      "Epoch 4/30, Loss: 0.5950\n",
      "Epoch 5/30, Loss: 0.5464\n",
      "Epoch 6/30, Loss: 0.4877\n",
      "Epoch 7/30, Loss: 0.3949\n",
      "Epoch 8/30, Loss: 0.3530\n",
      "Epoch 9/30, Loss: 0.2789\n",
      "Epoch 10/30, Loss: 0.2414\n",
      "Epoch 11/30, Loss: 0.2315\n",
      "Epoch 12/30, Loss: 0.1986\n",
      "Epoch 13/30, Loss: 0.1581\n",
      "Epoch 14/30, Loss: 0.1665\n",
      "Epoch 15/30, Loss: 0.1544\n",
      "Epoch 16/30, Loss: 0.1186\n",
      "Epoch 17/30, Loss: 0.1123\n",
      "Epoch 18/30, Loss: 0.0889\n",
      "Epoch 19/30, Loss: 0.0932\n",
      "Epoch 20/30, Loss: 0.1082\n",
      "Epoch 21/30, Loss: 0.0624\n",
      "Epoch 22/30, Loss: 0.0532\n",
      "Epoch 23/30, Loss: 0.0595\n",
      "Epoch 24/30, Loss: 0.0651\n",
      "Epoch 25/30, Loss: 0.0277\n",
      "Epoch 26/30, Loss: 0.0253\n",
      "Epoch 27/30, Loss: 0.0294\n",
      "Epoch 28/30, Loss: 0.0128\n",
      "Epoch 29/30, Loss: 0.0083\n",
      "Epoch 30/30, Loss: 0.0248\n",
      "Evaluating models...\n",
      "Successfully aligned predictions with 10 NaN padding values\n",
      "LSTM - Accuracy: 0.5103, F1: 0.5749, ROC AUC: 0.5325\n",
      "LightGBM - Accuracy: 0.5806, F1: 0.6597, ROC AUC: 0.5800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 5 - Evaluating methods:  60%|    | 3/5 [00:11<00:07,  3.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing normalization method: sigmoid (Fold 5)\n",
      "Created LSTM sequences with lookback=10: 763 train, 145 test\n",
      "Training LSTM model...\n",
      "Epoch 1/30, Loss: 0.6866\n",
      "Epoch 2/30, Loss: 0.6832\n",
      "Epoch 3/30, Loss: 0.6830\n",
      "Epoch 4/30, Loss: 0.6822\n",
      "Epoch 5/30, Loss: 0.6850\n",
      "Epoch 6/30, Loss: 0.6825\n",
      "Epoch 7/30, Loss: 0.6803\n",
      "Epoch 8/30, Loss: 0.6815\n",
      "Epoch 9/30, Loss: 0.6789\n",
      "Epoch 10/30, Loss: 0.6812\n",
      "Epoch 11/30, Loss: 0.6815\n",
      "Epoch 12/30, Loss: 0.6777\n",
      "Epoch 13/30, Loss: 0.6807\n",
      "Epoch 14/30, Loss: 0.6813\n",
      "Epoch 15/30, Loss: 0.6804\n",
      "Epoch 16/30, Loss: 0.6789\n",
      "Epoch 17/30, Loss: 0.6782\n",
      "Epoch 18/30, Loss: 0.6787\n",
      "Epoch 19/30, Loss: 0.6818\n",
      "Epoch 20/30, Loss: 0.6802\n",
      "Epoch 21/30, Loss: 0.6804\n",
      "Epoch 22/30, Loss: 0.6759\n",
      "Epoch 23/30, Loss: 0.6733\n",
      "Epoch 24/30, Loss: 0.6814\n",
      "Epoch 25/30, Loss: 0.6832\n",
      "Epoch 26/30, Loss: 0.6797\n",
      "Epoch 27/30, Loss: 0.6784\n",
      "Epoch 28/30, Loss: 0.6752\n",
      "Epoch 29/30, Loss: 0.6801\n",
      "Epoch 30/30, Loss: 0.6784\n",
      "Evaluating models...\n",
      "Successfully aligned predictions with 10 NaN padding values\n",
      "LSTM - Accuracy: 0.6138, F1: 0.7607, ROC AUC: 0.5919\n",
      "LightGBM - Accuracy: 0.5097, F1: 0.5422, ROC AUC: 0.5651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 5 - Evaluating methods:  80%|  | 4/5 [00:14<00:03,  3.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing normalization method: tanh_estimator (Fold 5)\n",
      "Created LSTM sequences with lookback=10: 763 train, 145 test\n",
      "Training LSTM model...\n",
      "Epoch 1/30, Loss: 0.6854\n",
      "Epoch 2/30, Loss: 0.6857\n",
      "Epoch 3/30, Loss: 0.6832\n",
      "Epoch 4/30, Loss: 0.6849\n",
      "Epoch 5/30, Loss: 0.6833\n",
      "Epoch 6/30, Loss: 0.6814\n",
      "Epoch 7/30, Loss: 0.6828\n",
      "Epoch 8/30, Loss: 0.6860\n",
      "Epoch 9/30, Loss: 0.6816\n",
      "Epoch 10/30, Loss: 0.6785\n",
      "Epoch 11/30, Loss: 0.6824\n",
      "Epoch 12/30, Loss: 0.6807\n",
      "Epoch 13/30, Loss: 0.6813\n",
      "Epoch 14/30, Loss: 0.6823\n",
      "Epoch 15/30, Loss: 0.6829\n",
      "Epoch 16/30, Loss: 0.6820\n",
      "Epoch 17/30, Loss: 0.6838\n",
      "Epoch 18/30, Loss: 0.6821\n",
      "Epoch 19/30, Loss: 0.6831\n",
      "Epoch 20/30, Loss: 0.6815\n",
      "Early stopping at epoch 20\n",
      "Evaluating models...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 5 - Evaluating methods: 100%|| 5/5 [00:16<00:00,  3.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully aligned predictions with 10 NaN padding values\n",
      "LSTM - Accuracy: 0.6138, F1: 0.7607, ROC AUC: 0.4730\n",
      "LightGBM - Accuracy: 0.5742, F1: 0.6333, ROC AUC: 0.6091\n",
      "\n",
      "Processing fold 6/10\n",
      "Class distribution in fold 6: {1: 550, 0: 378}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 6 - Evaluating methods:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing normalization method: min_max (Fold 6)\n",
      "Created LSTM sequences with lookback=10: 918 train, 145 test\n",
      "Training LSTM model...\n",
      "Epoch 1/30, Loss: 0.6837\n",
      "Epoch 2/30, Loss: 0.6814\n",
      "Epoch 3/30, Loss: 0.6749\n",
      "Epoch 4/30, Loss: 0.6770\n",
      "Epoch 5/30, Loss: 0.6782\n",
      "Epoch 6/30, Loss: 0.6747\n",
      "Epoch 7/30, Loss: 0.6777\n",
      "Epoch 8/30, Loss: 0.6754\n",
      "Epoch 9/30, Loss: 0.6746\n",
      "Epoch 10/30, Loss: 0.6738\n",
      "Epoch 11/30, Loss: 0.6714\n",
      "Epoch 12/30, Loss: 0.6702\n",
      "Epoch 13/30, Loss: 0.6666\n",
      "Epoch 14/30, Loss: 0.6689\n",
      "Epoch 15/30, Loss: 0.6718\n",
      "Epoch 16/30, Loss: 0.6699\n",
      "Epoch 17/30, Loss: 0.6694\n",
      "Epoch 18/30, Loss: 0.6654\n",
      "Epoch 19/30, Loss: 0.6598\n",
      "Epoch 20/30, Loss: 0.6554\n",
      "Epoch 21/30, Loss: 0.6718\n",
      "Epoch 22/30, Loss: 0.6671\n",
      "Epoch 23/30, Loss: 0.6595\n",
      "Epoch 24/30, Loss: 0.6559\n",
      "Epoch 25/30, Loss: 0.6555\n",
      "Epoch 26/30, Loss: 0.6556\n",
      "Epoch 27/30, Loss: 0.6483\n",
      "Epoch 28/30, Loss: 0.6501\n",
      "Epoch 29/30, Loss: 0.6530\n",
      "Epoch 30/30, Loss: 0.6492\n",
      "Evaluating models...\n",
      "Successfully aligned predictions with 10 NaN padding values\n",
      "LSTM - Accuracy: 0.6276, F1: 0.7033, ROC AUC: 0.6755\n",
      "LightGBM - Accuracy: 0.5355, F1: 0.6897, ROC AUC: 0.5297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 6 - Evaluating methods:  20%|        | 1/5 [00:03<00:15,  3.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing normalization method: z_score (Fold 6)\n",
      "Created LSTM sequences with lookback=10: 918 train, 145 test\n",
      "Training LSTM model...\n",
      "Epoch 1/30, Loss: 0.6880\n",
      "Epoch 2/30, Loss: 0.6686\n",
      "Epoch 3/30, Loss: 0.6447\n",
      "Epoch 4/30, Loss: 0.6258\n",
      "Epoch 5/30, Loss: 0.6293\n",
      "Epoch 6/30, Loss: 0.6155\n",
      "Epoch 7/30, Loss: 0.5976\n",
      "Epoch 8/30, Loss: 0.5894\n",
      "Epoch 9/30, Loss: 0.5733\n",
      "Epoch 10/30, Loss: 0.5682\n",
      "Epoch 11/30, Loss: 0.5401\n",
      "Epoch 12/30, Loss: 0.5298\n",
      "Epoch 13/30, Loss: 0.5037\n",
      "Epoch 14/30, Loss: 0.4771\n",
      "Epoch 15/30, Loss: 0.4583\n",
      "Epoch 16/30, Loss: 0.4332\n",
      "Epoch 17/30, Loss: 0.4288\n",
      "Epoch 18/30, Loss: 0.4000\n",
      "Epoch 19/30, Loss: 0.3592\n",
      "Epoch 20/30, Loss: 0.3581\n",
      "Epoch 21/30, Loss: 0.3532\n",
      "Epoch 22/30, Loss: 0.3121\n",
      "Epoch 23/30, Loss: 0.3043\n",
      "Epoch 24/30, Loss: 0.3169\n",
      "Epoch 25/30, Loss: 0.3073\n",
      "Epoch 26/30, Loss: 0.2807\n",
      "Epoch 27/30, Loss: 0.2695\n",
      "Epoch 28/30, Loss: 0.2687\n",
      "Epoch 29/30, Loss: 0.2503\n",
      "Epoch 30/30, Loss: 0.2349\n",
      "Evaluating models...\n",
      "Successfully aligned predictions with 10 NaN padding values\n",
      "LSTM - Accuracy: 0.5931, F1: 0.6878, ROC AUC: 0.6786\n",
      "LightGBM - Accuracy: 0.5290, F1: 0.6840, ROC AUC: 0.5476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 6 - Evaluating methods:  40%|      | 2/5 [00:11<00:18,  6.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing normalization method: median (Fold 6)\n",
      "Created LSTM sequences with lookback=10: 918 train, 145 test\n",
      "Training LSTM model...\n",
      "Epoch 1/30, Loss: 0.6769\n",
      "Epoch 2/30, Loss: 0.6637\n",
      "Epoch 3/30, Loss: 0.6539\n",
      "Epoch 4/30, Loss: 0.6407\n",
      "Epoch 5/30, Loss: 0.6195\n",
      "Epoch 6/30, Loss: 0.5873\n",
      "Epoch 7/30, Loss: 0.5452\n",
      "Epoch 8/30, Loss: 0.5190\n",
      "Epoch 9/30, Loss: 0.4572\n",
      "Epoch 10/30, Loss: 0.4031\n",
      "Epoch 11/30, Loss: 0.3651\n",
      "Epoch 12/30, Loss: 0.3346\n",
      "Epoch 13/30, Loss: 0.2923\n",
      "Epoch 14/30, Loss: 0.2737\n",
      "Epoch 15/30, Loss: 0.2509\n",
      "Epoch 16/30, Loss: 0.2641\n",
      "Epoch 17/30, Loss: 0.2105\n",
      "Epoch 18/30, Loss: 0.1785\n",
      "Epoch 19/30, Loss: 0.1836\n",
      "Epoch 20/30, Loss: 0.1319\n",
      "Epoch 21/30, Loss: 0.1320\n",
      "Epoch 22/30, Loss: 0.1406\n",
      "Epoch 23/30, Loss: 0.1081\n",
      "Epoch 24/30, Loss: 0.1028\n",
      "Epoch 25/30, Loss: 0.1063\n",
      "Epoch 26/30, Loss: 0.0779\n",
      "Epoch 27/30, Loss: 0.0674\n",
      "Epoch 28/30, Loss: 0.0665\n",
      "Epoch 29/30, Loss: 0.0649\n",
      "Epoch 30/30, Loss: 0.0411\n",
      "Evaluating models...\n",
      "Successfully aligned predictions with 10 NaN padding values\n",
      "LSTM - Accuracy: 0.5724, F1: 0.6395, ROC AUC: 0.5363\n",
      "LightGBM - Accuracy: 0.5290, F1: 0.6867, ROC AUC: 0.5347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 6 - Evaluating methods:  60%|    | 3/5 [00:15<00:10,  5.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing normalization method: sigmoid (Fold 6)\n",
      "Created LSTM sequences with lookback=10: 918 train, 145 test\n",
      "Training LSTM model...\n",
      "Epoch 1/30, Loss: 0.6869\n",
      "Epoch 2/30, Loss: 0.6861\n",
      "Epoch 3/30, Loss: 0.6822\n",
      "Epoch 4/30, Loss: 0.6766\n",
      "Epoch 5/30, Loss: 0.6795\n",
      "Epoch 6/30, Loss: 0.6782\n",
      "Epoch 7/30, Loss: 0.6777\n",
      "Epoch 8/30, Loss: 0.6776\n",
      "Epoch 9/30, Loss: 0.6783\n",
      "Epoch 10/30, Loss: 0.6769\n",
      "Epoch 11/30, Loss: 0.6822\n",
      "Epoch 12/30, Loss: 0.6776\n",
      "Epoch 13/30, Loss: 0.6770\n",
      "Epoch 14/30, Loss: 0.6746\n",
      "Epoch 15/30, Loss: 0.6751\n",
      "Epoch 16/30, Loss: 0.6743\n",
      "Epoch 17/30, Loss: 0.6753\n",
      "Epoch 18/30, Loss: 0.6743\n",
      "Epoch 19/30, Loss: 0.6737\n",
      "Epoch 20/30, Loss: 0.6768\n",
      "Epoch 21/30, Loss: 0.6704\n",
      "Epoch 22/30, Loss: 0.6724\n",
      "Epoch 23/30, Loss: 0.6749\n",
      "Epoch 24/30, Loss: 0.6702\n",
      "Epoch 25/30, Loss: 0.6695\n",
      "Epoch 26/30, Loss: 0.6768\n",
      "Epoch 27/30, Loss: 0.6788\n",
      "Epoch 28/30, Loss: 0.6728\n",
      "Epoch 29/30, Loss: 0.6686\n",
      "Epoch 30/30, Loss: 0.6771\n",
      "Evaluating models...\n",
      "Successfully aligned predictions with 10 NaN padding values\n",
      "LSTM - Accuracy: 0.5310, F1: 0.6937, ROC AUC: 0.6465\n",
      "LightGBM - Accuracy: 0.5226, F1: 0.6574, ROC AUC: 0.5209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 6 - Evaluating methods:  80%|  | 4/5 [00:19<00:04,  4.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing normalization method: tanh_estimator (Fold 6)\n",
      "Created LSTM sequences with lookback=10: 918 train, 145 test\n",
      "Training LSTM model...\n",
      "Epoch 1/30, Loss: 0.6869\n",
      "Epoch 2/30, Loss: 0.6791\n",
      "Epoch 3/30, Loss: 0.6814\n",
      "Epoch 4/30, Loss: 0.6817\n",
      "Epoch 5/30, Loss: 0.6815\n",
      "Epoch 6/30, Loss: 0.6809\n",
      "Epoch 7/30, Loss: 0.6812\n",
      "Epoch 8/30, Loss: 0.6791\n",
      "Epoch 9/30, Loss: 0.6782\n",
      "Epoch 10/30, Loss: 0.6815\n",
      "Epoch 11/30, Loss: 0.6803\n",
      "Epoch 12/30, Loss: 0.6800\n",
      "Epoch 13/30, Loss: 0.6780\n",
      "Epoch 14/30, Loss: 0.6815\n",
      "Epoch 15/30, Loss: 0.6780\n",
      "Epoch 16/30, Loss: 0.6783\n",
      "Epoch 17/30, Loss: 0.6799\n",
      "Epoch 18/30, Loss: 0.6798\n",
      "Epoch 19/30, Loss: 0.6804\n",
      "Epoch 20/30, Loss: 0.6798\n",
      "Epoch 21/30, Loss: 0.6787\n",
      "Epoch 22/30, Loss: 0.6769\n",
      "Epoch 23/30, Loss: 0.6789\n",
      "Epoch 24/30, Loss: 0.6783\n",
      "Epoch 25/30, Loss: 0.6786\n",
      "Epoch 26/30, Loss: 0.6791\n",
      "Epoch 27/30, Loss: 0.6776\n",
      "Epoch 28/30, Loss: 0.6800\n",
      "Epoch 29/30, Loss: 0.6787\n",
      "Epoch 30/30, Loss: 0.6783\n",
      "Evaluating models...\n",
      "Successfully aligned predictions with 10 NaN padding values\n",
      "LSTM - Accuracy: 0.5310, F1: 0.6937, ROC AUC: 0.4333\n",
      "LightGBM - Accuracy: 0.5355, F1: 0.6842, ROC AUC: 0.5347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 6 - Evaluating methods: 100%|| 5/5 [00:23<00:00,  4.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing fold 7/10\n",
      "Class distribution in fold 7: {1: 628, 0: 455}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 7 - Evaluating methods:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing normalization method: min_max (Fold 7)\n",
      "Created LSTM sequences with lookback=10: 1073 train, 145 test\n",
      "Training LSTM model...\n",
      "Epoch 1/30, Loss: 0.6822\n",
      "Epoch 2/30, Loss: 0.6834\n",
      "Epoch 3/30, Loss: 0.6832\n",
      "Epoch 4/30, Loss: 0.6803\n",
      "Epoch 5/30, Loss: 0.6841\n",
      "Epoch 6/30, Loss: 0.6764\n",
      "Epoch 7/30, Loss: 0.6763\n",
      "Epoch 8/30, Loss: 0.6716\n",
      "Epoch 9/30, Loss: 0.6793\n",
      "Epoch 10/30, Loss: 0.6775\n",
      "Epoch 11/30, Loss: 0.6777\n",
      "Epoch 12/30, Loss: 0.6783\n",
      "Epoch 13/30, Loss: 0.6675\n",
      "Epoch 14/30, Loss: 0.6673\n",
      "Epoch 15/30, Loss: 0.6784\n",
      "Epoch 16/30, Loss: 0.6674\n",
      "Epoch 17/30, Loss: 0.6786\n",
      "Epoch 18/30, Loss: 0.6719\n",
      "Epoch 19/30, Loss: 0.6750\n",
      "Epoch 20/30, Loss: 0.6695\n",
      "Epoch 21/30, Loss: 0.6549\n",
      "Epoch 22/30, Loss: 0.6600\n",
      "Epoch 23/30, Loss: 0.6482\n",
      "Epoch 24/30, Loss: 0.6485\n",
      "Epoch 25/30, Loss: 0.6560\n",
      "Epoch 26/30, Loss: 0.6581\n",
      "Epoch 27/30, Loss: 0.6538\n",
      "Epoch 28/30, Loss: 0.6573\n",
      "Epoch 29/30, Loss: 0.6446\n",
      "Epoch 30/30, Loss: 0.6448\n",
      "Evaluating models...\n",
      "Successfully aligned predictions with 10 NaN padding values\n",
      "LSTM - Accuracy: 0.3517, F1: 0.4471, ROC AUC: 0.3424\n",
      "LightGBM - Accuracy: 0.5806, F1: 0.6243, ROC AUC: 0.6268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 7 - Evaluating methods:  20%|        | 1/5 [00:06<00:24,  6.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing normalization method: z_score (Fold 7)\n",
      "Created LSTM sequences with lookback=10: 1073 train, 145 test\n",
      "Training LSTM model...\n",
      "Epoch 1/30, Loss: 0.6997\n",
      "Epoch 2/30, Loss: 0.6615\n",
      "Epoch 3/30, Loss: 0.6574\n",
      "Epoch 4/30, Loss: 0.6427\n",
      "Epoch 5/30, Loss: 0.6398\n",
      "Epoch 6/30, Loss: 0.6291\n",
      "Epoch 7/30, Loss: 0.6128\n",
      "Epoch 8/30, Loss: 0.5938\n",
      "Epoch 9/30, Loss: 0.5829\n",
      "Epoch 10/30, Loss: 0.5701\n",
      "Epoch 11/30, Loss: 0.5528\n",
      "Epoch 12/30, Loss: 0.5337\n",
      "Epoch 13/30, Loss: 0.5086\n",
      "Epoch 14/30, Loss: 0.4744\n",
      "Epoch 15/30, Loss: 0.4736\n",
      "Epoch 16/30, Loss: 0.4359\n",
      "Epoch 17/30, Loss: 0.4302\n",
      "Epoch 18/30, Loss: 0.4111\n",
      "Epoch 19/30, Loss: 0.3784\n",
      "Epoch 20/30, Loss: 0.3540\n",
      "Epoch 21/30, Loss: 0.3376\n",
      "Epoch 22/30, Loss: 0.3222\n",
      "Epoch 23/30, Loss: 0.3354\n",
      "Epoch 24/30, Loss: 0.2981\n",
      "Epoch 25/30, Loss: 0.2744\n",
      "Epoch 26/30, Loss: 0.2547\n",
      "Epoch 27/30, Loss: 0.2365\n",
      "Epoch 28/30, Loss: 0.2667\n",
      "Epoch 29/30, Loss: 0.2193\n",
      "Epoch 30/30, Loss: 0.2063\n",
      "Evaluating models...\n",
      "Successfully aligned predictions with 10 NaN padding values\n",
      "LSTM - Accuracy: 0.4000, F1: 0.4314, ROC AUC: 0.3727\n",
      "LightGBM - Accuracy: 0.6065, F1: 0.6514, ROC AUC: 0.6285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 7 - Evaluating methods:  40%|      | 2/5 [00:10<00:15,  5.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing normalization method: median (Fold 7)\n",
      "Created LSTM sequences with lookback=10: 1073 train, 145 test\n",
      "Training LSTM model...\n",
      "Epoch 1/30, Loss: 0.6742\n",
      "Epoch 2/30, Loss: 0.6530\n",
      "Epoch 3/30, Loss: 0.6440\n",
      "Epoch 4/30, Loss: 0.6267\n",
      "Epoch 5/30, Loss: 0.5939\n",
      "Epoch 6/30, Loss: 0.5681\n",
      "Epoch 7/30, Loss: 0.4894\n",
      "Epoch 8/30, Loss: 0.4430\n",
      "Epoch 9/30, Loss: 0.3920\n",
      "Epoch 10/30, Loss: 0.3188\n",
      "Epoch 11/30, Loss: 0.2842\n",
      "Epoch 12/30, Loss: 0.2921\n",
      "Epoch 13/30, Loss: 0.2366\n",
      "Epoch 14/30, Loss: 0.2167\n",
      "Epoch 15/30, Loss: 0.1934\n",
      "Epoch 16/30, Loss: 0.1945\n",
      "Epoch 17/30, Loss: 0.1585\n",
      "Epoch 18/30, Loss: 0.1463\n",
      "Epoch 19/30, Loss: 0.1296\n",
      "Epoch 20/30, Loss: 0.1172\n",
      "Epoch 21/30, Loss: 0.1162\n",
      "Epoch 22/30, Loss: 0.0928\n",
      "Epoch 23/30, Loss: 0.0759\n",
      "Epoch 24/30, Loss: 0.0893\n",
      "Epoch 25/30, Loss: 0.0678\n",
      "Epoch 26/30, Loss: 0.0544\n",
      "Epoch 27/30, Loss: 0.0592\n",
      "Epoch 28/30, Loss: 0.0491\n",
      "Epoch 29/30, Loss: 0.0337\n",
      "Epoch 30/30, Loss: 0.0306\n",
      "Evaluating models...\n",
      "Successfully aligned predictions with 10 NaN padding values\n",
      "LSTM - Accuracy: 0.5448, F1: 0.5926, ROC AUC: 0.5814\n",
      "LightGBM - Accuracy: 0.6258, F1: 0.6588, ROC AUC: 0.6291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 7 - Evaluating methods:  60%|    | 3/5 [00:15<00:09,  4.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing normalization method: sigmoid (Fold 7)\n",
      "Created LSTM sequences with lookback=10: 1073 train, 145 test\n",
      "Training LSTM model...\n",
      "Epoch 1/30, Loss: 0.6860\n",
      "Epoch 2/30, Loss: 0.6821\n",
      "Epoch 3/30, Loss: 0.6810\n",
      "Epoch 4/30, Loss: 0.6801\n",
      "Epoch 5/30, Loss: 0.6789\n",
      "Epoch 6/30, Loss: 0.6792\n",
      "Epoch 7/30, Loss: 0.6843\n",
      "Epoch 8/30, Loss: 0.6797\n",
      "Epoch 9/30, Loss: 0.6804\n",
      "Epoch 10/30, Loss: 0.6756\n",
      "Epoch 11/30, Loss: 0.6771\n",
      "Epoch 12/30, Loss: 0.6840\n",
      "Epoch 13/30, Loss: 0.6783\n",
      "Epoch 14/30, Loss: 0.6772\n",
      "Epoch 15/30, Loss: 0.6795\n",
      "Epoch 16/30, Loss: 0.6745\n",
      "Epoch 17/30, Loss: 0.6754\n",
      "Epoch 18/30, Loss: 0.6751\n",
      "Epoch 19/30, Loss: 0.6766\n",
      "Epoch 20/30, Loss: 0.6732\n",
      "Epoch 21/30, Loss: 0.6682\n",
      "Epoch 22/30, Loss: 0.6755\n",
      "Epoch 23/30, Loss: 0.6731\n",
      "Epoch 24/30, Loss: 0.6674\n",
      "Epoch 25/30, Loss: 0.6756\n",
      "Epoch 26/30, Loss: 0.6747\n",
      "Epoch 27/30, Loss: 0.6694\n",
      "Epoch 28/30, Loss: 0.6721\n",
      "Epoch 29/30, Loss: 0.6686\n",
      "Epoch 30/30, Loss: 0.6727\n",
      "Evaluating models...\n",
      "Successfully aligned predictions with 10 NaN padding values\n",
      "LSTM - Accuracy: 0.5724, F1: 0.7281, ROC AUC: 0.5550\n",
      "LightGBM - Accuracy: 0.4903, F1: 0.5864, ROC AUC: 0.4760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 7 - Evaluating methods:  80%|  | 4/5 [00:19<00:04,  4.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing normalization method: tanh_estimator (Fold 7)\n",
      "Created LSTM sequences with lookback=10: 1073 train, 145 test\n",
      "Training LSTM model...\n",
      "Epoch 1/30, Loss: 0.6829\n",
      "Epoch 2/30, Loss: 0.6847\n",
      "Epoch 3/30, Loss: 0.6856\n",
      "Epoch 4/30, Loss: 0.6849\n",
      "Epoch 5/30, Loss: 0.6792\n",
      "Epoch 6/30, Loss: 0.6837\n",
      "Epoch 7/30, Loss: 0.6840\n",
      "Epoch 8/30, Loss: 0.6837\n",
      "Epoch 9/30, Loss: 0.6858\n",
      "Epoch 10/30, Loss: 0.6804\n",
      "Epoch 11/30, Loss: 0.6812\n",
      "Epoch 12/30, Loss: 0.6800\n",
      "Epoch 13/30, Loss: 0.6818\n",
      "Epoch 14/30, Loss: 0.6841\n",
      "Epoch 15/30, Loss: 0.6833\n",
      "Early stopping at epoch 15\n",
      "Evaluating models...\n",
      "Successfully aligned predictions with 10 NaN padding values\n",
      "LSTM - Accuracy: 0.5724, F1: 0.7281, ROC AUC: 0.4709\n",
      "LightGBM - Accuracy: 0.6323, F1: 0.6627, ROC AUC: 0.6329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 7 - Evaluating methods: 100%|| 5/5 [00:22<00:00,  4.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing fold 8/10\n",
      "Class distribution in fold 8: {1: 720, 0: 518}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 8 - Evaluating methods:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing normalization method: min_max (Fold 8)\n",
      "Created LSTM sequences with lookback=10: 1228 train, 145 test\n",
      "Training LSTM model...\n",
      "Epoch 1/30, Loss: 0.6812\n",
      "Epoch 2/30, Loss: 0.6799\n",
      "Epoch 3/30, Loss: 0.6759\n",
      "Epoch 4/30, Loss: 0.6798\n",
      "Epoch 5/30, Loss: 0.6775\n",
      "Epoch 6/30, Loss: 0.6775\n",
      "Epoch 7/30, Loss: 0.6755\n",
      "Epoch 8/30, Loss: 0.6736\n",
      "Epoch 9/30, Loss: 0.6817\n",
      "Epoch 10/30, Loss: 0.6704\n",
      "Epoch 11/30, Loss: 0.6712\n",
      "Epoch 12/30, Loss: 0.6695\n",
      "Epoch 13/30, Loss: 0.6734\n",
      "Epoch 14/30, Loss: 0.6819\n",
      "Epoch 15/30, Loss: 0.6790\n",
      "Epoch 16/30, Loss: 0.6786\n",
      "Epoch 17/30, Loss: 0.6706\n",
      "Epoch 18/30, Loss: 0.6749\n",
      "Epoch 19/30, Loss: 0.6723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 8 - Evaluating methods:  20%|        | 1/5 [00:01<00:05,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/30, Loss: 0.6776\n",
      "Epoch 21/30, Loss: 0.6702\n",
      "Epoch 22/30, Loss: 0.6746\n",
      "Early stopping at epoch 22\n",
      "Evaluating models...\n",
      "Successfully aligned predictions with 10 NaN padding values\n",
      "LSTM - Accuracy: 0.5586, F1: 0.7168, ROC AUC: 0.5174\n",
      "LightGBM - Accuracy: 0.4710, F1: 0.3167, ROC AUC: 0.4526\n",
      "\n",
      "Testing normalization method: z_score (Fold 8)\n",
      "Created LSTM sequences with lookback=10: 1228 train, 145 test\n",
      "Training LSTM model...\n",
      "Epoch 1/30, Loss: 0.6898\n",
      "Epoch 2/30, Loss: 0.6730\n",
      "Epoch 3/30, Loss: 0.6597\n",
      "Epoch 4/30, Loss: 0.6492\n",
      "Epoch 5/30, Loss: 0.6411\n",
      "Epoch 6/30, Loss: 0.6437\n",
      "Epoch 7/30, Loss: 0.6244\n",
      "Epoch 8/30, Loss: 0.6111\n",
      "Epoch 9/30, Loss: 0.5957\n",
      "Epoch 10/30, Loss: 0.5810\n",
      "Epoch 11/30, Loss: 0.5501\n",
      "Epoch 12/30, Loss: 0.5184\n",
      "Epoch 13/30, Loss: 0.4991\n",
      "Epoch 14/30, Loss: 0.5000\n",
      "Epoch 15/30, Loss: 0.4409\n",
      "Epoch 16/30, Loss: 0.4374\n",
      "Epoch 17/30, Loss: 0.4120\n",
      "Epoch 18/30, Loss: 0.3847\n",
      "Epoch 19/30, Loss: 0.3509\n",
      "Epoch 20/30, Loss: 0.3450\n",
      "Epoch 21/30, Loss: 0.3281\n",
      "Epoch 22/30, Loss: 0.3054\n",
      "Epoch 23/30, Loss: 0.2605\n",
      "Epoch 24/30, Loss: 0.2655\n",
      "Epoch 25/30, Loss: 0.2594\n",
      "Epoch 26/30, Loss: 0.2429\n",
      "Epoch 27/30, Loss: 0.2297\n",
      "Epoch 28/30, Loss: 0.2281\n",
      "Epoch 29/30, Loss: 0.2153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 8 - Evaluating methods:  40%|      | 2/5 [00:03<00:04,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/30, Loss: 0.2111\n",
      "Evaluating models...\n",
      "Successfully aligned predictions with 10 NaN padding values\n",
      "LSTM - Accuracy: 0.5241, F1: 0.4103, ROC AUC: 0.5801\n",
      "LightGBM - Accuracy: 0.4774, F1: 0.3077, ROC AUC: 0.4555\n",
      "\n",
      "Testing normalization method: median (Fold 8)\n",
      "Created LSTM sequences with lookback=10: 1228 train, 145 test\n",
      "Training LSTM model...\n",
      "Epoch 1/30, Loss: 0.6778\n",
      "Epoch 2/30, Loss: 0.6637\n",
      "Epoch 3/30, Loss: 0.6573\n",
      "Epoch 4/30, Loss: 0.6355\n",
      "Epoch 5/30, Loss: 0.6251\n",
      "Epoch 6/30, Loss: 0.5845\n",
      "Epoch 7/30, Loss: 0.5383\n",
      "Epoch 8/30, Loss: 0.4876\n",
      "Epoch 9/30, Loss: 0.4408\n",
      "Epoch 10/30, Loss: 0.3982\n",
      "Epoch 11/30, Loss: 0.3731\n",
      "Epoch 12/30, Loss: 0.3398\n",
      "Epoch 13/30, Loss: 0.3133\n",
      "Epoch 14/30, Loss: 0.2806\n",
      "Epoch 15/30, Loss: 0.2254\n",
      "Epoch 16/30, Loss: 0.2083\n",
      "Epoch 17/30, Loss: 0.1922\n",
      "Epoch 18/30, Loss: 0.1910\n",
      "Epoch 19/30, Loss: 0.1599\n",
      "Epoch 20/30, Loss: 0.1335\n",
      "Epoch 21/30, Loss: 0.1106\n",
      "Epoch 22/30, Loss: 0.1075\n",
      "Epoch 23/30, Loss: 0.1076\n",
      "Epoch 24/30, Loss: 0.1220\n",
      "Epoch 25/30, Loss: 0.0968\n",
      "Epoch 26/30, Loss: 0.0946\n",
      "Epoch 27/30, Loss: 0.0676\n",
      "Epoch 28/30, Loss: 0.0500\n",
      "Epoch 29/30, Loss: 0.0570\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 8 - Evaluating methods:  60%|    | 3/5 [00:04<00:03,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/30, Loss: 0.0485\n",
      "Evaluating models...\n",
      "Successfully aligned predictions with 10 NaN padding values\n",
      "LSTM - Accuracy: 0.5448, F1: 0.5976, ROC AUC: 0.5047\n",
      "LightGBM - Accuracy: 0.4581, F1: 0.3000, ROC AUC: 0.4681\n",
      "\n",
      "Testing normalization method: sigmoid (Fold 8)\n",
      "Created LSTM sequences with lookback=10: 1228 train, 145 test\n",
      "Training LSTM model...\n",
      "Epoch 1/30, Loss: 0.6826\n",
      "Epoch 2/30, Loss: 0.6806\n",
      "Epoch 3/30, Loss: 0.6790\n",
      "Epoch 4/30, Loss: 0.6732\n",
      "Epoch 5/30, Loss: 0.6867\n",
      "Epoch 6/30, Loss: 0.6763\n",
      "Epoch 7/30, Loss: 0.6732\n",
      "Epoch 8/30, Loss: 0.6681\n",
      "Epoch 9/30, Loss: 0.6674\n",
      "Epoch 10/30, Loss: 0.6664\n",
      "Epoch 11/30, Loss: 0.6799\n",
      "Epoch 12/30, Loss: 0.6656\n",
      "Epoch 13/30, Loss: 0.6705\n",
      "Epoch 14/30, Loss: 0.6776\n",
      "Epoch 15/30, Loss: 0.6745\n",
      "Epoch 16/30, Loss: 0.6690\n",
      "Epoch 17/30, Loss: 0.6651\n",
      "Epoch 18/30, Loss: 0.6680\n",
      "Epoch 19/30, Loss: 0.6607\n",
      "Epoch 20/30, Loss: 0.6648\n",
      "Epoch 21/30, Loss: 0.6668\n",
      "Epoch 22/30, Loss: 0.6669\n",
      "Epoch 23/30, Loss: 0.6656\n",
      "Epoch 24/30, Loss: 0.6589\n",
      "Epoch 25/30, Loss: 0.6671\n",
      "Epoch 26/30, Loss: 0.6676\n",
      "Epoch 27/30, Loss: 0.6739\n",
      "Epoch 28/30, Loss: 0.6662\n",
      "Epoch 29/30, Loss: 0.6664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 8 - Evaluating methods:  80%|  | 4/5 [00:06<00:01,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/30, Loss: 0.6641\n",
      "Evaluating models...\n",
      "Successfully aligned predictions with 10 NaN padding values\n",
      "LSTM - Accuracy: 0.5586, F1: 0.7168, ROC AUC: 0.5589\n",
      "LightGBM - Accuracy: 0.5097, F1: 0.4722, ROC AUC: 0.5420\n",
      "\n",
      "Testing normalization method: tanh_estimator (Fold 8)\n",
      "Created LSTM sequences with lookback=10: 1228 train, 145 test\n",
      "Training LSTM model...\n",
      "Epoch 1/30, Loss: 0.6855\n",
      "Epoch 2/30, Loss: 0.6843\n",
      "Epoch 3/30, Loss: 0.6825\n",
      "Epoch 4/30, Loss: 0.6850\n",
      "Epoch 5/30, Loss: 0.6787\n",
      "Epoch 6/30, Loss: 0.6848\n",
      "Epoch 7/30, Loss: 0.6817\n",
      "Epoch 8/30, Loss: 0.6800\n",
      "Epoch 9/30, Loss: 0.6825\n",
      "Epoch 10/30, Loss: 0.6844\n",
      "Epoch 11/30, Loss: 0.6843\n",
      "Epoch 12/30, Loss: 0.6805\n",
      "Epoch 13/30, Loss: 0.6824\n",
      "Epoch 14/30, Loss: 0.6821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 8 - Evaluating methods: 100%|| 5/5 [00:07<00:00,  1.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/30, Loss: 0.6823\n",
      "Early stopping at epoch 15\n",
      "Evaluating models...\n",
      "Successfully aligned predictions with 10 NaN padding values\n",
      "LSTM - Accuracy: 0.5586, F1: 0.7168, ROC AUC: 0.3610\n",
      "LightGBM - Accuracy: 0.4710, F1: 0.3051, ROC AUC: 0.4742\n",
      "\n",
      "Processing fold 9/10\n",
      "Class distribution in fold 9: {1: 810, 0: 583}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 9 - Evaluating methods:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing normalization method: min_max (Fold 9)\n",
      "Created LSTM sequences with lookback=10: 1383 train, 145 test\n",
      "Training LSTM model...\n",
      "Epoch 1/30, Loss: 0.6846\n",
      "Epoch 2/30, Loss: 0.6817\n",
      "Epoch 3/30, Loss: 0.6798\n",
      "Epoch 4/30, Loss: 0.6807\n",
      "Epoch 5/30, Loss: 0.6787\n",
      "Epoch 6/30, Loss: 0.6781\n",
      "Epoch 7/30, Loss: 0.6747\n",
      "Epoch 8/30, Loss: 0.6731\n",
      "Epoch 9/30, Loss: 0.6714\n",
      "Epoch 10/30, Loss: 0.6694\n",
      "Epoch 11/30, Loss: 0.6684\n",
      "Epoch 12/30, Loss: 0.6754\n",
      "Epoch 13/30, Loss: 0.6829\n",
      "Epoch 14/30, Loss: 0.6745\n",
      "Epoch 15/30, Loss: 0.6658\n",
      "Epoch 16/30, Loss: 0.6678\n",
      "Epoch 17/30, Loss: 0.6661\n",
      "Epoch 18/30, Loss: 0.6639\n",
      "Epoch 19/30, Loss: 0.6641\n",
      "Epoch 20/30, Loss: 0.6599\n",
      "Epoch 21/30, Loss: 0.6631\n",
      "Epoch 22/30, Loss: 0.6565\n",
      "Epoch 23/30, Loss: 0.6542\n",
      "Epoch 24/30, Loss: 0.6546\n",
      "Epoch 25/30, Loss: 0.6547\n",
      "Epoch 26/30, Loss: 0.6542\n",
      "Epoch 27/30, Loss: 0.6636\n",
      "Epoch 28/30, Loss: 0.6606\n",
      "Epoch 29/30, Loss: 0.6562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 9 - Evaluating methods:  20%|        | 1/5 [00:01<00:07,  1.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/30, Loss: 0.6545\n",
      "Evaluating models...\n",
      "Successfully aligned predictions with 10 NaN padding values\n",
      "LSTM - Accuracy: 0.6069, F1: 0.7554, ROC AUC: 0.4547\n",
      "LightGBM - Accuracy: 0.3935, F1: 0.0000, ROC AUC: 0.5473\n",
      "\n",
      "Testing normalization method: z_score (Fold 9)\n",
      "Created LSTM sequences with lookback=10: 1383 train, 145 test\n",
      "Training LSTM model...\n",
      "Epoch 1/30, Loss: 0.6827\n",
      "Epoch 2/30, Loss: 0.6676\n",
      "Epoch 3/30, Loss: 0.6581\n",
      "Epoch 4/30, Loss: 0.6509\n",
      "Epoch 5/30, Loss: 0.6445\n",
      "Epoch 6/30, Loss: 0.6355\n",
      "Epoch 7/30, Loss: 0.6247\n",
      "Epoch 8/30, Loss: 0.6145\n",
      "Epoch 9/30, Loss: 0.5945\n",
      "Epoch 10/30, Loss: 0.5818\n",
      "Epoch 11/30, Loss: 0.5654\n",
      "Epoch 12/30, Loss: 0.5556\n",
      "Epoch 13/30, Loss: 0.5285\n",
      "Epoch 14/30, Loss: 0.5066\n",
      "Epoch 15/30, Loss: 0.4843\n",
      "Epoch 16/30, Loss: 0.4579\n",
      "Epoch 17/30, Loss: 0.4487\n",
      "Epoch 18/30, Loss: 0.4231\n",
      "Epoch 19/30, Loss: 0.4095\n",
      "Epoch 20/30, Loss: 0.3893\n",
      "Epoch 21/30, Loss: 0.3771\n",
      "Epoch 22/30, Loss: 0.3490\n",
      "Epoch 23/30, Loss: 0.3415\n",
      "Epoch 24/30, Loss: 0.3302\n",
      "Epoch 25/30, Loss: 0.3108\n",
      "Epoch 26/30, Loss: 0.2948\n",
      "Epoch 27/30, Loss: 0.3019\n",
      "Epoch 28/30, Loss: 0.2735\n",
      "Epoch 29/30, Loss: 0.2647\n",
      "Epoch 30/30, Loss: 0.2577\n",
      "Evaluating models...\n",
      "Successfully aligned predictions with 10 NaN padding values\n",
      "LSTM - Accuracy: 0.4621, F1: 0.4429, ROC AUC: 0.4681\n",
      "LightGBM - Accuracy: 0.3935, F1: 0.0000, ROC AUC: 0.5776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 9 - Evaluating methods:  40%|      | 2/5 [00:03<00:05,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing normalization method: median (Fold 9)\n",
      "Created LSTM sequences with lookback=10: 1383 train, 145 test\n",
      "Training LSTM model...\n",
      "Epoch 1/30, Loss: 0.6788\n",
      "Epoch 2/30, Loss: 0.6625\n",
      "Epoch 3/30, Loss: 0.6491\n",
      "Epoch 4/30, Loss: 0.6368\n",
      "Epoch 5/30, Loss: 0.6195\n",
      "Epoch 6/30, Loss: 0.5928\n",
      "Epoch 7/30, Loss: 0.5699\n",
      "Epoch 8/30, Loss: 0.5320\n",
      "Epoch 9/30, Loss: 0.4945\n",
      "Epoch 10/30, Loss: 0.4403\n",
      "Epoch 11/30, Loss: 0.4045\n",
      "Epoch 12/30, Loss: 0.3605\n",
      "Epoch 13/30, Loss: 0.3333\n",
      "Epoch 14/30, Loss: 0.2959\n",
      "Epoch 15/30, Loss: 0.2748\n",
      "Epoch 16/30, Loss: 0.2618\n",
      "Epoch 17/30, Loss: 0.2425\n",
      "Epoch 18/30, Loss: 0.2015\n",
      "Epoch 19/30, Loss: 0.1910\n",
      "Epoch 20/30, Loss: 0.1744\n",
      "Epoch 21/30, Loss: 0.1760\n",
      "Epoch 22/30, Loss: 0.1532\n",
      "Epoch 23/30, Loss: 0.1439\n",
      "Epoch 24/30, Loss: 0.1285\n",
      "Epoch 25/30, Loss: 0.1163\n",
      "Epoch 26/30, Loss: 0.1254\n",
      "Epoch 27/30, Loss: 0.1177\n",
      "Epoch 28/30, Loss: 0.1368\n",
      "Epoch 29/30, Loss: 0.0940\n",
      "Epoch 30/30, Loss: 0.0916\n",
      "Evaluating models...\n",
      "Successfully aligned predictions with 10 NaN padding values\n",
      "LSTM - Accuracy: 0.4759, F1: 0.6122, ROC AUC: 0.4318\n",
      "LightGBM - Accuracy: 0.3935, F1: 0.0000, ROC AUC: 0.5499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 9 - Evaluating methods:  60%|    | 3/5 [00:06<00:04,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing normalization method: sigmoid (Fold 9)\n",
      "Created LSTM sequences with lookback=10: 1383 train, 145 test\n",
      "Training LSTM model...\n",
      "Epoch 1/30, Loss: 0.6822\n",
      "Epoch 2/30, Loss: 0.6818\n",
      "Epoch 3/30, Loss: 0.6802\n",
      "Epoch 4/30, Loss: 0.6810\n",
      "Epoch 5/30, Loss: 0.6810\n",
      "Epoch 6/30, Loss: 0.6775\n",
      "Epoch 7/30, Loss: 0.6750\n",
      "Epoch 8/30, Loss: 0.6736\n",
      "Epoch 9/30, Loss: 0.6766\n",
      "Epoch 10/30, Loss: 0.6795\n",
      "Epoch 11/30, Loss: 0.6726\n",
      "Epoch 12/30, Loss: 0.6724\n",
      "Epoch 13/30, Loss: 0.6731\n",
      "Epoch 14/30, Loss: 0.6704\n",
      "Epoch 15/30, Loss: 0.6689\n",
      "Epoch 16/30, Loss: 0.6684\n",
      "Epoch 17/30, Loss: 0.6699\n",
      "Epoch 18/30, Loss: 0.6678\n",
      "Epoch 19/30, Loss: 0.6663\n",
      "Epoch 20/30, Loss: 0.6666\n",
      "Epoch 21/30, Loss: 0.6706\n",
      "Epoch 22/30, Loss: 0.6689\n",
      "Epoch 23/30, Loss: 0.6665\n",
      "Epoch 24/30, Loss: 0.6740\n",
      "Epoch 25/30, Loss: 0.6684\n",
      "Epoch 26/30, Loss: 0.6669\n",
      "Epoch 27/30, Loss: 0.6661\n",
      "Epoch 28/30, Loss: 0.6660\n",
      "Epoch 29/30, Loss: 0.6668\n",
      "Epoch 30/30, Loss: 0.6723\n",
      "Evaluating models...\n",
      "Successfully aligned predictions with 10 NaN padding values\n",
      "LSTM - Accuracy: 0.5931, F1: 0.7354, ROC AUC: 0.4623\n",
      "LightGBM - Accuracy: 0.4968, F1: 0.5357, ROC AUC: 0.4829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 9 - Evaluating methods:  80%|  | 4/5 [00:08<00:02,  2.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing normalization method: tanh_estimator (Fold 9)\n",
      "Created LSTM sequences with lookback=10: 1383 train, 145 test\n",
      "Training LSTM model...\n",
      "Epoch 1/30, Loss: 0.6886\n",
      "Epoch 2/30, Loss: 0.6824\n",
      "Epoch 3/30, Loss: 0.6817\n",
      "Epoch 4/30, Loss: 0.6818\n",
      "Epoch 5/30, Loss: 0.6834\n",
      "Epoch 6/30, Loss: 0.6817\n",
      "Epoch 7/30, Loss: 0.6816\n",
      "Epoch 8/30, Loss: 0.6852\n",
      "Epoch 9/30, Loss: 0.6807\n",
      "Epoch 10/30, Loss: 0.6815\n",
      "Epoch 11/30, Loss: 0.6826\n",
      "Epoch 12/30, Loss: 0.6805\n",
      "Epoch 13/30, Loss: 0.6806\n",
      "Epoch 14/30, Loss: 0.6803\n",
      "Epoch 15/30, Loss: 0.6834\n",
      "Epoch 16/30, Loss: 0.6829\n",
      "Epoch 17/30, Loss: 0.6802\n",
      "Epoch 18/30, Loss: 0.6815\n",
      "Epoch 19/30, Loss: 0.6806\n",
      "Epoch 20/30, Loss: 0.6826\n",
      "Epoch 21/30, Loss: 0.6813\n",
      "Epoch 22/30, Loss: 0.6797\n",
      "Epoch 23/30, Loss: 0.6811\n",
      "Epoch 24/30, Loss: 0.6812\n",
      "Epoch 25/30, Loss: 0.6823\n",
      "Epoch 26/30, Loss: 0.6804\n",
      "Epoch 27/30, Loss: 0.6821\n",
      "Epoch 28/30, Loss: 0.6831\n",
      "Epoch 29/30, Loss: 0.6812\n",
      "Epoch 30/30, Loss: 0.6806\n",
      "Evaluating models...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 9 - Evaluating methods: 100%|| 5/5 [00:10<00:00,  2.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully aligned predictions with 10 NaN padding values\n",
      "LSTM - Accuracy: 0.6069, F1: 0.7554, ROC AUC: 0.4436\n",
      "LightGBM - Accuracy: 0.3935, F1: 0.0000, ROC AUC: 0.5516\n",
      "\n",
      "Processing fold 10/10\n",
      "Class distribution in fold 10: {1: 898, 0: 650}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 10 - Evaluating methods:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing normalization method: min_max (Fold 10)\n",
      "Created LSTM sequences with lookback=10: 1538 train, 145 test\n",
      "Training LSTM model...\n",
      "Epoch 1/30, Loss: 0.6826\n",
      "Epoch 2/30, Loss: 0.6797\n",
      "Epoch 3/30, Loss: 0.6775\n",
      "Epoch 4/30, Loss: 0.6787\n",
      "Epoch 5/30, Loss: 0.6784\n",
      "Epoch 6/30, Loss: 0.6763\n",
      "Epoch 7/30, Loss: 0.6757\n",
      "Epoch 8/30, Loss: 0.6783\n",
      "Epoch 9/30, Loss: 0.6748\n",
      "Epoch 10/30, Loss: 0.6785\n",
      "Epoch 11/30, Loss: 0.6764\n",
      "Epoch 12/30, Loss: 0.6747\n",
      "Epoch 13/30, Loss: 0.6741\n",
      "Epoch 14/30, Loss: 0.6731\n",
      "Epoch 15/30, Loss: 0.6781\n",
      "Epoch 16/30, Loss: 0.6763\n",
      "Epoch 17/30, Loss: 0.6764\n",
      "Epoch 18/30, Loss: 0.6748\n",
      "Epoch 19/30, Loss: 0.6744\n",
      "Epoch 20/30, Loss: 0.6755\n",
      "Epoch 21/30, Loss: 0.6734\n",
      "Epoch 22/30, Loss: 0.6705\n",
      "Epoch 23/30, Loss: 0.6741\n",
      "Epoch 24/30, Loss: 0.6683\n",
      "Epoch 25/30, Loss: 0.6736\n",
      "Epoch 26/30, Loss: 0.6752\n",
      "Epoch 27/30, Loss: 0.6720\n",
      "Epoch 28/30, Loss: 0.6728\n",
      "Epoch 29/30, Loss: 0.6693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 10 - Evaluating methods:  20%|        | 1/5 [00:06<00:25,  6.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/30, Loss: 0.6716\n",
      "Evaluating models...\n",
      "Successfully aligned predictions with 10 NaN padding values\n",
      "LSTM - Accuracy: 0.5379, F1: 0.6996, ROC AUC: 0.6144\n",
      "LightGBM - Accuracy: 0.5161, F1: 0.5665, ROC AUC: 0.5757\n",
      "\n",
      "Testing normalization method: z_score (Fold 10)\n",
      "Created LSTM sequences with lookback=10: 1538 train, 145 test\n",
      "Training LSTM model...\n",
      "Epoch 1/30, Loss: 0.6739\n",
      "Epoch 2/30, Loss: 0.6605\n",
      "Epoch 3/30, Loss: 0.6469\n",
      "Epoch 4/30, Loss: 0.6511\n",
      "Epoch 5/30, Loss: 0.6240\n",
      "Epoch 6/30, Loss: 0.6142\n",
      "Epoch 7/30, Loss: 0.5912\n",
      "Epoch 8/30, Loss: 0.5769\n",
      "Epoch 9/30, Loss: 0.5364\n",
      "Epoch 10/30, Loss: 0.5140\n",
      "Epoch 11/30, Loss: 0.4892\n",
      "Epoch 12/30, Loss: 0.4584\n",
      "Epoch 13/30, Loss: 0.4334\n",
      "Epoch 14/30, Loss: 0.4227\n",
      "Epoch 15/30, Loss: 0.3799\n",
      "Epoch 16/30, Loss: 0.3535\n",
      "Epoch 17/30, Loss: 0.3629\n",
      "Epoch 18/30, Loss: 0.3235\n",
      "Epoch 19/30, Loss: 0.3216\n",
      "Epoch 20/30, Loss: 0.2991\n",
      "Epoch 21/30, Loss: 0.2782\n",
      "Epoch 22/30, Loss: 0.2638\n",
      "Epoch 23/30, Loss: 0.2621\n",
      "Epoch 24/30, Loss: 0.2492\n",
      "Epoch 25/30, Loss: 0.2297\n",
      "Epoch 26/30, Loss: 0.2228\n",
      "Epoch 27/30, Loss: 0.2195\n",
      "Epoch 28/30, Loss: 0.2063\n",
      "Epoch 29/30, Loss: 0.1810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 10 - Evaluating methods:  40%|      | 2/5 [00:16<00:25,  8.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/30, Loss: 0.1881\n",
      "Evaluating models...\n",
      "Successfully aligned predictions with 10 NaN padding values\n",
      "LSTM - Accuracy: 0.5241, F1: 0.4733, ROC AUC: 0.5216\n",
      "LightGBM - Accuracy: 0.4839, F1: 0.5556, ROC AUC: 0.5420\n",
      "\n",
      "Testing normalization method: median (Fold 10)\n",
      "Created LSTM sequences with lookback=10: 1538 train, 145 test\n",
      "Training LSTM model...\n",
      "Epoch 1/30, Loss: 0.6737\n",
      "Epoch 2/30, Loss: 0.6602\n",
      "Epoch 3/30, Loss: 0.6365\n",
      "Epoch 4/30, Loss: 0.6053\n",
      "Epoch 5/30, Loss: 0.5822\n",
      "Epoch 6/30, Loss: 0.5322\n",
      "Epoch 7/30, Loss: 0.4868\n",
      "Epoch 8/30, Loss: 0.4359\n",
      "Epoch 9/30, Loss: 0.4075\n",
      "Epoch 10/30, Loss: 0.3658\n",
      "Epoch 11/30, Loss: 0.3241\n",
      "Epoch 12/30, Loss: 0.2942\n",
      "Epoch 13/30, Loss: 0.2744\n",
      "Epoch 14/30, Loss: 0.2480\n",
      "Epoch 15/30, Loss: 0.2290\n",
      "Epoch 16/30, Loss: 0.2263\n",
      "Epoch 17/30, Loss: 0.1875\n",
      "Epoch 18/30, Loss: 0.1673\n",
      "Epoch 19/30, Loss: 0.1668\n",
      "Epoch 20/30, Loss: 0.1461\n",
      "Epoch 21/30, Loss: 0.1142\n",
      "Epoch 22/30, Loss: 0.1280\n",
      "Epoch 23/30, Loss: 0.1136\n",
      "Epoch 24/30, Loss: 0.1033\n",
      "Epoch 25/30, Loss: 0.0933\n",
      "Epoch 26/30, Loss: 0.0771\n",
      "Epoch 27/30, Loss: 0.0753\n",
      "Epoch 28/30, Loss: 0.0666\n",
      "Epoch 29/30, Loss: 0.0662\n",
      "Epoch 30/30, Loss: 0.0533\n",
      "Evaluating models...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 10 - Evaluating methods:  60%|    | 3/5 [00:22<00:14,  7.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully aligned predictions with 10 NaN padding values\n",
      "LSTM - Accuracy: 0.5655, F1: 0.6038, ROC AUC: 0.5838\n",
      "LightGBM - Accuracy: 0.4774, F1: 0.5525, ROC AUC: 0.5462\n",
      "\n",
      "Testing normalization method: sigmoid (Fold 10)\n",
      "Created LSTM sequences with lookback=10: 1538 train, 145 test\n",
      "Training LSTM model...\n",
      "Epoch 1/30, Loss: 0.6842\n",
      "Epoch 2/30, Loss: 0.6822\n",
      "Epoch 3/30, Loss: 0.6821\n",
      "Epoch 4/30, Loss: 0.6805\n",
      "Epoch 5/30, Loss: 0.6809\n",
      "Epoch 6/30, Loss: 0.6758\n",
      "Epoch 7/30, Loss: 0.6788\n",
      "Epoch 8/30, Loss: 0.6788\n",
      "Epoch 9/30, Loss: 0.6781\n",
      "Epoch 10/30, Loss: 0.6805\n",
      "Epoch 11/30, Loss: 0.6763\n",
      "Epoch 12/30, Loss: 0.6774\n",
      "Epoch 13/30, Loss: 0.6733\n",
      "Epoch 14/30, Loss: 0.6758\n",
      "Epoch 15/30, Loss: 0.6750\n",
      "Epoch 16/30, Loss: 0.6746\n",
      "Epoch 17/30, Loss: 0.6766\n",
      "Epoch 18/30, Loss: 0.6763\n",
      "Epoch 19/30, Loss: 0.6710\n",
      "Epoch 20/30, Loss: 0.6736\n",
      "Epoch 21/30, Loss: 0.6769\n",
      "Epoch 22/30, Loss: 0.6766\n",
      "Epoch 23/30, Loss: 0.6737\n",
      "Epoch 24/30, Loss: 0.6769\n",
      "Epoch 25/30, Loss: 0.6775\n",
      "Epoch 26/30, Loss: 0.6716\n",
      "Epoch 27/30, Loss: 0.6714\n",
      "Epoch 28/30, Loss: 0.6727\n",
      "Epoch 29/30, Loss: 0.6715\n",
      "Early stopping at epoch 29\n",
      "Evaluating models...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 10 - Evaluating methods:  80%|  | 4/5 [00:28<00:06,  6.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully aligned predictions with 10 NaN padding values\n",
      "LSTM - Accuracy: 0.5379, F1: 0.6996, ROC AUC: 0.7344\n",
      "LightGBM - Accuracy: 0.5871, F1: 0.6049, ROC AUC: 0.5979\n",
      "\n",
      "Testing normalization method: tanh_estimator (Fold 10)\n",
      "Created LSTM sequences with lookback=10: 1538 train, 145 test\n",
      "Training LSTM model...\n",
      "Epoch 1/30, Loss: 0.6879\n",
      "Epoch 2/30, Loss: 0.6823\n",
      "Epoch 3/30, Loss: 0.6847\n",
      "Epoch 4/30, Loss: 0.6825\n",
      "Epoch 5/30, Loss: 0.6814\n",
      "Epoch 6/30, Loss: 0.6845\n",
      "Epoch 7/30, Loss: 0.6804\n",
      "Epoch 8/30, Loss: 0.6871\n",
      "Epoch 9/30, Loss: 0.6809\n",
      "Epoch 10/30, Loss: 0.6828\n",
      "Epoch 11/30, Loss: 0.6839\n",
      "Epoch 12/30, Loss: 0.6842\n",
      "Epoch 13/30, Loss: 0.6835\n",
      "Epoch 14/30, Loss: 0.6825\n",
      "Epoch 15/30, Loss: 0.6814\n",
      "Epoch 16/30, Loss: 0.6816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 10 - Evaluating methods: 100%|| 5/5 [00:33<00:00,  6.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/30, Loss: 0.6821\n",
      "Early stopping at epoch 17\n",
      "Evaluating models...\n",
      "Successfully aligned predictions with 10 NaN padding values\n",
      "LSTM - Accuracy: 0.5379, F1: 0.6996, ROC AUC: 0.3848\n",
      "LightGBM - Accuracy: 0.5419, F1: 0.6077, ROC AUC: 0.5844\n",
      "\n",
      "Processing cross-validation results...\n",
      "\n",
      "Performing statistical significance tests (Wilcoxon)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "STATISTICAL SIGNIFICANCE ANALYSIS (WILCOXON TEST)\n",
      "======================================================================\n",
      "\n",
      "LIGHTGBM MODEL RESULTS:\n",
      "--------------------------------------------------\n",
      "\n",
      "ACCURACY (baseline: min_max):\n",
      "Method          Mean Diff    % Improv   p-value      Significant\n",
      "------------------------------------------------------------\n",
      "sigmoid         0.0123       2.33%      0.5566       No        \n",
      "tanh_estimator  0.0052       0.98%      0.6250       No        \n",
      "z_score         -0.0019      -0.37%     0.9453       No        \n",
      "median          -0.0077      -1.47%     0.2656       No        \n",
      "\n",
      "* p < 0.05 indicates statistical significance\n",
      "\n",
      "F1 (baseline: min_max):\n",
      "Method          Mean Diff    % Improv   p-value      Significant\n",
      "------------------------------------------------------------\n",
      "sigmoid         0.0740       14.05%     0.3750       No        \n",
      "tanh_estimator  0.0012       0.22%      1.0000       No        \n",
      "z_score         -0.0003      -0.05%     0.7422       No        \n",
      "median          -0.0096      -1.82%     0.1953       No        \n",
      "\n",
      "* p < 0.05 indicates statistical significance\n",
      "\n",
      "ROC_AUC (baseline: min_max):\n",
      "Method          Mean Diff    % Improv   p-value      Significant\n",
      "------------------------------------------------------------\n",
      "tanh_estimator  0.0036       0.66%      0.1641       No        \n",
      "z_score         0.0004       0.06%      0.8457       No        \n",
      "median          -0.0017      -0.31%     0.9219       No        \n",
      "sigmoid         -0.0083      -1.51%     0.9102       No        \n",
      "\n",
      "* p < 0.05 indicates statistical significance\n",
      "\n",
      "LSTM MODEL RESULTS:\n",
      "--------------------------------------------------\n",
      "\n",
      "ACCURACY (baseline: min_max):\n",
      "Method          Mean Diff    % Improv   p-value      Significant\n",
      "------------------------------------------------------------\n",
      "tanh_estimator  0.0110       1.97%      1.0000       No        \n",
      "sigmoid         -0.0145      -2.58%     0.5938       No        \n",
      "z_score         -0.0303      -5.41%     0.0938       No        \n",
      "median          -0.0324      -5.77%     0.2031       No        \n",
      "\n",
      "* p < 0.05 indicates statistical significance\n",
      "\n",
      "F1 (baseline: min_max):\n",
      "Method          Mean Diff    % Improv   p-value      Significant\n",
      "------------------------------------------------------------\n",
      "tanh_estimator  0.0453       6.64%      0.6250       No        \n",
      "sigmoid         0.0167       2.45%      1.0000       No        \n",
      "median          -0.1008      -14.78%    0.0371*      Yes*      \n",
      "z_score         -0.1144      -16.78%    0.0039*      Yes*      \n",
      "\n",
      "* p < 0.05 indicates statistical significance\n",
      "\n",
      "ROC_AUC (baseline: min_max):\n",
      "Method          Mean Diff    % Improv   p-value      Significant\n",
      "------------------------------------------------------------\n",
      "sigmoid         0.0047       0.87%      1.0000       No        \n",
      "z_score         -0.0159      -2.95%     1.0000       No        \n",
      "median          -0.0169      -3.16%     0.2754       No        \n",
      "tanh_estimator  -0.0805      -14.99%    0.1055       No        \n",
      "\n",
      "* p < 0.05 indicates statistical significance\n",
      "\n",
      "==================================================\n",
      "SUMMARY OF STATISTICAL FINDINGS\n",
      "==================================================\n",
      "\n",
      "No statistically significant improvements were found over the baseline method.\n",
      "\n",
      "Note: Statistical significance was tested using the Wilcoxon signed-rank test.\n",
      "\n",
      "Generating statistical significance visualizations in visualizations/\n",
      "\n",
      "============================================================\n",
      "NORMALIZATION METHOD PERFORMANCE SUMMARY (10-FOLD CV)\n",
      "============================================================\n",
      "\n",
      "LIGHTGBM MODEL RESULTS:\n",
      "----------------------------------------\n",
      "Best accuracy: sigmoid (0.5381)\n",
      "  vs. baseline (min_max): 0.5258 (+2.33%)\n",
      "  Std Dev: 0.0345 vs. baseline: 0.0664\n",
      "Best f1: sigmoid (0.6005)\n",
      "  vs. baseline (min_max): 0.5265 (+14.05%)\n",
      "  Std Dev: 0.0625 vs. baseline: 0.2095\n",
      "Best roc_auc: tanh_estimator (0.5532)\n",
      "  vs. baseline (min_max): 0.5496 (+0.66%)\n",
      "  Std Dev: 0.0564 vs. baseline: 0.0559\n",
      "\n",
      "All methods:\n",
      "Method          Accuracy             F1-Score             ROC AUC             \n",
      "---------------------------------------------------------------------------\n",
      "min_max         0.5258  0.0664      0.5265  0.2095      0.5496  0.0559     \n",
      "z_score         0.5239  0.0655      0.5263  0.2103      0.5499  0.0578     \n",
      "median          0.5181  0.0758      0.5169  0.2135      0.5478  0.0526     \n",
      "sigmoid         0.5381  0.0345      0.6005  0.0625      0.5412  0.0428     \n",
      "tanh_estimator  0.5310  0.0711      0.5277  0.2105      0.5532  0.0564     \n",
      "\n",
      "LSTM MODEL RESULTS:\n",
      "----------------------------------------\n",
      "Best accuracy: tanh_estimator (0.5724)\n",
      "  vs. baseline (min_max): 0.5614 (+1.97%)\n",
      "  Std Dev: 0.0391 vs. baseline: 0.0839\n",
      "Best f1: tanh_estimator (0.7273)\n",
      "  vs. baseline (min_max): 0.6820 (+6.64%)\n",
      "  Std Dev: 0.0315 vs. baseline: 0.1082\n",
      "Best roc_auc: sigmoid (0.5416)\n",
      "  vs. baseline (min_max): 0.5369 (+0.87%)\n",
      "  Std Dev: 0.0932 vs. baseline: 0.1028\n",
      "\n",
      "All methods:\n",
      "Method          Accuracy             F1-Score             ROC AUC             \n",
      "---------------------------------------------------------------------------\n",
      "min_max         0.5614  0.0839      0.6820  0.1082      0.5369  0.1028     \n",
      "z_score         0.5310  0.0657      0.5676  0.1377      0.5211  0.0771     \n",
      "median          0.5290  0.0366      0.5812  0.0669      0.5200  0.0493     \n",
      "sigmoid         0.5469  0.0364      0.6987  0.0416      0.5416  0.0932     \n",
      "tanh_estimator  0.5724  0.0391      0.7273  0.0315      0.4564  0.0672     \n",
      "\n",
      "========================================\n",
      "OVERALL BEST NORMALIZATION METHODS\n",
      "========================================\n",
      "\n",
      "LIGHTGBM:\n",
      "Top methods by average rank:\n",
      "1. tanh_estimator (avg rank: 1.67, acc: 0.5310, f1: 0.5277, roc_auc: 0.5532)\n",
      "2. sigmoid (avg rank: 2.33, acc: 0.5381, f1: 0.6005, roc_auc: 0.5412)\n",
      "3. min_max (avg rank: 3.00, acc: 0.5258, f1: 0.5265, roc_auc: 0.5496)\n",
      "\n",
      "LSTM:\n",
      "Top methods by average rank:\n",
      "1. sigmoid (avg rank: 2.00, acc: 0.5469, f1: 0.6987, roc_auc: 0.5416)\n",
      "2. min_max (avg rank: 2.33, acc: 0.5614, f1: 0.6820, roc_auc: 0.5369)\n",
      "3. tanh_estimator (avg rank: 2.33, acc: 0.5724, f1: 0.7273, roc_auc: 0.4564)\n",
      "Results saved to results/normalization_results_osebx_with_stats.csv\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Impact of Normalization Techniques with Statistical Significance Testing\")\n",
    "print(\"=\"*60)\n",
    "norm_methods = [\n",
    "    \"min_max\",\n",
    "    \"z_score\",\n",
    "    \"median\",\n",
    "    \"sigmoid\",\n",
    "    \"tanh_estimator\"\n",
    "]\n",
    "baseline = \"min_max\"\n",
    "fast_mode = False\n",
    "n_folds = 10\n",
    "time_series_split = True\n",
    "gap = 5\n",
    "\n",
    "research = NormalizationResearch(\n",
    "    cache_path=\"data\",\n",
    "    fast_mode=fast_mode,\n",
    "    start_date=\"2014-01-01\",\n",
    "    end_date=\"2024-12-31\",\n",
    "    norm_methods=norm_methods,\n",
    "    baseline_method=baseline,\n",
    "    market_index=\"OSEBX.OL\",\n",
    "    n_folds=n_folds,\n",
    "    time_series_split=time_series_split,\n",
    "    gap=gap,\n",
    "    lookback_window=10,\n",
    "    random_seed=2025\n",
    ")\n",
    "\n",
    "results = research.run_normalization_comparison()\n",
    "\n",
    "research.perform_statistical_tests()\n",
    "research.print_statistical_summary()\n",
    "research.plot_statistical_significance()\n",
    "research.plot_pvalue_heatmap()\n",
    "\n",
    "research.print_summary()\n",
    "research.save_results_to_csv(\"results/normalization_results_osebx_with_stats.csv\")\n",
    "research.plot_results()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "big-data-exam",
   "language": "python",
   "name": "big-data-exam"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
